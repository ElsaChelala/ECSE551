body,subreddit
"When using <a href> once the client hovers over the <a> element, at the left bottom corner he'll see what link your directing them. Many clients, so am I, like to see what link you're directing them into.",Javascript
"Both of the ugly here are for web deployed apps.  
For electron apps I'm going to keep using css in js. It's a lot cleaner and nicer to use than webpack integrated less/css module styles and other alternatives I've used.",Javascript
"This is great! Thank you!

There’s one thing missing from number format though I believe, the locale provider. 

The output should render differently if I choose USD with a locale of en-ca for example.",Javascript
I built my own music player to listen during coding sessions at work to improve my productivity. Built it in React framework and just used Javascript's inbuilt Audio API to implement the player functionality. The app is running at [https://unmusic.github.io](https://unmusic.github.io) and source code is available in [Github](https://github.com/unmusic/unmusic.github.io). Please check it out and give feedback.,Javascript
"Hi everyone!

I’m a high school senior in NYC who’s been building [Alu Learn](https://alulearn.com/l/signup): a website that uses spaced repetition flashcards to optimize memory retention and help students learn more effectively.  I’ve focused on creating flashcards for different AP Exams, exams that many high schoolers take to get college credit.

You can check it out at [alulearn.com](https://alulearn.com/l/signup)",Javascript
"Hey everyone!

I've been creating several in-depth Javascript tutorials and exercises which I've been posting on Youtube daily. I would love any feedback or criticism: [https://www.youtube.com/channel/UCw3LzfWsv-xXTFI6Q4Y4SwQ/](https://www.youtube.com/channel/UCw3LzfWsv-xXTFI6Q4Y4SwQ/)

I've been teaching programming for several years and was both humbled and saddened by the struggles so many students had when learning. Going through the ""traditional"" path myself, I wanted to share as much as I can that I've learned from both industry and teaching.

Being a super nerd at heart and overly fond of programming, I want to do whatever possible to share that love and help others break in to the field and see if it's right for them :)",Javascript
"I use Nunjucks for a templating engine with my nodejs website at my job. This is a website that serves a few thousand employees. But I'm a bacnkend programmer who created this website out of neccesity so to answer your question, I dont know.",Javascript
"In my experience, many legacy enterprise applications are using some sort of templating language. If you are working in a large enterprise be prepared to fix issues in these applications as they stick around forever.",Javascript
"Template Engines are still very much a thing. JAMStack static site builders like 11ty, Jekyll still leverage template languages. In terms of Enterprise,  Shopify theme development relies on the Liquid template Engine for its webshops.   


Aside from Shopify and JAMStack, frameworks also employ them. You have Blade (Laravel), EEX (Embedded Elixir) and many more. Use cases vary for the applied usage but very prevalent in SaaS platforms which need a safe consumer facing language.",Javascript
Yes.  I'm not sure how others use template engines but the way we use a template engine is to generate documents that eventually gets served to customers related to their billing information or account information.  These documents are either viewed as PDF(s) for the customer or get mailed out to the customer (if they selected to receive mailing for any billing/charges).,Javascript
"1. This is incorrect. Shadowmaps are associated with lights. Lights can be enabled for different objects via .layers.  
2. In threejs you can render on demand at any time. You call renderer.render().  
3. Threejs IS ""just"" a renderer, but there are Game Engines built on top of it.. and there are samples that encapsulate many game behaviors like integration with physics libraries (ammo.js/cannon.js), AR/VR, and a pointerlock samples..  (as do PlayCanvas and AFrame and other engines).  But generally threejs seems to focus on rendering instead of being a monolothic engine. If a full game engine is your style, there are a number of them available, including ones with ts bindings/written in ts. There are also facilities for running on web via Unity or Unreal.  
4. WebGPU hasn't landed in browsers so how this will work in threejs is still up in the air a bit, but there is a wip WebGPU renderer.  
5. You can already do something similar to the described ""snapshot rendering"" in threejs in all browsers today, by disabling matrixAutoUpdate on the scene, and calling the renderer.render in threejs. I think you can also create a shallow clone of scene hierarchies that may fill the same purpose. This will skip doing the transformation hierarchy update and just render the buffers as they are encountered, though the use case for this still seems dubious to me, since modelviewmatrices need to be recomputed when viewpoints change.. and material changes may require different/additional matrix inputs depending on what they have enabled, hence requiring a matrix update traversal anyway.  
6. Tooling:THREEJS has the threejs editor.. (here: https://threejs.org/editor/ ) which allows inspection/editing/scripting of scene components/properties. It's also just another component in the library and can be modified to suit the needs of game engines built on top of threejs.  PlayCanvas and I believe AFrame both offer similar functionality.  
7. threejs used to have a blender exporter, but this was deprecated in favor of deeply supporting the GLTF format. You can add custom properties to objects in blender and these will be exported via the GLTF exporter.Additionally.. the gltf-pack tool can modify, transform, and compress gltf files by orders of magnitude over what is offered by other formats. We deal with models at my current job that start out at 100-200 megabytes and can compress down to <\~10 megabytes via gltfpack. Not only do you gain on disk/wire compression, the models and textures can stay ""compressed"" in memory, and thus have a smaller GPU footprint and reduce vertex/texture bandwidth in the renderer. it's pretty amazing. (Ibelieve this is interoperable with babylon as well, and i highly recommend checking it out!)  
8. Community and support. The threejs community is vast, and there are lots of people working on the engine. I haven't encountered engine bugs in a long time as it is relatively stable especially if you are pinned to a known version of threejs. There ma",Javascript
"So we've set up a pipeline that does latest dependency updates for us daily (using npm-check-updates). Our package.json pins version on patch but the pipeline itself always updates to the latest version regardless of pinning then creates a PR to test.

If it breaks we don't merge it, but now we know we have to plan in work to update to the latest version. 

If you're updating dependencies on the major without testing, IMHO if your app breaks own it.",Javascript
"Our team used Linaria extensively and found it to work to pretty. Slightly more convenient than `styled-components` even. Yes, it uses inline styles to handle dynamic props, but other than that it solved all the downsides mentioned in this post, at least. It cleanly generates a separate CSS that is loaded the way hand-written CSS would be.

Ultimately we did move away from it, but that was because it’s exclusive to Babel, and we really wanted to move to SWC, because of the performance benefits.",Javascript
I feel like the actual takeaway here is to have functional tests. If all your tests mock axios (probably not an unreasonable assumptions for unit testing to not make actual network calls) then you wouldn't have noticed the issue anyway - even if you did have a lockfile.,Javascript
"These people have a problem with their production setup. If your production can break out of the blue because of a third party updating their library, you’re doing it wrong, very wrong:

1.	Referencing dependencies directly via a cdn (without a specific version).
2.	Not installing the dependency via a package manager.
3.	Not having any tests in place before you deploy to production.

We should call them out on it before they complain to an open source maintainer…",Javascript
"Ok, there’s apparently a whole parallel universe that’s like the Wild West where devops best practices don’t exist … and they seem to think it’s how it’s *supposed to be done*.  

Not quite as crazy, the folks in this thread seem to be surprised that the others exist. Sorry to shock you but, anybody can bang on the keyboard, deploy, and then call themselves a “software engineer.”

“When you have a computer they let you do it. You can do anything. Grab 'em by versionless URL. You can do anything.”",Javascript
"As always, people blame the users, and not the infrastructure. Maybe the JS community can benefit from a package manager that doesn't enable so much foot shooting. At the very least, npm/yarn should not use wildcard versions by default, and considering how maddeningly chaotic dependency trees can get, maybe getting rid of wildcards altogether would be beneficial.",Javascript
"Page straight up crashed chrome on my phone lol. And it keeps crashing, freezing, and eventually killing the page or the OS.

GitHub also needs to get their crap together and handle rendering less elements to the DOM per comment I guess haha",Javascript
Just a friendly reminder that the polyfill used here is enormous because it was written more as a means of experimentation with the proposal than as a polyfill that is ready for production. You're probably better off sticking with a smaller date library for the time being and switching to Temporal once it reaches stage 4 and has a suitable polyfill in place.,Javascript
"It depends. I'm a senior frontend engineer, and while the obvious answer to the question asked by the audience is ""yes"", I couldn't tell you the ""how"" any more than he can. To me, there is no concept of ""senior react engineer"" or ""senior angular engineer"" because those are just frameworks/libraries, and you can get good at them to a degree while having never learned the underlying language, but unless you learn the underlying language, you'll never really be truly good at the framework. A century or so ago, we had this same debate about whether Ruby on Rails engineers were really ruby engineers. What makes someone a senior frontend engineer to me is their language skills - html, css, js (and build tools, etc - the ecosystem that modern js uses). A senior engineer can relatively easily pick up whatever framework is needed for the job because at the end of the day, it's all just javascript.

What makes a senior engineer is very subjective, so to the speaker, he is whatever he says he is (assuming he truly does have experience and skill in his craft). To you, he might not qualify to be a senior engineer because he's not familiar enough with all the modern frameworks, and that's perfectly acceptable.

So I guess the answer is (as with everything else lol) ""it depends"".

Edit: added minor clarification",Javascript
"He is a senior who specializes in React.

Just like there are many doctors, you ask an eye doctor about your heart, the doctor will refer you to a heart doctor.

Eye doctor might have a slight idea, but will still refer you to heart doctor.",Javascript
"The ""senior"" designation has no correlation to number of frameworks under your belt, it's meant to correlate to a baseline of architectural and/or team leading skills.

More likely than not, they are just using their official title from work and you're reading too much into it.",Javascript
"I have built major projects on 6 different frameworks and am very much a senior, but I am only senior level on 2 of the frameworks i have used.  


To me a senior is someone with the capability to solve most problems on their own, they understand the process of creation from discovery to deployment, and stand ready to tackle projects outside their expertise as a 'challenge'

If you are looking for someone who knows every framework and every language out there at a senior level...they do not exist....and if they claim they do, they are full of it.",Javascript
"Has anyone tried compiled? [https://compiledcssinjs.com/](https://compiledcssinjs.com/)

From my understanding, it gives you all the css-in-js api but it compiles it into css during build time so you have less runtime overhead.",Javascript
"You're right, in that those techniques are independent of any client-side framework.  You can build libraries to sort of pre-package them into a specific framework, with reusable componentry.  But it's not necessary, they're not connected.  

When people say ""I made an XYZ in React!"" that is a clickbaity way of getting attention.  Really, you can do any client-side technique in any client-side framework, because under the hood, it's all just JavaScript and browsers.  

If people really wanted to be educational, they would divorce the technique from the framework.  But then nobody would go to their talk.  So, this person is just a huckster, who is targeting React people, and doesn't care to delve into anything else, because it's not useful to them.

Ultimately, the blame is on the webdev community, for letting itself become so framework hypnotized.  He is just working an audience.",Javascript
"Experimented with an erasable canvas in a halloween theme, for the CodePen Pumpkin Challenge. Switching from the light to dark was an interesting learning experience as well.   


Next time I'd implement some sort of flood fill algorithm so that isolated chunks would fall out on their own.",Javascript
"```js
    sql`SELECT * FROM comments WHERE body = ${id}`;
```
is still an SQL injection waiting to happen.

This should have an additional primitive that either makes it explicit for stuff to be injected in the query text like
```js
    sql`SELECT * FROM comments WHERE ${identifier(colName)} = 5;
```
or be marked as query parameter
```js
    sql`SELECT * FROM comments WHERE body = ${parameter(id)}`;
```

I really love the way [pg-sql2](https://github.com/graphile/graphile-engine/tree/master/packages/pg-sql2) is going about that.",Javascript
"Thanks, this is really neat.

Unfortunately the first Live Demo I found is a bit broken on iOS within in-app-browser:

[https://surveyjs.io/form-library/examples/nps-question/reactjs](https://surveyjs.io/form-library/examples/nps-question/reactjs)

The 'On a scale' question presents as a text box, which when tapped opens up a drop-down and the on-screen keyboard. This means the keyboard hides the drop-down. Also, if you type the number you want, the correct drop-down item is selected, then when you click 'Done' the text box is cleared.

There's also visual bugs with the text-box value and cursor appearing above the drop-down menu, and it is very difficult to select the value you want as the drop-down closes when you attempt to scroll to select an off-screen value.",Javascript
"Cool idea. I really am happy to see that OSS is becoming something that folks can sustain themselves. Great idea with indirect dependencies – given the fact that JS/Node community is built on smaller packages, this might really prove significant.

I would suggest offer one-time payment. Maybe that's just me, but seeing subscription model everywhere is really off-putting. And maybe, but this is probably for the long future, ability to manually adjust the amounts (for example, I want to pay more to an unknown package that I use).",Javascript
"Having had a look at the website, it appears that even projects from Meta and Microsoft get money.

Where does that money end up? As these multi billion companies definitely don't need any more from us..

Excluding companies from donations obviously is a territory you wouldn't really want to tread, but this looks really weird.",Javascript
"Something like this could easily be a scam so how are you keeping things transparent and not just collecting money in your own pockets?

Not that you didn't deserve a cut if you do this legit. Definately interested.",Javascript
"Hey JS Community, I'm a long time JS developer that has no doubt benefited from the great work many of you here have contributed over the years. To pay back our thanks and to hopefully make open source development a viable source of income for many more developers, we built StackAid, a service that automatically discovers and funds your direct and indirect (second order) open source dependencies with a monthly subscription. We're obviously excited to get feedback from the community and hear your thoughts. Cheers.",Javascript
"Please excuse any gramatical errors i’m on my phone and english is not my first language.

These are my thoughts, I haven’t read anything but your homepage so maybe you are doing some of this already.

Try to figure out a way to make it tax deductible for at least the countries that make it easy, you will see wider adoption. Not a lawyer but seems plausible.
I know I wouldn’t bat and eyelash as i would think of it as essentially free.

Add some sort of badge that mantainers can use on their readme’s, it doubles as publicity and for mantainers to implicitly confirm that they are receiving the funds.

Make disbursement information publicity available to build trust and independent persons can verify that the money is being allocated fairly.  

Instead of me having to disable each organization that I dont want have presets like “no public companies” so I don’t need to be on top of it.

Add a non subscription option. I want to do it once a year for tax purposes (if you manage to do it) it might not seem fair because it would be a snapshot but you can use the git history to add weights based on the time the dependency was in use.

Great Idea overall, best of luck.",Javascript
"Cool idea but despite the stereotype that programmers all make 150k-500k/year, lots of hungry developers are poor.

People have a problem paying $10-15/month for streaming services that they use for 6+ hours every single day.

I can buy actual useful software development tools for cheaper than $15/month.  That is waaaaaaay too expensive.  You would get much more adoption for something way cheaper.  

$15/mo sounds like a plan for companies and teams that are feeling charitable.  For the average dev $20/year would be way more appealing.",Javascript
"One thing I like about css in JS is our ability to define theme properties like colors in global provider fed populated from an api request and then utilizing those theme variables inside the style objects. 

What’s the ideal way to provide this capability in css modules?",Javascript
"I love this model. I've been subscribed to Coil for a long time, I wish more sites would use it. I was a fan of Google's paid subscription to remove ads across the web. It disappeared because they couldn't figure out a pricing model that worked at that scale.

I hate it when people glorify ad blockers and expect the universe for free. Bringing that model to NPM just makes sense.

Are you manually adding Stripe accounts for these projects? Or is there an expectation that package maintainers have to sign up? Seems like that would slow things down as opposed to an integration with something like OpenCollective.

I think this would require manual adjustment too. Projects with more packages may get an unfair split simply due to their organizational model.",Javascript
"Was impressed when you [posted your library previously](https://www.reddit.com/r/javascript/comments/xob7n9/subsecond_jquery_is_the_best_way_to_transform_a/), and this playground looks terrific.

Been looking at codemods a lot myself recently and taking the jQuery-route to reduce the boilerplate seems inspired. Really great work.",Javascript
"So basically the idea is that you, knowing your specific use case, could write a better ""framework"" for your specific use case?

I mean, yeah, obviously. The point is that most people will consider the time tradeoff, and in most cases, it's better to save the tremendous amount of time than it is to write your own slightly better version of something.

The kicker is that it's not really a ""better"" version because it's not been tested to the same standards and it's not been around long enough to find all the gotchas that will eventually pop up. Performance is not always the most important thing.",Javascript
"This [project](https://leftonread.me/) is a ton of fun, so wanted to share! Using Electron, React, Typescript, and sqlite, I built an open-source Desktop app that analyzes iMessages and curates a Spotify wrapped-like experience. You can download it [here](https://leftonread.me/) or check us out on [github](https://github.com/Left-on-Read/leftonread). Let me know if any qs. It’s entirely open-source and we do not store your data. The beauty of a Desktop app: the data never leaves your computer!",Javascript
Yo. I love this so much. Gonna share this with all of my friends. Could you give some more details on the technical implementation of this? Would love to learn more about your stack. I've always wanted to build something similar to this.,Javascript
Greetings JS experts out there.  I have a weather application that I'm trying to develop in JavaScript.html.css. I'm new on js been doing Java now I'm moving to Angular since I'm now on spring Boot. All I do self taught. Can anyone contribute to the project? I would appreciate so much. As well as for me to keep learning. I can share the source code,Javascript
"> I love legacy codebases.

> A legacy codebase means that the product is performing well. It means that I can often make immediate and impactful improvements.

I gotta give the writer props for saying this and really looking at the glass half full approach. 

I constantly complain about our legacy code. I'm a bitter old man But they're right. I think about all the code I threw away. Dead. Gone. New code replaced it. 

The ones I haven't thrown away because they're still mission critical? They're doing their job. They're holding together. They may be annoying AF to work in... But I and a lot of people's job exist because of this code. And it's too complex to touch without a major intervention. 

I dunno if that's their intention. But I definitely realize I should stop whining about legacy code (at least for a little bit)",Javascript
"If you need to build a form management system that is flexible and self-hosted, and allows non-technical users like content manager to create multiple forms themselves to lift this burden up your shoulders, you might find adding SurveyJS component to your React app a smart decision on dealing with the challenge.
  

  
The getting started tutorial is here: [https://surveyjs.io/survey-creator/documentation/get-started-react](https://surveyjs.io/survey-creator/documentation/get-started-react) 
  

  
You can find the full code for the getting started in the following GitHub repository: [https://github.com/surveyjs/code-examples/tree/main/get-started-creator/react](https://github.com/surveyjs/code-examples/tree/main/get-started-creator/react).",Javascript
"You are getting bugs because you do not have abstraction layer on top of it.

Create methods for saving, deleting, updating items, have try catch for errors and so on. Never access local storage directly from components but rather have updateItem('key',item). I think you get my point.

Read about repository pattern, it could be applied on any db structure, including local storage.
IndexDB may be the better solution here, but changing the stack due to bad implemention does no seem reasonable to me.",Javascript
"IndexedDB is probably what you want, but it can be a bit of a pain to get set up with.

localForage ([https://localforage.github.io/localForage/](https://localforage.github.io/localForage/)) mirrors localStorage syntax, but uses IndexedDB in the background.  
If that's not supported, it uses WebSQL and then LocalStorage",Javascript
"I literally just merged my PR with CSS-in-JS replacement with CSS Modules. I was fixated on using it just because everybody else was doing it I kinda los the sight of the purpose here.   
CSS Variables and SASS really do their jobs good enough to ditch any CSS-in-JS I'd need.",Javascript
"
It’ll depend completely on the specifications for the output and how easy it is to optimise for it. Some languages lend themselves to be easier for it but it’s far far FARRRR away from gaining mass adoption",Javascript
"WASM makes sense as a target for plugins but not as a replacement for frontend frameworks. You can't access the DOM from WASM so there would be overhead for any solution. Besides, the point of a frontend framework is to provide practical conventions to build off of, improve developer productivity. WASM-based framework bindings  would need to be very abstract in order to support the variety of language implementations, and each implementation would introduce different behavior, so the benefits really fall away.",Javascript
"https://github.com/samchon/typescript-json#runtime-validators

I'd hoped very strong runtime validator library which can support every TypeScript type specs, but there had not been such library. Therefore, I've been developing such library by myself, for a long time.

During one year development, I've succeeded to implement such full-spec runtime validator library.

Now, my library `typescript-json` is the only one which can validate every TypeScript types. The every TypeScript type means that even validating {dynamic properties, template literals types and extreme union types like JSON schema} are possible.

The `typescript-json` requires only one line. Just enjoy the full-spec validator library like below:

```typescript

    export interface DynamicComposite {
        id: string;
        name: string;
        [index: number]: number;
        [key: `prefix_${string}`]: string;
        [key: `${string}_postfix`]: string;
        [key: `value_${number}`]: boolean | string | number;
        [key: `between_${string}_and_${number}`]: boolean;
    }

    const dynamic: DynamicComposite = { ... };
    TSON.is<DynamicComposite>(union);
    TSON.assertType<DynamicComposite>(union);
    TSON.validate<DynamicComposite>(union);
    TSON.stringify<DynamicComposite>(union);

    export type IJsonSchema =
        | IJsonSchema.IEnumeration<""boolean"">
        | IJsonSchema.IEnumeration<""number"">
        | IJsonSchema.IEnumeration<""bigint"">
        | IJsonSchema.IEnumeration<""string"">
        | IJsonSchema.IBoolean
        | IJsonSchema.INumber
        | IJsonSchema.IBigInt
        | IJsonSchema.IString
        | IJsonSchema.IArray
        | IJsonSchema.ITuple
        | IJsonSchema.IOneOf
        | IJsonSchema.IReference
        | IJsonSchema.IRecursiveReference
        | IJsonSchema.IUnknown;

    const schema: IJsonSchema = { ... };
    TSON.is<IJsonSchema>(schema);
    TSON.assertEquals<IJsonSchema>(schema);
    TSON.validateEquals<IJsonSchema>(schema);
    TSON.stringify<IJsonSchema>(schema);

```",Javascript
This seems super useful and I've been considering leveraging `io-ts` or `zod` for runtime type validation purposes. Do you feel your library could provide the same benefits regarding runtime type checking?,Javascript
"Deploy duration is the major factor you are building your release pipeline around. If your application can be deployed to production in a matter of minutes, you can have multiple versions per day (and, this is not a popular opinion, but you can be a bit sloppy, because applying patch takes no time). If your deployment takes a couple of hours, then your release must be carefully prepared and thoroughly tested (which doubles, if not triples the actual time to go live).

That being said, build step is almost always the shortest. Tests and where the time is consumed. If, for example, build using TypeScript and Webpack takes 5 minutes (using Node), and Fresh is saving these 5 minutes with Deno, great, but not enough to migrate or pick this framework basing solely on this factor.",Javascript
"> are build and deploy times such a big deal for you guys?

Yes. Usually, the faster it is to deploy, the more deploys you can do.

- 1 day to deploy => Deploy every few weeks
- 3 hour to deploy => Deploy every few days
- 30 minutes to deploy => Deploy a few times a day
- 5 minutes to deploy => Deploy every time there's a change.

This also changes the way people code. 

You can afford to spend less time on QA if you know any problem can be reverted in a few minutes, and the fix can be deployed in less than an hour. 

This allows developers to work faster and make more drastic & risky changes.

> And what's the reason it takes longer with other frameworks?

Two reasons I can think of:

1. No `node_modules` folder. Node's package resolution algorithm just does file crawling. Installing and resolving dependencies is sloooooow. It takes considerable amount of time in most CI/CDs. Deno doesn't have this problem.

2. A lot of legacy tooling. A lot of frameworks rely on a mountain of old build tools, that have never been optimized for performance. Builds are slow, because developers expect a lot of features from a lot of slow tools. Fresh just uses ESBuild, which doesn't support many features, but is very fast.

Fresh's performance isn't free. It come with a lot of restrictions about the kind of tooling you can use. If you're okay with these restrictions, then Fresh is a great framework!",Javascript
"Our pipeline takes around 6-60 minutes depending on change size. For us, tests are the longest step. Eliminating the build step would reduce total time to deployment by maybe 20-40% (on the higher end if we can avoid building or using ts-jest for the test suites). Meaningful, but hardly an order of magnitude, and I struggle to think of what kind of project would actually gain that much.",Javascript
"the number of deployments is a good indicator (of several) for software quality. 

Fast deployments are not a feature but a necessity for modern style development in general. You want to push as often and as fast to production as possible, because you want to do the smallest incremental changes you can do to stay fully agile and be able to fail fast forward. 

i recommend „accelerate“ as an excellent read here",Javascript
"Within reason, no not at all. And by that I mean, preparing a release and getting it through the CI pipeline shouldn't take more than, say, half an hour back to back. The shorter the better, but half an hour is really the pain point for me.

Replacing webpack, which might take a minute, with vite, which is maybe twice as fast or even ten times as fast, is not really worthwhile. A somewhat involved webpack config will easily take _days_ to replace properly.",Javascript
"Yes, for my project it takes about 5 minutes locally and 20 minutes on the cloud. It can be a pain to debug something that requires a server restart locally or if theres a bug that only shows up once deployed. 

For example, server side rendering with something like Gatsby will let you get away some things locally that fail once it actually does the SSR. So when this happens for me, I have to wait for the build to fail, fix it, and then redeploy which will probably take around 40 minutes if I'm quick and know exactly how to fix it.",Javascript
"Thanks for writing this. Now when I encounter one of these idiots in the wild I can tell them that even the 2nd most active maintainer of a css-in-js library is ditching it.

Funny thing is - the reasons you gave in the article are the reasons a lot of people haven't even used it - i.e. we knew it was a performance hit from the start.",Javascript
"I'll add that CI/CD pipelines should have a lot of automated validations if it is going to production. I would hope the time to actually build the artifact is low, but there may be multiple layers of tests, security scans, code quality scans, etc. Which IMO is a very good thing as it catches issues early.",Javascript
"In addition to agility with respect to production code, build and deploy times is a major factor in development in at least two scenarios:

1. Iterating on design or UX. You push up your branch / changes, and want to generate some preview environment so that the designer or product person or other collaborating engineer can give you some input. If the build / deploy takes 2 minutes, you can get up, do some stretches, then shoot them a message saying it's up. If it the build / deploy takes 30 minutes, you need to set a mental timer to check (or send them an immediate message and then have them do the mental timer). And now what do you do for 30 min? Beyond the time of the cycle itself, you now have a lot of mental overhead.
2. If whatever you are working on isn't easy to test locally. We've all been there - it's something involving SAML or logging or some external service and the local environment isn't capable of properly reproducing the issue. Now every change requires pushing to some remote env, waiting for that to build, and then checking the logs / output / whatever else. Painful.",Javascript
"If you are working solo and you have a system set up that's easy to iterate on locally, then you don't need to worry about build times.

If you need to deploy your project to see how changes are affecting it, then build time becomes important.

If you work on a large team where many people are deploying changes, then build time becomes a HUGE factor.",Javascript
"It's definitely a big deal for me. Sitting around waiting for this to build is a big waste of time and breaks my concentration.  


When I push changes I'd like it to go through CI and deploy as quickly as possible so that I can move on.",Javascript
"Project Page (?): https://github.com/nickwelp/somjs

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/javascript) if you have any questions or concerns.*",Javascript
"Thanks for sharing your open source project, but it looks like you haven't specified a license.

> When you make a creative work (which includes code), the work is under exclusive copyright by default. Unless you include a license that specifies otherwise, nobody else can use, copy, distribute, or modify your work without being at risk of take-downs, shake-downs, or litigation. Once the work has other contributors (each a copyright holder), “nobody” starts including you.

[choosealicense.com](https://choosealicense.com/) is a great resource to learn about open source software licensing.",Javascript
">It’s a bit unfortunate that we have to use \`swc\` for scripts when we are already using \`esbuild\` for the frontend. However, any \`esbuild\` related solution was much slower in my testing

curious why not swc for all the things instead, it seems to be consistently faster than esbuild",Javascript
"Anyone reading this, please save yourself the time and frustration and don't read this. Here's why you should use hooks to abstract logic instead of HoCs:

- Uni-directional flow of logic makes the code more readable top-down and therefore easier to follow and debug, whereas in HoCs it's backwards.
- HoCs are more difficult to debug and there's an additional point of failure, the surface or glue code you apply when applying the HoC logic to the component.
- HoCs are a bad abstraction, but they really are just higher order functions, so the majority of the downsides are inherited from HoFs. The principle of taking a target object and decorating it with a chain of functions works better in languages that support piping, which helps remove the confusing hierarchical aspect of HoFs.
- Debugging HoFs is a pain. Even if one provides a meaningful `displayName` to every HoC, using 12 hooks in a component has no negative effect on debugging experience, while applying 12 HoCs definitely will.
- It's easy to introduce crippling performance issues with HoCs, which is nicely showcased by this post, where OP (I assume this is a self-promotion, because no person possessing the wherewithal of operating Reddit would be misguided to post this unless fueled by misplaced self-confidence) constructs the HoC decorated components in a render function, which re-created the entire component tree from scratch on every single render of the component inside which this happens.

It's also lazily written, doesn't go much in depth about principles of HoCs or HoFs and their origin and uses in programming, other than React themed /r/programminghorror content. I really hope the author reads this and takes it as constructive criticism, which I intend it to be, if there's one key take-away from all of this, it's that the fact that you've stumbled across something that looks cool or fun, doesn't really warrant an article. Please do some research before posting, especially if you then go on to share it with such a wide audience.

Edit: just for completeness sake, there's 1 thing in React at this very moment that could only be achieved with a HoC and a class component wrapping a function component and that is a functional error boundary component and even that could technically be done by constructing the class based component inside a custom hook and then returning it to wrap the component tree, though that solution is less pragmatic and so I'd say if you *must* handle errors inside a function component for whatever reason and React 42 still doesn't have `useDerivedStateFromError` or something similar HoC is your best bet.",Javascript
"> React has, not so long ago, introduced, in version 16.8, this concept of Hooks to its Functional Components. 

React 16.8 was released in February 2019, i wouldn't call that ""not so long ago"", especially in the JavaScript ecosystem",Javascript
"Typescript tip: Because HOCs require the use of generics, marshalling props into a generated component can result in some crazy type errors.  The following adjustments will help alleviate that.

    import React, { ComponentType, ReactNode } from ""react"";

    // Should be imported from a utility types file.
    export type HOCProps<P> = P &
      JSX.IntrinsicAttributes & { children?: ReactNode };

    const withMyStuff = function <P>(
      Component: ComponentType<P>
    ): ComponentType<P> {
      // HOCProps<P> is essentially <P>, but with all the stuff
      // expected by a fully generic component.
      // In this area, handle static stuff that should _only_ be
      // computed when you define a component using the HOC.
      return Object.assign(
        (hocProps: HOCProps<P>) => {
          // Do render-time stuff - this is where you put hook calls and such,
          // not in the outside function
          return <Component {...hocProps} />;
        },
        // Give the HOC an appropriate name
        { name: `withMyStuff(${Component.name})` }
      );
    };

    export default withMyStuff;",Javascript
"I've transitioned to using Tailwind even though I was a massive fan of Emotion, mostly because I had to follow the trend at my workplace and I did see some benefits when using it. However, I think dismissing CSS-in-JS is misguided. I also think that this article is kind of naive (and even states that they're intentionally using the slower version of declaring styles, which kind of negates their point a bit here).

CSS-in-JS excels at dynamic styling, something that Tailwind can't provide. The Tailwind engine works by looking through all of your files, aggregating Tailwind classes and then creating an optimized CSS stylesheet. This means that CSS-in-JS excels in situations where the styles change rapidly (and potentially even randomly), such as when dealing with user-generated content or when styling interactive content, like resizable panels, etc.

I think that anyone who is clinging onto one framework or the other is woefully misguided and/or just inexperienced. These are all _tools_, and you should use the right tool for the job. Unfortunately, I've found that frontend developers lack in a certain... let's call it, engineering ethos... that will allow them to see past the documentation. 

At one point I had an frontend developer try to convince me HTTP requests made in JSX was going to be the next big thing. Lol... fucking frontend developers man.

Edit: it was this. https://github.com/jamesplease/react-request lol thank the fucking lord I don't work there anymore.",Javascript
"Good read!

You could mention that before strict mode, ""not defined"" was not a thing. You could reference a variable that was never defined, and it would simply create a new variable and add it to the global scope.

That was a massive footgun that made typos in variable names hard to detect, so ""Not defined"" was added to help developers.",Javascript
"The typeof approach is unnecessary and overly verbose when you know the property exists, as is the case in the with function parameters like `function greet(name)`.  These examples would also be better written to make use of default parameters which performs the undefined check automatically for you, reassigning when needed.

    function greet(name = 'Stranger') { 
      // ...

Additionally, typeof fails to handle checks in the TDZ of lexical declarations.

    console.log(typeof myNoVar) // undefined
    console.log(typeof myNoVarYet) // Error
    let myNoVarYet

Ideally, you should always be aware of what variables are in scope and never need to use `typeof` to check for existence.  Those you do have access to which may or may not be defined can be checked with a simple `=== undefined`.",Javascript
"Undefined is a very special keyword in JS and undefined != Not defined. 
Undefined    : a variable is declared , it has its own placeholder but not  having the value of itself 'defined' hence undefined and until th variable has assigned a value , the undefined fills tht perticular placeholder.
 
'Not defined '      : this case comes in error where Js engine neither find that particular variable nor its placeholder and cannot find the variable in first phase of context (memory allocation context)",Javascript
"Hi everybody, in this article I write about the difference of undeclared vs. unassigned variables in JavaScript. The article goes into detail on the in-built `undefined` type and `ReferenceError` exceptions. In the end, the text will layout an easy way to check if your variables will be safe to use.

Feel free to drop your thoughts in the comments :)",Javascript
"I am really looking forward to this being widely supported and/or well supported by tools. Chrome/Chromium supports it, now WebKit does, and Firefox has experimental support. I think I read that deno has support and something about node as well.",Javascript
"Thanks for sharing your open source project, but it looks like you haven't specified a license.

> When you make a creative work (which includes code), the work is under exclusive copyright by default. Unless you include a license that specifies otherwise, nobody else can use, copy, distribute, or modify your work without being at risk of take-downs, shake-downs, or litigation. Once the work has other contributors (each a copyright holder), “nobody” starts including you.

[choosealicense.com](https://choosealicense.com/) is a great resource to learn about open source software licensing.",Javascript
"i wrote this to scratch an itch. apparently others had the same itch.

https://leeoniya.github.io/uFuzzy/demos/compare.html?libs=uFuzzy&search=super%20ma

(there's a 4MB text file, give it a second for initial download)

i'll cross-link to HN here, where a pretty extensive discussion happened a couple days ago. a lot more example links in there. please read through it before asking already-answered questions :) https://news.ycombinator.com/item?id=33035580

i added support for single substitutions, transpositions, or deletions yesterday, which was probably the main point of contention in that thread:

https://leeoniya.github.io/uFuzzy/demos/compare.html?libs=uFuzzy&intraTrn=1&intraSub=1&search=super%20maet%20boy

(there are no visible toggles for these options in the demo yet; they can only be enabled via url params)

any pre-1.0 feedback appreciated!",Javascript
"Would be interested to see  [js-search](https://www.npmjs.com/package/js-search) in the comparison table, as it's my go-to for client side fuzzy searching (due to good performance, small bundle size, and easy to use API).",Javascript
"[https://leeoniya.github.io/uFuzzy/demos/compare.html?libs=uFuzzy,fuzzysort,QuickScore,Fuse&search=TMNT](https://leeoniya.github.io/uFuzzy/demos/compare.html?libs=uFuzzy,fuzzysort,QuickScore,Fuse&search=TMNT)

A bit unfortunate abbreviations don't work. Only fuzzysort worked for this query",Javascript
"Hey all :) If you're a Frontend dev who wondered what magic happens behind the scenes of state management libraries for SPA frameworks, this article is for you! The examples are based on the React ecosystem, but there are lessons to be learned for everyone!  


I hope you find this useful, and all feedback is appreciated :)",Javascript
I’ve been thinking about getting off of css in js because I can just create my own components. But one thing I really appreciate are the vendor prefixes. You have a solution I can use for vendor prefixing?,Javascript
">	The great thing about state management libraries is that only the relevant components will be re-rendered once the state is modified. This is in contrast to the Context API, where any update will result in the whole sub-tree – starting from the Context Provider – being re-rendered.

But this is *not* what happens? 

Only the sub-tree from the Context Subscriber actually re-renders, everything else does not as long as your Provider isn’t explicitly a parent. 

Extract your Provider and state management in a component, that subsequently wrap the application slice (by using the *children* prop); your component (and context, and states etc.) **do** rerender, but React **will not** rerender *children* as the prop isn’t changed

So cool infographic but it’s wrong

I know, everyone gets it wrong all the times …

EDIT: https://codesandbox.io/s/compassionate-wave-6yzs1w?file=/src/App.js

At least downvote me when I'm wrong",Javascript
"I just did, actually. I still need to write up a proper documentation for it, file down some edges but here's a minesweeper clone using it. https://alexaegis.github.io/svelte-minesweeper/

If you click on enable debug mode it loads the redux-devtools plugin (lazily!) and state logging.",Javascript
"Still remember that fun transition from JS to TS at a start-up I was at, when we converted our first common library by setting every type to `any` and giving ourselves a pat on the back. Learnt a few things since then.",Javascript
"The linked first blog post is also worth a read. It's amazing how consistent it is with how things worked out 10 years later.

https://web.archive.org/web/20121003001910/https://blogs.msdn.com/b/somasegar/archive/2012/10/01/typescript-javascript-development-at-application-scale.aspx",Javascript
"TS is probably the biggest improvement for webdev since jQuery. But as its a language of its own, it will be around for much longer than jQuery did. I never felt confident with untyped languges, so for me TS is a musthave for any project. Good times!",Javascript
"I’m sure I’ll get downvoted for this, but TypeScript is useless on the front end. There is some value to it when doing server side code. On the front end, I prefer React PropTypes. I have over 10 years of development experience. I started using TS about a year ago when I switched jobs because that is what the company forces everyone to use. I’m slower when writing with TS, I don’t see a difference in the number of bugs, and TS errors are often very cryptic.",Javascript
"Are some features paywalled? Years ago I wrote my own auth server for my home apps, and I've been wanting to replace it with something official (for obvious reasons). I looked at Fusion auth but client credentials is paywalled there. So I'm just curious about your product here.",Javascript
"Can Logto connect to an Identity Provider, using SAML?

If not, would it be possible with a proper plugin?

I want to connect a React app with an old SAML Identity Provider and I'm looking for solutions.",Javascript
"Built a tool that brings Git in the browser via WebAssembly. To create, upload, edit (multiple) local files... in different branches on the fly in the browser.

Repo: [https://github.com/thomscoder/harmony](https://github.com/thomscoder/harmony)

I'm almost done with a complete UI refactor (to drastically improve mobile experience).",Javascript
"**Open source local web development studio**

Hi, DECK is built with electron, node & svelte. It lets you create multiple development environments using an intuitive GUI. Feel free to browse thru the source code or try out the app itself. Thank you

https://github.com/sfx101/deck",Javascript
"DX > Perfomance  


Unless youre building something very complex like photoshop for the web, the performance loss, is little to the DX gained and type support. I wrote CSS for many years (over 12 years now) and JSS is the future for sure imo.",Javascript
"I lost internet at my house and couldn't make a react app, so I tried to code a react-like page using components with just HTML, CSS and JS. Worked out pretty well, they all just get appended to one root div. 

https://bmbaron.github.io/dino-page

Note: I'm a beginner and just making stuff for fun",Javascript
"I have nothing to show off really, but I'm very happy that I recently finished a tic tac toe exercise where I use the minimax function with alpha beta pruning. so far the toughest nut to crack for me. :)",Javascript
"I don't know if this is the right place to ask for help. I just finished coding my first game project using HTML, CSS and JavaScript . I don't know yet the steps to publish  it in the stores.  

What's the next step?? Do we have to use Android studio? Or there is simple way? 

I find Android Studio a bit hard.",Javascript
"> If you use && for conditional rendering, you’re gonna have a bad time with numbers because 0 is truthy in JavaScript. 

No. `0` is ""falsey"". 

`0 && <p>Foo</p>` is an expression. Expressions must return a value (else they'd be statements). Not sure what the spec states but in boolean expressions the ending part of the expression, i.e., the part that caused evaluation to cease, is returned: 

```
> 1 && true && 999999999
999999999
> 1 && 0 && 1
0
> 1 && null && 1
null
> false && null && 1
false
```",Javascript
"41.  Can anyone link me to the overly spreading is bad in the docs?  

Our UI is heavily tied to the backend and I found that by spreading the object, if the backend added new functionality we could just update the component itself, not adding a prop and updating every instance to include the prop.",Javascript
"You could write npm package that solves human mortality problem and I would still hate that extra number added to total npm package list.

Maybe this is bad but this is the way I am now. I can't help but hate node_modules and npm all together. I fucking hate Javascript ecosystem. Sorry, not sorry.

This has nothing to do with this package you shared, I just had to rant a bit.",Javascript
"Thanks for sharing your open source project, but it looks like you haven't specified a license.

> When you make a creative work (which includes code), the work is under exclusive copyright by default. Unless you include a license that specifies otherwise, nobody else can use, copy, distribute, or modify your work without being at risk of take-downs, shake-downs, or litigation. Once the work has other contributors (each a copyright holder), “nobody” starts including you.

[choosealicense.com](https://choosealicense.com/) is a great resource to learn about open source software licensing.",Javascript
"The main idea is to simplify (and speed up) the process of building web applications in Deno with stackable middlewares over a handler - this is represented as \``Pipeline`\` i.e. \``[...Middleware[], Handler]`\` where \``Middleware`\` is just \``Handler => Handler`\`

The end result is a handler composed (or folded) from these middlewares than can be directly passed to Deno's built-in \``serve`\` function.

Let me know your questions!",Javascript
"Seems like it's just more of a general thing about having arguments make sense what they do in a function, not so much about boolean arguments. I mean...

```
function doThing(opt) {
  switch (opt) {
    case: 'a'
    // Do something
    case 'b':
      // Do something else
  }
}
```

Is just as true.",Javascript
"The ""drilling"" argument can apply to any kind of variable, especially when dealing with prop-passing Components. It doesn't seem specific to booleans, and the solution for a series of prop-drilled components would not be to ""avoid booleans"", but to push the state further up the tree with Context, perhaps.

Another situation I can think of might be adding props to API calls where there are several layers before the actual end-point is hit -- sagas, mocking, sanitisation, etc. Still, if an object is used and the schema isn't changed for changes sake between laters, then this seems like a bit of a non-issue? Perhaps I've got the wrong end of the stick?

But I'd agree with some of the smaller points. Actually, I was rather wondering if the argument you were going to make was like this:

    function toggle(force) {
      if (force !== undefined) {
        // ...
      } else {
        // ...
      }
    }

    // Versus:

    function turnOn() { ... }
    function turnOff() { ... }
    function toggleOnOrOff() { ... }

I think that's some of your point? Nice clear single-use functions with names that indicate what they do without hiding stuff behind mystery booleans.",Javascript
"I have two pieces of advice here:

1) Try thinking of tests as more of a reassurance that your code still works in the future. If you need to change a piece of code, your tests will help you feel confident that your changes did not break anything else relying on that code. If you think of it this way, writing tests feels a lot less like just “getting proof something works”. 

2) Try writing your tests before you write your code (or at least plan what tests you’re going to write). This can help you plan for edge cases, error states etc ahead of time which I find leads to cleaner, pure code.",Javascript
"This has a lot of similarities to component composition and ""prop passing"" in view libs such as React.  


The deeper point about structuring your code such that it is easy to recompose a similar but different function for each flag (or composition of flags?) is worth further exploration.  


One add-on that is worth mentioning is that you can structure functions in a way that defers execution logic to the caller, via a variety of approaches (directly passing in CBs or interfaces, passing in declarative ""strategies"" as an enum that then maps out to a particular fn).",Javascript
"If a function does exactly the opposite when false is passed of what it does when true is passed, then I’d say it’s fine. The function‘s name should be kind of a yes or no question.
„Setters“ are good examples.

someElement.isVisible(true)
User.isAdmin(false)
someErrorMessage.canBeIgnored(true) // :-P",Javascript
"Seems to me like the problem with a function like this could have been made a lot more obvious by naming it correctly in the first place. Instead of doThis it should have been called doThisOrThat. Now it's immediately obvious that it should be two functions: doThis and doThat. Once that is understood, the premise of the article basically evaporates. Not to mention that the example in question only seems to produce side effects. Kinda gross.

The other thing I note is that the author only seems to consider booleans as flags, which seems simplistic. What if we wanted to implement a logical function that doesn't exist natively in JavaScript, eg NAND? Contrived, maybe, but completely legit.",Javascript
"We support anything with 2% global usage, plus the 2 latest versions of Chrome, Firefox, and Safari (though they are typically no added work compared to the first part). Very little attention for anyone with JavaScript disabled.",Javascript
In JavaScript we polyfill with Babel set to support MS Edge due to a lot of customers still using older Windows devices. CSS is not polyfilled as long as the site remains usable. A few glitches on an ageing laptop can be tolerated.,Javascript
"We stopped supporting IE < 11 in 2020 and IE in general early this year. We used to have a surprising number of IE users during workdays (2% I think, falling to 0.5% on the weekend :D)

Edit: to more properly answer the question, we use our server logs to see what we need to support.

Edit2: while it was not linked anymore, I actually only deleted the ie7.css compatibility file we used with conditional comments a few days ago ;)",Javascript
"We polyfill everything necessary for every browser.

We have a custom library that basically:

- has a db of user agents
- if agent is not detected, or has < 10 hits we send a script to detect necessary polyfills
- once that’s loaded we bundle the polyfills and send them
- then load the actual site code (fetched before this)

For unknown browsers that means there’s a short delay, but for 99.x% of page loads we just send the appropriate bundle",Javascript
"I'm not saying it. but — My company recommends us to block every single \`user-agent\` that is not google chrome or chromium based browser.

Its all up to the userbase, and in our case we force them to install latest chrome, otherwise, no way to even sign in.",Javascript
"As a web outsider, something I’ve never understood is why the server doesn’t use the User-Agent header to just serve whatever poly fills are needed for any given browser?  It is an unbelievable feat of engineering that the web has developed the technology to compile JS to multiple backwards compatible targets, yet the entire industry basically throws away this superpower by targeting only a single build.  I just don’t get it.",Javascript
"Depends on how handy the feature is and how many users we lose. We use all tracked in Belgium/Netherlands to measure, which is a lot more modern than globally.
Currently https://caniuse.com/css-math-functions is pretty much our baseline, which is around 98% of our general target audience. To support more than that requires exponentially more polyfills",Javascript
"The server could be running (and talking to the database) in any language - not just JavaScript. E.g. in all the work I do, our web pages are calling a server (you can call it “querying”, but I don’t think if it that way) the server is running c# that’s running a whole bunch of logic and “querying” a sql server. The web sever might make 10 or more calls to the sql server (or to multiple sql servers) then it manipulates and combines the data in various ways before eventually returning the result as a JSON response.

This is very very common, and, as mentioned, the internals are usually opaque for security reasons.",Javascript
"There hundred of schools of thought regarding testing. Honestly, in my experience 100% coverage and what you seek aka complete proof the code works as indented is nigh impossible to achieve(of course, depending on the code/project complexity). The way I approach testing is just to lay down an inital contract of what the piece of code is expected to do, as things progress you will probably uncover more cases as bugs are found and these new behaviors should be added to the test suite. What I mean is, testing in my opinion is a way to assure the code stays delivering the same result as it evolves during the project lifecycle to avoid regression.",Javascript
"Thanks for sharing your open source project, but it looks like you haven't specified a license.

> When you make a creative work (which includes code), the work is under exclusive copyright by default. Unless you include a license that specifies otherwise, nobody else can use, copy, distribute, or modify your work without being at risk of take-downs, shake-downs, or litigation. Once the work has other contributors (each a copyright holder), “nobody” starts including you.

[choosealicense.com](https://choosealicense.com/) is a great resource to learn about open source software licensing.",Javascript
"It's a stripped down `fetch()` that supports barely any options with simplistic error handling. Also, only useful for JSON and doesn't check Content-Type as I recall.

You'd be better off just using `fetch()`.",Javascript
"Hello, I hope you find this short article useful to improve efficiency when making many api calls that require the same type of structure. Feel free to leave feedback on how you would improve this fetch wrapper",Javascript
"[EDIT]

I already got as many answers as needed, so the survey is down by now. 

I'll move on with the research now. After completing the analysis I'll be back with the results.

Thank you all for participating in this, I'm deeply grateful for your help.




[ORIGINAL POST]

Dear community,

I am a student at the [University of Brasilia (BRAZIL)](https://international.unb.br/) and I'm conducting a survey as part of my undergraduate final paper. The research is about coding patterns in JavaScript that might be confusing to read, understand and predict their results (inspired by a similar work that was conducted using C as the reference language, called [Atoms of Confusion](http://atomsofconfusion.com/publications.html)).

With this research, I'm interested in understanding whether certain constructs, allowed by the language, make the code harder to understand. So, I'm surveying programmers of different experience levels and showing them small code snippets in JS. For each code snippet, there is a similar version of it without the specific construct which could be a source of confusion. I'm going to measure whether the answers are correct or not, in the expectation that the confusing versions will lead to more incorrect answers.

After having collected a significant enough sample, I'm going to rank the code snippets from most confusing to least confusing.

The survey contains 12 questions in which you are required to predict the output of the program. It requires only basic JavaScript knowledge if any. No question is longer than 15 lines of significant code, meaning the survey is designed to take a short amount of time.

A couple of years ago some colleagues of mine conducted a similar survey and also asked for your help here in this Reddit community, so, if you have been here for a longer period of time, this might not be the first time you see this. At that time, some suggestions were made for the sake of the survey improvement, and they were addressed in this new version. I'm also investigating new code patterns this time. If you are interested in seeing the first discussion, you can find it [here](https://www.reddit.com/r/javascript/comments/bw36h6/academic_research_on_confusing_code_on_javascript/?utm_source=share&utm_medium=ios_app&utm_name=iossmf).

The data collected in this survey will only be used for the purposes of the survey and the research being conducted. Some demographic info (email, age, degree level, and years of experience) is requested for participating in the survey. Considering that no one of them can identify you but your email, this one info is optional.

Thank you very much in advance for helping me out.



[EDIT 1]
First of all, thanks for contributing!

As this is a point for almost every participant that made a comment bellow, I’ll make this answer general:

Indeed, that is a misunderstanding about the presence or absence of quotes/spaces/commas in the answer. This might be leading to frustrations when your know your an",Javascript
"I wasn't expecting more confusing stuff xD

The formating of the answer is a bit strange around quoting, we don't know what is expected in terms of quotes. But I guess you can rework the answers to avoid false positives",Javascript
"You're going to have to add some improved parsing of the results. Most of my answers were marked as wrong, because the examples would, for instance, `console.log(""true"")`, while the answer would expect a bare word. Or the absense/presence of commas between values. Those are implementation details of `console.log` in a browser, and shouldn't have any relevance to the actual research.",Javascript
Got a lot of wrongs because I use commas in output which was not allowed. String comparison is not a good idea to verify that the output was correct. To compare the output you need to create a better parser I would use regular expressions and make commas and quotes optional.,Javascript
"It's weird they expect ""true"" without quotes where it's not a boolean but a string as they print it by \`console.log('true');\`. Just because I wrapped my ""true""s with quotes, I got 4 of them wrong. :)",Javascript
"As others have noted there are some issues with the answers because many of them depend on how `console.log` things.  For example, in question 5 the expected answer is `P1 [1, 2, 3]` but Chrome (V8) prints `P1 [ 1, 2, 3 ]` while Safari (jsc) prints `p1 – [1, 2, 3] (3)`.  It might be better to structure the quiz in a way that does not depend parts of JavaScript (such as `console`) that are not part of the ECMAScript standard.

All this pales in comparison to the biggest issues, however, which is that all these programs define a function `f` but never call it, and so will not generate any output at all.",Javascript
"Holy cow, this is undersold. This looks like a fairly comprehensive book on the fundamentals of node.js. I haven't read a lot of it, but you should be quite proud of this and imo rename it to be more general. I'm thinking about sending this to members of my team to onboard them to node. I was _not_ expecting this level of depth.",Javascript
"Here are some things that did it for me
1. Quote: ""If you're going to console.log you might as well write a test, it's the same thing but faster""
2. Quote: ""If it doesn't have a test it doesn't exist""
3. The entire section on code contracts in pragmatic programmer. Between having typesafe code or unit/acceptance tests it gets ya there.
4. TDD/BDD - the simplified concept is you writing a feature that does one thing, write down what feature you're trying to make, get your app into that state via code and test the 1 incremental thing you're doing.

At this point I find it easier to just write unit tests and fix unit tests than it is to crack open a browser navigate for 1 minute to iterate on something simple. Also it just helps me think about what can go wrong.

If you're talking about manual testing - then the thing I'd say is - ya you gotta do it. The craft is not just writing code or designing systems - the craft is making awesome products that make users happy.

Oh last note - it's ok to just not bother with certain classes of tests like pure UI code.",Javascript
"What do you use this for? To build any sort of in-app search, e.g. I am using it to allow log filtering in [@roarr/cli](https://github.com/gajus/roarr-cli). I have also seen it used as a document search in [notesnook](https://github.com/streetwriters/notesnook) open-source note-taking app.

As far as I know, this is the most complete project in JavaScript ecosystem that performs parsing and serialization of Lucene-like syntax.",Javascript
"If someone is looking to contribute, I would really appreciate someone taking over this issue.

https://github.com/gajus/liqe/issues/1

It is not a particularly hard issue to solve but requires an understanding of Nearley.",Javascript
"Damn! At first I was looking at this sort of absent-mindedly, thinking it was one of those projects in an area I have nothing to do with. But then I realized what this actually is and that it's basically just what I need for my next project (note taking app for which powerful search is a priority). Didn't even consider that there would be libraries for this, thought at first that I'd have to write my own DSL. Looks really cool, thank you for making this!",Javascript
"I've not encountered any convention.  Just as functions can return new objects built from a template, and Object create() can return new objects with a given prototype, I've not seen any feeling that lacking ""new"" matters all that much.",Javascript
"It's a factory function that creates an object, so I think `createPerson()` is a good fit.

The only reason I can see to for something else is if you want to distinguish between these Crockford factory functions and other factory functions, but I think that would be overdoing it.

Just `Person()` without `new` also feels strange to me. In Java there is a naming convention that would make it `newPerson()`, but just keep it simple and stick with `createPerson()` :)",Javascript
"That's what's so confusing about JS is the number of frameworks. Seems like frontend masters has more cheerleading presentations on why learning (hot new js framework #10) will make your life easier, than they post about learning JavaScript. Frameworks are spammed so much that people question if they should even learn the language first before learning a framework. No other language has that problem",Javascript
"Thanks for sharing your open source project, but it looks like you haven't specified a license.

> When you make a creative work (which includes code), the work is under exclusive copyright by default. Unless you include a license that specifies otherwise, nobody else can use, copy, distribute, or modify your work without being at risk of take-downs, shake-downs, or litigation. Once the work has other contributors (each a copyright holder), “nobody” starts including you.

[choosealicense.com](https://choosealicense.com/) is a great resource to learn about open source software licensing.",Javascript
"Thank you for what you are doing!  
I've used strapi before and I think, that their documentation and permission setup (which is stored in database) is terrible.  


I would love to see your project compared to KeystoneJS. As it really is your only competitor.",Javascript
"Hey r/javascript, here's a quick disclaimer:

Clearly I'm associated with Payload so at first pass you might think that this is a bit biased, but we really did our best to make sure that this test was as scientific and as head-to-head as possible. You can download the code for each test and run it yourself, on your own machine. We were doing this for internal research purposes but then figured that the results, the testing process, and the overall seeding workflow comparisons between the three platforms would be interesting to others.

In a big way, I attribute our performance to having solved the [GraphQL N+1 problem](https://medium.com/the-marcy-lab-school/what-is-the-n-1-problem-in-graphql-dd4921cb3c1a). In any case, the results are pretty fascinating.

Would love to know what you think!",Javascript
"i like the style of the article and the nature of reddit comments made by the employee. it is exemplary on how to interact with the dev community. 

it is honestly so good to see people are getting better at the communication part.

also give the guy/team a raise or smth",Javascript
"IMO your type system (I assume Typescript) should not be use to narrow integers output to range or you will just move the complexity from one place to another. What should bring confidence to your tests suite is splitting your code into small functions (pure, doing only one thing...) easier to reason about and the code coverage which should be generated by your test runner and show you if every branches and statements of your code is tested.",Javascript
"An interesting idea. I like the thought of being able to navigate from a DOM element directly to the line of code that generates it for editing, but I think I'd want it to just open that file for me in VS Code directly.",Javascript
"Really promising tool, but I couldn't get it to work in a project I'm working on with vite due to lots of errors regarding the usage of BigInt by the lib. Tried to change the target to es2020 as it was the most suggested solution, but no success. I'll keep an eye on it.",Javascript
"Yes, finally! Only four years after Chrome.

My next project will finally be able to use it. It should be a major performance improvement, because the render thread no longer has to block the UI thread.",Javascript
"> However, when one Worker explicitly sends a request to another Worker, the destination Worker actually runs in the same thread with zero latency. So, it performs more like a function call.

Ok I never knew about this Cloudflare worker feature so I had to look it up. It's called Service environments.

> We have temporarily disabled the creation of Service Environments while we are improving this feature.

So is this a feature that's still in the works Or can this be done currently in workers?",Javascript
"If you have a better server setup , you can use queues easily to trigger such events. For e.g. with every action push one message into SQS  from your server and consume it with lambda or own server to fire mails for given event. 
Each event will have some mail template ID attached to it. 
You can set up local queues also.

DB can also be used for such events, a cron can be scheduled which fethes the data and processes then Evey 10 minutes or so. This fetching process can be based on a column entry to what stage the user is in right now. 

For anything to work in your system user flow has to be very well defined and tracked too.",Javascript
"https://github.com/mautic/mautic is one open source entry. It's pretty robust (full disclosure, I haven't used it in 3+ years). It's a php app that runs independently of your application and has an embeddable js that makes the connection (a lot like google analytics, etc).",Javascript
"Sounds like a basic service that collects a list of users from the DB with certain `WHERE` conditions. You schedule a setTimeout timer for each of them or until just one set to when the next candidate is available. When it fires, send the emails. (Maybe even ""lock"" the DB records, though you're not supposed to use the DB as a queue system.)

I do something similar for a reservation system in NodeJS:

    if (checkReservationsTimer) {
      clearTimeout(checkReservationsTimer);
      checkReservationsTimer = null;
    }
    if (nextWatch) {
      let timeUntilNextWatch = nextWatch.getTime() - now.getTime();
      if (timeUntilNextWatch > 0x7F_FF_FF_FF) {
        timeUntilNextWatch = 0x7F_FF_FF_FF;
      }
      checkReservationsTimer = setTimeout(checkReservations, timeUntilNextWatch);
      console.log('Checking reservations in', timeUntilNextWatch, 'ms');
    }

Only caveat is you can't setTimeout for more than `0x7F_FF_FF_FF`, so I set it to that and let it loop. My use cases are more ""to the millisecond"", which doesn't sound so critical as email, but you remove any timer based DB polling and stay all in JS.",Javascript
"I paid for 1 month on a whim. Ive been enjoying it so far. There’s some fairly standard algorithm-style problems, general front end trivia, and some good vanilla HTML + JS + CSS prompts (create a re-usable star rating component with specific requirements).",Javascript
"If your curious to learn more about the four colour theorem check out the Numberphile  video. It was the first math proof using a computer!

[https://www.youtube.com/watch?v=NgbK43jB4rQ](https://www.youtube.com/watch?v=NgbK43jB4rQ)",Javascript
"Generally speaking, ESM is explicit whereas CJS is implicit. 

Explicit has issues requiring more characters, but it's much easier to tree-shake ESM than CJS because of the way exports work. CJS fully depends on the backend that's doing the module resolution. ""node"" is the popular one, but it's not bulletproof. ""node"" actually travels the file system and tries multiple files which makes it a real pain to try to handle each possibility. That means it fully depends on navigating the file system in question. CJS is either `${name}`|`${name}.js`|`${name}/index.js`. And that makes little sense in the browser context because HTTP servers don't normally remap URLs to `./index.js`. They map to `./index.html`.  

Because it's implicit, CJS creates a bunch of resolution issues with Typescript, to the point where if you want to code for the browser, you can't easily can't and have to either recompile with something like webpack to rewrite the module resolution, or [add `.js` to all your TS imports](https://github.com/microsoft/TypeScript/issues/42151), which already looks weird (you'd think you're importing the `.ts` files). [sip.js](https://github.com/onsip/SIP.js/issues/905) has that issue.

CJS was needed because we had little options before, but now with ESM the vagueness and issues related to it are cleaned up. It also technically opens up future cases of non-filesystem specific imports (eg: `import https://`). You can also create browser/node compatible imports because they're URLs `await import(new URL('node:fs'))` and handle any errors with runtime code and not depend on recompilers/bundlers.",Javascript
"> The point of testing though seems to be that I discover where my assumptions went wrong. So how am I supposed to know what tests I need to write?

Maybe look at the perspective that the point of testing is to capture things you don't want to break in the future.

You might have intimate knowledge of the ins and outs of your code today... But in a week or few months that knowledge will have gaps. Untested code is very easy to unintentionally break, *especially* when you include multiple developers in a single code base.",Javascript
"IMHO the only con worth of mentioning is that ESM modules are async. And is a big con unfortunately.

Code is code and MUST be there or the whole program should abort. Asynchronously loading modules means that the code could be present or not or be in a forever “loading” state depending on a resolution of a promise. In practice it’s the Schrödinger's code.

I think that’s a terrible idea: it makes hard to conditionally load modules, it makes even harder to lazy-load code.

Top-level await is not the feature you can’t live without and import from remote position is definitely the feature you can live without.

I really wonder who thought that `import xyz from “https://…”` was a good idea: network is the most unreliable place to load the code from; even golang which loads modules directly from github downloads them before compiling.",Javascript
"I very much prefer something that works in both browser and in node, so I am entirely in favor of esm. 

Why are you against async loading of dynamic imports? I see that as a benefit. Anything touching the filesystem or network should be async. 

How can you say that including the extension seems oddly unnecessary just before saying you understand the reason? That doesn't make sense. But importmaps should solve this anyways. 

In which way is esm slower? I've never checked this but don't get that impression. 

Yeah, a lot of things are sadly behind. It's frustrating.

I say node should deprecate cjs and exclusively use esm. That'll mean all work on imports is just on esm, presumedly improving things. Libraries and frameworks will have to support esm.",Javascript
"I find Node ESM to be significantly faster than CJS (anecdotally). I assumed this was due to the ability of asynchronous importing vs static w/ \`require()\`. Why do you say it's slower?

ESM was designed with input from Node, even though they claim their feedback was not totally accepted. IMO this has caused animosity from the Node crowd towards ESM, and caused it to take forever to land support in core, plus mjs... That said, it's here now and we can respect the effort that went in, given how well it works.

It's only harder to mock right now since the tooling isn't mainstream yet for it. I suspect a loader will easily take care of this problem.

Same for extension-less loading, I wrote a loader for this: [https://github.com/tbranyen/extless-loader](https://github.com/tbranyen/extless-loader). Perhaps it will be an option in the future.

Agreed with tooling not fully supporting it yet, thankfully you can import CJS from ESM.",Javascript
"Node relies on standard JS. CommonJS is not a standard. Are you suggesting that Node picks and chooses what part of the ESM standard it supports? That would be disastrous.

Anyone who wants to go with a runtime that is moving forward with JS and the web I suggest you check out Deno. Its support of import maps removes the pain of long import URLs.",Javascript
"Cons:

 - absolute imports don't work as expected on windows

 - they still haven't figured out cache busting (for reloading changed files during dev)

- slightly worse readability (package.func() is very clear. ""func()"" doesn't help you understand where it's imported from so you have to look at the top of the file to see that it's from ""import func from 'package'"")",Javascript
">Hard to mock

I have found that loaders make it much easier to use mocks (especially if the whole project is in ESM).

>Harder to conditionally import (you have to be async)

In some rare cases, yes. Top level await makes it easier to work with dynamic imports.

>Is slower

The ESM loader needs some performance improvements, but it should be faster than the CommonJS loader for most projects. Both loaders do massive amounts of (synchronous) I/O.

>You have to write the .js extension in import paths,

You can use the commandline --experimental-specifier-resolution=node to allow node to figure out extensions.

>A lot of major tools/libraries/frameworks don't support it well unless you sacrifice a virgin goat on a blood moon

Is this an ESM problem? No doubt there are tooling issues related to node packages. I believe the problem is due to incrementally adding ESM features and tooling assumptions of ECMA versions.

I don't feel the problem is with ESM or CJS, but the decision by node to support two package systems. On top of that, there is a lot of confusion about where node is heading in this area. The result is package creators doing the following:

* CJS must be deprecate, so I will publish only ESM
* I don't want to support two package system, so I will publish the lowest common denominator: CJS
* I will support both, but my library is published as CJS with a thin ESM interface file (a nightmare for tooling).
* I will publish with independent CJS and ESM modules. Risk an instance in CJS and ESM loaders.. and another nightmare for tooling.",Javascript
"> Hard to mock

I think this is a feature, kind of! Immutable modules are nice.

> Is slower

This is interesting to me. Is there some benchmarks I can run? Hadn't heard of this before.

> You have to write the .js extension in import paths, which seems oddly unnecessary, although I understand the reason why. But it's especially absurd with Typescript where you're specifying an extension that's different than the actual one (.ts, not .js)

This was one of the biggest lessons learned from Node.js - the author regrets ""no extensions"", since it massively complicates tooling. From a user perspective, I don't think writing an extension is really a poor experience, is it?

I agree moving from CJS to ESM is very difficult for any non trivial code base. I don't have a preference w.r.t syntax, but I really like the idea of ""one module system"", and ESM is what browsers use, so happy to just deal with it for the sake of consistency.",Javascript
"> Better static analysis. ... I don't see how it applies to node.

Imagine you have a CJS module with 10 `require` statements at the top. Node must go to the filesystem to find the first `require`d module, load it, parse it and execute it, all before going to the filesystem again to find the second module. Rinse and repeat each module. This manifests as long boot times.

With ESM, finding, loading and parsing the 10 modules can happen in parallel, then execution happens serially.

> Harder to conditionally import (you have to be async)

Unless you are writing ""shell"" scripts I don't see how blocking the event loop while reading the filesystem is a good idea.

And Node has top-level await now.

> Hot reloading doesn't work without major hacks in ESM

Is hot reloading in Node a thing? Am I out of the loop?

> But it's especially absurd with Typescript where you're specifying an extension that's different than the actual one (.ts, not .js)

Yes that is basically the one thing that is keeping me from just using Node ESM in my company.",Javascript
"For a CTO…RN.  Dart is not a well known language and you will not be able to hire cost effectively.  For a junior Dev… learn RN because it’s more universally applicable.  Once you have RN and are a bit more senior, then maybe do a side project in Dart so you have enough experience to jump in or add it to your resume.",Javascript
"Flutter is much better to work with. If you know typescript you can figure out dart in a hour or so enough to start developing with it and google by your side. The performance really is definitely better both when developing and in production. React native is still good, but tracking down performance problems can be a nightmare.",Javascript
"My little 2 cents for knowing what tests to write: think of edge cases or border conditions like zero, beginning, end, small, large, random and write tests for those. 

If your code has fail conditions, write some tests that trigger those fail points.",Javascript
"Were you thinking of improving your JavaScript applications’ performance? [Join Dmytro Mezhenskyi](https://register.gotowebinar.com/register/347587937260509964?utm_source=PressRelease&utm_medium=Leads%20Acquisition&utm_content=webinar0922), Developer Expert of [Decoded Frontend](https://www.youtube.com/c/DecodedFrontend), on **September 30, 2022 — at 11 AM CT**, and learn about various optimization techniques you can use to speed up your apps.

## The webinar will cover a wide range of topics, including:

- Web graphic optimizations
- Network optimizations
- Page loading
- JavaScript runtime optimizations
- Tools to measure performance
- Team performance

Because of its broad scope, optimizing applications can be challenging even for experienced developers.

Developers spend a lot of time improving the performance of their apps due to heavy research that sometimes leads to more confusion.

Learning about optimization might be overwhelming for some, but you don’t have to scour the internet and collate all the necessary information.

Dmytro has gathered some practical strategies to help you keep your JavaScript applications in their best shape.

The webinar aims to let you discover the different ways you can speed up your apps in a clear and organized manner.

Maintaining applications can be exhausting enough. Enhancing their performance for the experience users will enjoy doesn’t have to be complicated. This webinar is brought to you by [Filestack](https://www.filestack.com/).

Are you interested? [Click here](https://register.gotowebinar.com/register/347587937260509964?utm_source=PressRelease&utm_medium=Leads%20Acquisition&utm_content=webinar0922) to register now; see you there!",Javascript
"Please, never do this:

```
let canVibrate = false;
if('vibrate' in navigator)
  canVibrate = true;
```

If you are assigning a Boolean value in one case, and the opposite in another, just use your conditional (or the negation of it). 

```
const canVibrate = ‘vibrate’ in navigator
```",Javascript
"    let canVibrate = false;
    if('vibrate' in navigator)
      canVibrate = true;

`let` instead of `const`.  Using a conditional to flip a boolean (tell me you're a shitty programmer without saying it out loud).  It should be:

    const canVibrate = 'vibrate' in navigator;

> In fact, just calling navigator.vibrate() when the user is on an Apple iPhone causes the entire program to freeze.

Er.  If it's a TypeError, you can just monkey-patch, and not wrap all your calls in conditionals.  e.g.,

    navigator.vibrate = navigator.vibrate ?? (() => {});

Meanwhile, my desktop Chrome has a `navigator.vibrate` property that is a native function - so how do I detect if `navigator.vibrate([...])` will actually do something?  Because if it won't maybe I want to play a short, bassy noise and/or shake the screen instead?

[The answer](https://developer.mozilla.org/en-US/docs/Web/API/Navigator/vibrate): ""If the method was unable to vibrate because of invalid parameters, it will return false, else it returns true.""

Desktop Chrome / Chromium correctly returns `false`, because any parameters when there's no vibration motor are invalid. [Edit: Now my desktop Chrome is returning true. IDFK. See comment on Firefox below.]

So, the full prep code might be:

    navigator.vibrate = navigator.vibrate ?? (() => {});
    // navigator.vibrate returns false if no vibes available (this is not true)
    // `0` stops all currently running vibes, acting as a NOP
    const canVibrate = navigator.vibrate(0);

Then, you could use `canVibrate` to choose whether to use haptic or alternative feedback, and you don't have to worry about Safari's lack of support.

... or you would be able to, except Desktop Firefox (and, apparently now, Chrome) returns `true`.  No exception thrown.  No attempt at speaker-driven fakery or 1px screen shaking or other shenanigans.  Just `true`.

Feature not yet ready for production, AFAICT. [Edit: there is presently no way to detect device-level vibe support]",Javascript
"If-else with closing brackets makes code look much cleaner. If you really think a one line IF is going to save anything at all, then I have nothing much to say. Easy to read code is much more crucial then having a fancy one liner syntax. Just my opinion, before anyone starts downvoting the bejesus out of this.",Javascript
"It’s nice for feedback on webapps that have a unique UX. For example, you might have something that does an action on press and on long press, so if a user presses down and you wait 1000ms, you can perform the long press action and vibrate to let the user know they can let go now. 

I don’t think vibration has a place in 99.9% of sites though",Javascript
"From the repo page on Github:


> Core JavaScript in the early days was fairly difficult to use, so jQuery emerged as the de facto way to write JavaScript.


This is absolutely false, jQuery emerged because it solved cross-browser incompatibilities, that was the only reason everybody used it.",Javascript
"Good post, I didn't know you could use stylelint with CSS-in-JS. That will be useful. Wish we could do something similar for Figma - as you say inexperienced designers tend to go outside of the design system and it makes it even harder to push the dev team to stick to the system.",Javascript
"https://github.com/samchon/typescript-json#runtime-validators

From now on, `typescript-json` validators started supporting Template Literal Types.

Therefore, `typescript-json` is the only one library who can validate not only complicate union type, but also TypeScript Template Literal Type. Below crazy interface `TemplateUnion` is an example of such Template Literal Type and `typescript-json` can validate it perfectly.

```typescript

    export interface TemplateUnion {
        prefix: `prefix_${string | number | boolean}`;
        postfix: `${string | number | boolean}_postfix`;
        middle: `the_${number | boolean}_value`;
        mixed:
            | `the_${number | ""A"" | ""B""}_value`
            | { name: string }
            | boolean
            | number;
    }

    const union: TemplateUnion = {
        ...
    };
    TSON.is<TemplateUnion>(union);
    TSON.assertType<TemplateUnion>(union);
    TSON.validate<TemplateUnion>(union);
    
```",Javascript
"Looking around the GitHub there's an excerpt from 'Structure and Interpretation of Computer Program'. It seems a JS edition just came out. (I have the Scheme version, is excellent for coding fundamentals).
I suspect there's an LP example in the book.
JSON probably would make a good format for LP : declare things in it, have a JS Prolog engine do the resolution.",Javascript
"Project Page (?): https://github.com/uvop/memorix

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/javascript) if you have any questions or concerns.*",Javascript
"Personally I don't like TDD or concerning myself with code coverage numbers.

Just test the requirements, think a bit about all possible inputs (to the system, not to functions), and do your best.

Bugs might appear in the future - add a test for the bug scenario, fix it.

The most important thing is that tests let you know that you aren't breaking anything when making new changes in the future.",Javascript
"Is React really the behemoth that the article makes it out to be? I feel like 1/3 -> 1/2 of the article was about React.  I know it's probably the most used, and certainly for a lot of large, corporate apps, but there's a lot to learn from all the other players in the space.

[edit]
Please don't downvote an honest question. I'm only a hobbyist at this point and was just curious.",Javascript
"This fucking carousel I swear to God.

I've been doing FE for almost 25 years and every five years or so someone decides that server side rendering is the way to improve performance best so we rewrite our entire stack. Then just as we finish that a new capability turns up and we switch it all around again. Put it this way, I remember thinking AJAX was incredible. Then XSLT. Then JSON. Then GraphQL. Now we've got Remix and we're back to 2002 architecture... Just with Typescript instead of Perl. And you best believe Java is still well in the mix (Sun Microsystems RIP). Like yes, we're better at what we do. We have matured a lot, we have a real industry, we're not just nerds in a bedroom making brochureware anymore. But, it used to be exciting but now it's just exhausting.

At some point we have to accept that the web ecosystem is a goddamn terrible way to write distributed applications, and that's probably why we have a thousand different ways to solve one problem, and they all suck.",Javascript
"> The new wave of Javascript web frameworks

React is almost over 9 years old now, and Vue is over 8 years old.

""New""

OMG DOES ANYONE ELSE FRONTEND CHANGES SO FAST.

No.

jQuery, Prototype, et al. reigned for about a decade, too.

> Solid, Astro, Marko, Fresh, Next, Remix, Qwik

Nobody uses any of that crap. You're creating your own problem.",Javascript
"[https://632c3c725368f3061eee439d--transcendent-zuccutto-d970f2.netlify.app/](https://632c3c725368f3061eee439d--transcendent-zuccutto-d970f2.netlify.app/)

I made a password Generator with Sveltekit. Other than a few stylistic things I need to take care of I would like some critique",Javascript
"I have written a blog on developing the infinitely nested comment & reply feature. I have created a small app for a visual representation of the solution.   
Would love to hear your feedback on it!
  

  
Blog Link: [https://jaynil-gaglani.hashnode.dev/infinitely-nested-comment-reply-feature](https://jaynil-gaglani.hashnode.dev/infinitely-nested-comment-reply-feature) 
  

  
Demo Link: [https://nested-comment-reply-feature.vercel.app/](https://nested-comment-reply-feature.vercel.app/) 
  

  
GitHub Link: [https://github.com/Jaynil1611/Nested-Comment-Reply-Feature](https://github.com/Jaynil1611/Nested-Comment-Reply-Feature)",Javascript
"Link: https://www.joshuawootonn.com/react-slider-component  
Hey yall! I recently created this slider for work and in the process learned a bunch from my coworkers. Check out the above blog post for details on how to create a slider for yourself. I would to hear if you have any feedback :)",Javascript
"Wow, that `satisfies` and `in` stuff are two issues that annoy me pretty regularly. Pretty exciting release! I hope `hasOwnProperty` and `Object.hasOwn` can work the same was as `in`, I tend to use those more frequently.",Javascript
"Do we lose what the values precisely are on each object property when NOT using “satisfies” because the example is saying each value can be a string or array of numbers? And that’s just the natural consequence of using Record<Keys, Types>?

But somehow “satisfies” is able to maintain the specific type for each value?

I think I only understand this at the moment if I accept “satisfies” does some level of magic to preserve the key/value type relationship. Perhaps I need to look into the PR as to how “satisfies” is working under the hood.

Pretty neat regardless.",Javascript
"You need the people skills to attract some people with talent and persuade them to invest in your vision. 

Two primary steps - first meet a lot of people so you can find that rare person with relevant skills. Next persuade them to join you by showing a clear vision that you can share that shows potential to be more than just a lame project and waste of time. Demonstrate a path to raising money, building a larger team etc, and creating a marketable product.

It's not very easy. But when it comes to doing this your tech skills aren't actually very relevant. They are only relevant to the extent that you can use them to build traction by building a prototype. But there are other ways to get a prototype also besides building it yourself.",Javascript
"Leading others is different than multiplying your productivity by 3. It's a whole skillset to be able to delegate and integrate the work of others. That said, you could try working on open source projects and meeting people through that. Or look for positions in startups where you can have more equity and therefore reap the benefits of your 1337 skillz.",Javascript
"Read the testing trophy by Kent Dodds. Its short.

Basically all testing strategies have benefits and drawbacks. End to end tests are really hard to write and maintain, and run slowly but give the greatest confidence. Linters and type checks run super fast but are very limited in what they can test. You want to layer different kinds of tests to cover your whole codebase.

Most code does not benefit from a ""the code does what the code does"" unit test, as you will be forced to mock out too much stuff -- detaching the test suite from reality. You are left with a ""garbage in garbage out"" test that will continue to pass forever, long after your program has broken. It also doesn't really explain why your code does what it does, meaning it doesn't offer many clues for those that come after you.

Integration tests (i.e. a test that exercises several pieces of code will behave as expected) is the best bang for your buck test. You can usually write them from a behavior driven standpoint (BDD) by which I mean they're implementation agnostic. They are describing a job. They explain why your code exists in a very human way. Want to refactor your code? The test won't change. Big confidence booster.

Contract testing is also a great way to ensure data marshaling can be done reliably. Also via code gen and type checking, these kinds of contracts can save you a lotta time staring at documentation instead of like ... building useful stuff. Is this param supposed to be passed as a number? My IDE can tell me. What query parameters are allowed? What do they do? My IDE can tell me.",Javascript
"I'm mostly commenting to follow, but had the same plot needs once. 

As another commented, scatter with C being a Mx3 matrix corresponding to the colors you want each point to be, works.   
Alternatively, if you don't need each point to be colored, but just need a sort of heatmap of whats where, similar to fig2, pcolor combined with contour might be what you need.",Matlab
"Hey all! I created [gistlib](https://gistlib.com/?language=matlab) to make learning how to do certain things in code easier. I initially started it for JavaScript, but I've also added support for Matlab.

I would love to hear your feedback on the site and your thoughts. I'm also looking for ways to improve it, so if you have any suggestions, please let me know!",Matlab
"The best way to learn matlab is to have a clearly and solidly defined project with a deadline and an end goal and to work towards that end goal. 

When I was in school we were assigned multiple matlab projects and homework assignments (e.g.: a project to solve the Taylor-Maccoll eqn. with Runge-Kutta, assignments to script various finite-difference solving methods, another project involving Numerical Lifting Line Theory). Most of the stuff was iterative solving scripts but there were also things like interfacing MATLAB with an Arduino to read sensor data.

When you force yourself (or are forced) to provide some kind of result, that is when you learn how to use matlab, and how to use the documentation to find what you want to know.

I'm sure there are many other applications of matlab that I am not familiar with, I only provide examples of the things that I have done with it.",Matlab
"You might look into [tiledlayout](https://www.mathworks.com/help/matlab/ref/tiledlayout.html), a newer version of subplot. You can use it the same way where you specify the rows and columns. Or you can use it with the ""flow"" option where the plots are automatically arranged.",Matlab
"Think of it like any other array.

You have an nxm array where n is the number of rows and m the number of columns.

So subplot(n,m,c)

If you've ever indexed an array using just one value, your c is the same as that. It runs down the column before going to the next column.

Hopefully this helps?",Matlab
"Since the code is not provided for copy-&-paste, here is a simple example:

    fun = @(x) (x(1) - 3)^2 + (x(2) - 5)^2;
    x0  = [-2, 2];
    x   = fminsearch(fun, x0)

It should return x1 = 3 and x2 = 5.",Matlab
"If it’s the x values what you’re tryin to normalize between 0 and 1, you need to divide all x values by their max, 70 in this case

If you’re trying to set y axis limits, use ylim as they told you already",Matlab
"You could try  xlim function 

The syntax is 
xlim([""first point"" ""second point""])

For your case 

xlim([0 1])

I'd probably recommend you to set it 10 though since it's linear till 10 

xlim([0 10]) 

PS: the same syntax also works for y axis(ylim)",Matlab
The warning tells you directly what to do... Provide a start point for the optimizer to get rid of the randomness. Read the documentation to find out how to do this. Choose the start point so that it is close to the expected optimum.,Matlab
"pu is the product of three components: (1) \[u\^3 u\^2 u 1\], which is a 1 x 4 vector; (2)  \[-1/2 3/2 -3/2 1/2; 1 -5/2 2 -1/2; -1/2 0 1/2 0; 0 1 0 0\] , which is a 4 x 4 matrix; and (3) \[p0 p1 p2 p3\], which is a 1 x 4 vector.

Assuming we're going left to right, the product of the first and the second is a 1 x 4 vector. To multiply it by the third (given the rules of linear algebra), the third should be 4 x 1 and not 1 x 4.

So, the following works without errors:

pu = \[u\^3 u\^2 u 1\] \* \[-1/2 3/2 -3/2 1/2; 1 -5/2 2 -1/2; -1/2 0 1/2 0; 0 1 0 0\] \* \[p0 p1 p2 p3\]';

where the apostrophe at the end transposes the third thing from 1 x 4 to 4 x 1.",Matlab
"If on your lab computer you included a “clear” line before the code, or closed and reopened matlab, the code would fail on the notebook too. 
As the other commenters mentioned, r, g, and b are not assigned in the code snippet. It worked on the other computer because the variables r, g and b were likely left over in the workspace from before, either by someone else or when you edited the code. .",Matlab
"The variables r g and b are not defined in the code displayed above. If this code is identical to the lab code, then it should not work either. 

It looks like you intend r g and b to relate to a different column of the variable named ‘rgb’

Edit: actually, after looking up what imread does, I’m not sure what I said about ‘rgb’ is what you’re trying to do. I don’t do image processing really. Bottom line is the variables ‘r’ ‘g’ and ‘b’ are not assigned here",Matlab
"The first line assigns the result of the imread operation to an array called 'rgb'. The variables 'r', 'g' and 'b' are not created or assigned any values in this step (or in any of the following steps, for that matter), so MATLAB fails to execute line 3. I suspect that 'r', 'g' and 'b' were leftovers in the MATLAB workspace on your lab PC from some previous operation, which is why the code managed to run on it but not on your laptop.  


This example should help you figure out how to extract the R, G and B components before you perform the subsequent operations - `openExample('matlab/ConvertIndexedImagetoRGBExample')`",Matlab
"It already says there: **If P(0) = 0, then P(t) will remain zero forever.**

Also if P(0) = P\*, where P\* is steady-state, then P(t) will stay equal to P\* for all future times

If P(0) is not at steady-state, then you will see something...

    P(1) = 1e-3; 
    K = 30; 
    r = 2;
    for t = 1:100
        P(t+1) = r*P(t)*(1 - (P(t)/K));
    end
    t = 1:101;
    plot(t, P)",Matlab
"> However, on my laptop, it gives me this error:
>
>     Unrecognized function or variable 'r'. 
>
> and only displays the original image, not the final, red tracker image.

What do you think that error message means?",Matlab
"You need to pass x and y as vectors. `randn(19)` creates 19x19 matrix. 


    x = randn(19,1);
    y = randn(19,1);  
    sz = randi(100,[19 1]);
    col = randi(100,[19 1]);
      
    figure
    scatter(x, y, sz, col, ""filled"")

Hope this helps.",Matlab
"> Error: Invalid training data. The output size ([1 1 26013]) of the last layer does not match the response size ([1 1 26103]).

* output size   [1 1 26013]
* response size [1 1 26103]

They are not the same size. 26013 vs. 26103",Matlab
"The simpler way, in my opinion, is to do what @MezzoScettico refers to as a wrapper, maybe even in one-line form: just pass to the optimizer this

@(x) cost_function(x, A)

Informally, x is a dummy variable bound to the @ syntax, A is an actual argument you are passing to the cost_function.

More technically I believe you are actually creating a temporary anonymous function that takes just one argument (x) and passes it as the first argument to your named cost function. The A value it passed is hardcoded in this temporary anonymous function so it is not subjected to optimization (recall: the anonymous function just takes x). After the optimization is done the temporary lambda (synonym to anonymous function) is discarded. So you can put all this in a loop where you feed different values to A.

In general then

@(x) f(x, a, b, c,...) would make a temporary lambda that accepts just one argument while hard coding the a, b, c... parameters in its definition. If passed to an optimizer it would be treated as a function of one variable and optimized just along that ""direction"".",Matlab
"Generally speaking, this is called an [anonymous function](https://www.mathworks.com/help/matlab/matlab_prog/anonymous-functions.html).

If your function has one input argument, you can do this

    function_handle = @(x) x+1;

The anonymous function is saved in a variable `function_handle`.

Then you can use it like a regular function

    y = function_handle(10);

If you have multiple input arguments, you can do this.

    function_handle2 = @(x,y) x+y;
    z = function_handle2(10,20)

Also, you can define an anonymous function with multiple parameters.

    a = 1;
    b = 2;
    c = 3;
    function_handle3 = @(x,y) a*(x + y) + c;

Good luck.",Matlab
"Just so that I understand the intended functionality here - cost_function(X,A) is a function of 2 variables and you wish to optimise w.r.t 'x' for a particular value of 'A', correct?

If so, then this is effectively a trivial case of constrained optimization with the equality constraint 1*A=100 (or whatever value you want instead of 100)

This can be specified by setting Aeq = [ 0 1 ] and beq = [ 0 100 ] while calling ga. The 0s keep 'x' from being subjected to any equality constraint. 

Refer to this is you need any further help in figuring out how to do that - https://uk.mathworks.com/help/gads/ga.html#d124e50955",Matlab
">If I want to input another value to the cost function, I will change it to the following

>function cost = cost_function(x, A) 
>%Where A is NOT a parameters to be optimized 
>cost = A*sqrt(abs(x(2)-.01*x(1)^2))+.01*(abs(x(1)+10));


I think what you need to do is fully parameterize your cost function so that it contains no [magic numbers](https://en.m.wikipedia.org/wiki/Magic_number_(programming))

Variable x also appears to be an array of two distinct numbers, so they are better represented as separate variables, say x and y.

Once parameterised, you can express default values for all parameters if they are commonly used.

```
function cost = cost_function(x, y, a, b c)
arguments
    x
    y
    a = 0.1;
    b = 0.1;
    c = 10;
end

cost = a*sqrt(abs(y-a*x^2))+b*(abs(x+c))
```",Matlab
"I think in your case if you want A to be some constant, you can either define it as a global value and then not pass it to the cost function, or include it in the call:

    [x, fval, exitflag] = ga( @(x) cost_function(x, YourValueHere), 1, ...


where ""YourValueHere"" is the value of A you want to use, but not be optimized.

Edit: I haven't tried this, and am going from memory.

Explanation:

This makes an anonymous function that takes one variable named `x`. The simple anonymous function is just a wrapper that calls your main cost function passing in `x` as the first value and lets you define the second value as you see fit.

The line

    @(x) cost_function(x, YourValueHere)

is equivalent to

    function out = myFnWrapper(x)
        A = 5000; % or whatever you want
        out = cost_function(x, A);

It just does that definition inside of the call to `ga`.",Matlab
"It looks like you can pass constant parameters to anonymous functions pretty easily using fmincon.  I think it used to be more complex (?).

&#x200B;

% The problem is to search over x,y values to minimize y
  
%        min   y
  
%        x,y
  
% Constraints:
  
% y>x\^2-2       % Values above a ""happy"" parabola shifted down by 2
  
% x\^2+y\^2<4     % Points inside a circle of radius 2 at origin
  
% y=x\^3      << Equality const!  % Must be on the function y=x\^3 exactly
  

  
% Standard form problem:  min f(x) over x subject to g(x)<=0
  
% min 0x+1y
  
% x,y  
  
% Subject to:
  
% x\^2-2-y <= 0
  
% x\^2+y\^2-4 <=0
  
%  x\^3-y <= 0    % Can rewrite equality constratint to two inequalities
  
% -x\^3+y <= 0    % fmincon will work with both inequality and equality
  

  
f = @(x) \[x(2)\];   % Want to minimize y (which is just 1\*x(2)+0\*x(1)
  

  
% Deal makes two separate output values
  
g = @(x) deal(\[x(1)\^2-2-x(2);x(1)\^2+x(2)\^2-4\],\[x(1)\^3-x(2)\]);
  
% The MATLAB optimizer expects the constraint function to give both the
  
% vector of inequality constraints and the vector of equality constratints
  

  
x=\[2;3\]      % Initial starting point
  
f(x)         % Value there?
  
\[cin,ceq\]=g(x) % inequality and equality constraint values
  

  
% Origin (0,0) should satisfy all constraints! cin < 0 , ceq is = 0
  
\[cin,ceq\]=g(\[0 0\]) % inequality and equality constraint values
  

  

  
%X = fmincon(FUN,X0,A,B,Aeq,Beq,LB,UB,NONLCON,OPTIONS)
  
x = fmincon(f,\[2 ;3\],\[\],\[\],\[\],\[\],\[\],\[\],g,\[\])
  

  
% Testing now with a parameter variable, change one of the constraints a bit.

p1=1.12
  
gg = @(x,p1) deal(\[p1\*x(1)\^2-2-x(2);x(1)\^2+x(2)\^2-4\],\[x(1)\^3-x(2)\]);
  
x = fmincon(f,\[2 ;3\],\[\],\[\],\[\],\[\],\[\],\[\],@(x)gg(x,p1),\[\])",Matlab
"If you used MATLAB a while back, a lot of things have changed since then, including new data types, live scripts, Python support, etc. And those changes enabled new workflows.

First, [MATLAB Onramp](https://www.mathworks.com/support/learn-with-matlab-tutorials.html) (a free browser-based interactive tutorial) is a good refresher to get to know modern MATLAB.

You can also check out some of my code shares since I have been trying to show those new workflows.

* [Tables are new structs](https://www.reddit.com/r/matlab/comments/ww2700/tables_are_new_structs/)
* [What can you do with table? Group Summary](https://www.reddit.com/r/matlab/comments/x1puir/what_can_you_do_with_table_group_summary/)
* [What can you do with table? Table Join](https://www.reddit.com/r/matlab/comments/x1s7md/what_can_you_do_with_table_table_join/)
* [What is the benefit of a string array over a cell array](https://www.reddit.com/r/matlab/comments/x9i2sa/whats_the_benefit_of_a_string_array_over_a_cell/)
* [Writing MATLAB Code with fewer loops](https://www.reddit.com/r/matlab/comments/xa82m3/writing_matlab_code_with_fewer_loops_hint_matrix/)
* [Importing data from multiple text files](https://www.reddit.com/r/matlab/comments/xet118/importing_data_from_multiple_text_files_speed/)
* [How to debug MATLAB Code](https://www.reddit.com/r/matlab/comments/xvcqy2/how_to_use_debugging_tools_in_matlab/)
* [For fun: Text Analysis of MATLAB Subreddit](https://www.reddit.com/r/matlab/comments/vy3pgt/for_fun_text_analysis_of_matlab_subreddit/)
* [New features from recent release notes](https://www.reddit.com/r/matlab/comments/vzs9fz/what_is_your_new_favorite_new_features/)
* [Plot table data in various plots](https://www.reddit.com/r/matlab/comments/w28mh6/plot_table_data_in_scatter_plots_bubble_charts/) (more and more plots support table as input)
* [Live Editor animation](https://www.reddit.com/r/matlab/comments/w2y55e/live_editor_animations_export_animations_to/)
* [Plotting 95% confidence intervals](https://www.reddit.com/r/matlab/comments/wgxbr2/plotting_95_confidence_intervals/)
* [Using MATLAB with Python - new live task](https://www.reddit.com/r/matlab/comments/x2qrjy/using_matlab_with_python_a_new_live_task/)
* [New AI bias and fairness functions](https://www.reddit.com/r/matlab/comments/xoi12y/new_in_r2022b_ai_bias_and_fairness_functions_in/)

You may also want to check out u/croucher's post about [new dictionary data type](https://www.reddit.com/r/matlab/comments/xeuslr/matlabs_new_dictionary_datatype/).

Good luck!",Matlab
"While the other guy gave you the solution, please, for all that is holy, actually look up vectorizing in MATLAB. It is such an important skill for optimising code.

The fact you needed to ask implies you didn't look it up because this is probably the easiest example of it.

Sorry if this comes across as rude, but you really need to look it up. Lol",Matlab
"One solution i can think of is this:

Make a user defined function, takes a function, a min and a max. You'll use a for loop to check each ""y"" and if it's out of bounds you replace the value at the index with either ymin or ymax. 
I'm sure there's other ways to go about it, but if you want the values to be limited, rather than just cropping your plot (using ylim and xlim) this is one way.",Matlab
"Did you use a surface plot for the function?  
If not, look at meshgrid to generate a reasonable grid to plot over.  
I would suggest  defining a new function  z = f(gamma0,v0) - 30000    
and  then looking at the zero contour line",Matlab
"generate the list of points using meshgrid as you did  
and then remove the upper right corner from the list  
of points.

    z = [x y];
    %select points not in the upper right corner
    z1 = z( ( z(:,1) <= -z(:,2) +2900),:);
    dt = delaunayTriangulation(z1(:,1),z1(:,2));",Matlab
"Assign your figure for the image to a variable ie hfig. Then after generating the image, as you normally would, move it to the place where you want it to appear and type in hfig.Position into the command window. You should get 4 values for figure size and position, i forget the exact order. In your main code add the following hfig.Position =[]; copy and paste the earlier output from the command window in between the square brackets. The figure should now consistently appear where you've moved it. Hope I've understood and answered the q appropriately.",Matlab
"There is confusion of where the function is being evaluated.You want to evaluate the first four samples which would be 10\^-6 \* (0,1,2,3) but you are evaluating at 0, 1, 2 and 3.  Similarly at the end (eg. you are evaluating at 97, rather than 100 - .000003)

The counter refers to the subintervals and not the value of the function.

For Part 3, it is asking to rerun the evaluation with different values for the subintervals, n.The questions suggests that a nested loop is the way to go.

Also, do not use a variable called 'error'  as it is a matlab function and bad practice to overwrite commands.

Edit:   it should be 10\^-4  instead of 10\^-6 as pointed out by OP",Matlab
"One of the best things you can do to start understanding the code you’re writing is interactive debugging. Matlab’s IDE makes this super easy, either through the console or workspace interface. When your code bonks, the error message will tell you what Matlab is unhappy about- then go look at the variables to understand WHY it’s unhappy. Very quickly, you’ll start to see “oh, I thought I was defining an array, why is this variable getting declared as a scalar??” Or “huh, that’s not the value I expected- why is that?”

If you need to, you can add breakpoints to your code and March through the execution, line by line if needed, and you can inspect the output of each operation as you go. Once you get comfortable doing that, you’ll find it easy to resolve a lot of issues.",Matlab
"Its pretty clear, you access an element in an array but it only has zero elements.

In your first Iteration i equals 19 and you want to access y(19) but this does not exist because y has zero elements at this time.",Matlab
"The variable `mx` inside `funct` is not the same as the variable `mx` at top level.  You're setting one to the other, but this is fooling you.

`fzero` also wants to call your function, with **other** values for the argument, but every time `fzero` calls `funct`, you are wiping out `fzero`'s argument and replacing it with your own.

Remove the setting of `mx` inside `funct`.",Matlab
"You can try defining function as having the input–output relationship, y = f(x), where x is the input and y is the output.

Hope you realize that there is another root on the positive side.

    % --- Top level ---
    x    = linspace(-10, 10, 201);
    xsol = fzero(@funct, -0.9)
    plot(x, funct(x), xsol, 0, 'o'), grid on, xlabel('mx'), ylabel('y2')
    
    % --- Function level ---
    function y = funct(x)
        y = x.^2 - 2.^x;
    end",Matlab
"https://www.mathworks.com/help/images/examples.html?category=deep-learning&s_tid=CRUX_topnav

There are some examples in here that I believe can get you started. But to go this route, it depends on specific toolboxes. Are you constrained to native MATLAB, or do you have a lot of the ML toolboxes?

It also depends on the images you have, and really how much data you have. This is the most significant contributor to starting ML applications.",Matlab
"I think your're missing one dot in your notation for V. It should have a second dot between the two h variables because it's likely multiplying two arrays. Try using this definition of V:

    V = @(h) pi*h.^2.*((3*4 - h)/3) - 50;

You really only need the dot notation for when array multiplication is performed. The constants like pi are multiplied element-wise. However, it shouldn't hurt to use dot notation on each use of ""\*"" or ""/"" if you only intend to perform element-wise operations.",Matlab
"p=polyfit(temperature,resistance, 1);

Figure()

plot(temperature, resistance, 'r')

hold on

plot(temperature, polyval(p, temperature), 'b')


legend('data', 'linear fit')


In General like this. Not sure about the variable namens while typing",Matlab
"Many ways to do this; data import tool has already been suggested, and that's probably the best option in general.

In this particular case, you could also take advantage of your text already being in respectable matlab syntax for a row vector, and then reshape it and transpose it.  (Transpose because internal storage is column-wise.)

Here's an 11x11 example:

>\>> x = 1:121; x = reshape(x,11,11)'

    x =
      1     2     3     4     5     6     7     8     9    10    11
     12    13    14    15    16    17    18    19    20    21    22
     23    24    25    26    27    28    29    30    31    32    33
     34    35    36    37    38    39    40    41    42    43    44
     45    46    47    48    49    50    51    52    53    54    55
     56    57    58    59    60    61    62    63    64    65    66
     67    68    69    70    71    72    73    74    75    76    77
     78    79    80    81    82    83    84    85    86    87    88
     89    90    91    92    93    94    95    96    97    98    99
    100   101   102   103   104   105   106   107   108   109   110  
    111   112   113   114   115   116   117   118   119   120   121",Matlab
"Maybe the Least Squares Method? And followed by performing a Laplace transform?

Or directly use the [System Identification Toolbox](https://www.mathworks.com/help/ident/).

Selection of the tools depends on whether you are trying to do a Linear Model Identification, or a Nonlinear Model Identification.",Matlab
"Just so I understand, you want your H input to be a vector of multiple altitudes?

In that case, with the “else if” you’re comparing all three values to H11, and get a vector of three logical values. Then you’re comparing those logical values to H with the “&&” which is where your code is breaking. 

any() or all() will evaluate your logical arrays to scalars, but I don’t think that fits your intent with this function.",Matlab
"I obtained values and don't receive any error message when I run :

    H = 15000;
    [p, T, rho, a] = AtmosProp(H)

with your code:

    function [p, T, rho, a] = AtmosProp(H)
        % all outputs are in base units, e.g. distance is in m not Km
        g     =  9.8065;
        R     =  287.05287;
        gamma =  1.4;
        L0    = -0.0065;
        L11   =  0;
        T0    =  288.15;
        T11   =  216.65;
        P0    =  101325;
        P11   =  22632.559;
        L20   =  0.001;
        H11   =  11000;
        H20   =  20000;
        if H <= H11
            T   = T0 + L0*(H);
            a   = sqrt(gamma*R*T);
            p   = P0*((1 + (H*(L0/T0)))^-(g/R*L0));
            rho = p/(R*T);
        elseif H > H11 && H <= H20
            T   = T11 + L11*(H - H11);
            a   = sqrt(gamma*R*T);
            p   = P11*exp(- (g/(R*T11))*(H - H11));
            rho = p/(R*T);
        else
            T   = T11 + L20*(H - H20);
            a   = sqrt(gamma*R*T);
            P20 = P11*exp(- (g/(R*T11))*(20000 - 11000));
            p   = P20*exp(- (g/(R*T11))*(H - H20));
            rho = p/(R*T);
        end
    end",Matlab
"Instead of using if/else, use logical indexing.

    function [p, T, rho, a] = AtmosProp2(H)
    g = 9.8065;
    R = 287.05287;
    gamma = 1.4;
    L0 = -0.0065;
    L11 = 0;
    T0 = 288.15;
    T11 = 216.65;
    P0 = 101325;
    P11 = 22632.559;
    L20 = 0.001;
    H11 = 11000;
    H20 = 20000;
    
    T = zeros(size(H));
    a = zeros(size(H));
    p = zeros(size(H));
    rho = zeros(size(H));
    
    isLessEqH11 = H <= H11;
    T(isLessEqH11) = T0 + L0*(H(isLessEqH11));
    a(isLessEqH11) = sqrt(gamma*R*T(isLessEqH11));
    p(isLessEqH11) = P0*((1+(H(isLessEqH11)*(L0/T0)))^-(g/R*L0));
    rho(isLessEqH11) = p(isLessEqH11)./(R*T(isLessEqH11));
    
    isBetH11_H20 = H > H11 & H <= H20;
    T(isBetH11_H20) = T11 + L11*(H(isBetH11_H20)-H11);
    a(isBetH11_H20) = sqrt(gamma*R*T(isBetH11_H20));
    p(isBetH11_H20) = P11*exp(-(g/(R*T11))*(H(isBetH11_H20)-H11));
    rho(isBetH11_H20) = p(isBetH11_H20)./(R*T(isBetH11_H20));
    
    isGreaterEqH20 = H > H20;
    T(isGreaterEqH20) = T11 + L20*(H(isGreaterEqH20)-H20);
    a(isGreaterEqH20) = sqrt(gamma*R*T(isGreaterEqH20));
    P20 = P11*exp(-(g/(R*T11))*(20000-11000));
    p(isGreaterEqH20) = P20*exp(-(g/(R*T11))*(H(isGreaterEqH20)-H20));
    rho(isGreaterEqH20) = p(isGreaterEqH20)./(R*T(isGreaterEqH20));
    
    end

Good luck.",Matlab
"Hello, u/Lord1Tumnus is working on something that may be related to your idea using [uihtml](https://www.mathworks.com/help/matlab/ref/uihtml.html).  

https://www.reddit.com/r/matlab/comments/wvzlwo/possibilities\_of\_uihtml/

https://www.reddit.com/r/matlab/comments/x4v9xq/uihtml\_part\_2/",Matlab
"Unfortunately, no. Check out u/MikeCroucher's comment here [https://www.reddit.com/r/matlab/comments/xf4elj/comment/ip3ijmx/?utm\_source=reddit&utm\_medium=web2x&context=3](https://www.reddit.com/r/matlab/comments/xf4elj/comment/ip3ijmx/?utm_source=reddit&utm_medium=web2x&context=3)

>Hi. MathWorks released a beta for M1 silicon for R2022a which I wrote about here [https://blogs.mathworks.com/matlab/2022/05/05/exploring-the-matlab-beta-for-native-apple-silicon/](https://blogs.mathworks.com/matlab/2022/05/05/exploring-the-matlab-beta-for-native-apple-silicon/). That beta is closed now but if you go to the page where you used to be able to get it, [https://www.mathworks.com/support/apple-silicon-r2022a-beta.html](https://www.mathworks.com/support/apple-silicon-r2022a-beta.html) we have the message:  
>  
>*Thank you for participating in the MATLAB R2022a Native Apple Silicon Platform Open Beta. The R2022a beta has concluded.*  
>  
>*An updated beta based on MATLAB R2022b will be released in the coming weeks. If you have any questions about the platform open beta program, please contact MathWorks support.*  
>  
>*We all want this and a lot of people are working hard to make it happen. It's coming and you'll have another chance to try out aa beta soon.*",Matlab
"Your University Library should have some books about using MATLAB.

One of the fastest ways is go through the books that provide many examples and exercises/solutions using MATLAB codes.

For example, if you are taking ""**Numerical Analysis and Methods**"" course, find the books on Applied Numerical Methods with MATLAB for Engineers.

if you are taking ""**Signals and Systems**"" course, find the books that present examples and introduce MATLAB functions to implement the methods described in the books.

if you are a Mechanical Engineering student, then you will learn a lot of custom functions on calculating ""***Stress, Strain, and Structural Dynamics: An Interactive Handbook of Formulas, Solutions, and MATLAB Toolboxes***"", 2nd edition.",Matlab
I get a feeling this is an exercise on elementary / permutation matrices and matrix compositions. First multiply `A` with a column-switching matrix and then with a row-permuting one: <https://en.m.wikipedia.org/wiki/Elementary_matrix>.,Matlab
"Before the lopp:

vec=[] ;

Inside the loop you have to use an iterator, lets call the iterator it.

Then also before the loop you Set

it=1;

Then insider your loop you have somewhere

vec(it) =x ;
it=it+1;

Easier would be, if possible, to use a for loop and use the iterator of the for loop for indexing.",Matlab
"Look  at the formula/equation/(your notes) for the first term of the sin x expansion.  
What should y2(1) be?

Also you haven't cleared y and y2 between values of x so it is possible that y(end) is not y(k+1) as you intended.",Matlab
"Fixed.

    TOL = 1e-5;
    x   = linspace(0, 2*pi, 361);
    Y   = [];
    Y2  = [];
    for n = 1:numel(x)
        error = 1;
        y(1)  = 1;
        y2(1) = x(n);
        k     = 0;
        while error>TOL
            k       = k + 1;
        y(k+1)  = ((-1)^k)*(x(n)^(2*k))/factorial(2*k) + y(k);          % cos
            y2(k+1) = ((-1)^k)*(x(n)^(2*k + 1))/factorial(2*k + 1) + y2(k); % sin
            error   = abs(y(k + 1) - y(k));
        end
        Y  = [Y y(end)];
        Y2 = [Y2 y2(end)];
    end
    plot(x, [Y; Y2]')",Matlab
">I’m having a hard time figuring out how to calculate the summation because there is no variable.

The ""i"" in the summation is just the loop counter.  For example:

`x = 0;`

`for(i=1:500000)`

`x = x+0.00001;`

`end`

There are probably more clever ways of going about this, but this will work.",Matlab
"As others have said, you don't want to use A_i for something like this, but you could easily turn what you want into a function.

Here's a simple way to do it with an anonymous function:

    A = @(i,N) ((1:N)' == i)

Then calling `A(i,N)` returns the i-th column of eye(N). This would return as a logical vector in this case, which can usually be used without modification as a numerical vector in most applications. If for some reason you want an actual numerical vector, replace the above with

    A = @(i,N) double((1:N)' == i)",Matlab
"This can be done, though it is almost certainly not the best way to do what you need to do. lookup the documentation for eval which should help you understand how to do it, but also why is not ideal. There is also a page called alternatives to eval which discusses your use case exactly",Matlab
"Matlab on-ramp ( self paced courses) can be a good start if you are completely new to Matlab and vectors.  On-ramp interface allows you to simultaneously learn and code. Once you cover the basics and feel comfortable, you can start coding/reviewing others code gradually. Matlab documentation is great which can be found through the search option on the top right corner of your Matlab application window. You can type in any function or command for which you need help with. Also, you can type help “function name” for the corresponding document to open. The documentation offers syntax, examples and use cases which can be adopted for your requirements and help understand the objective of the function or a command.

Good luck!",Matlab
"I've been working on something similar for my NACA Utility app to generate stl files from the geometry, jist haven't had the time recently to work on it.

Even so it may br of use?


https://www.mathworks.com/matlabcentral/fileexchange/101864-naca-utility",Matlab
"If you don't need both on the same plot, plot them separately. If you do, why not change the subplot from side-by-side to one on top and one on bottom?

I'm assuming your issue is that the bars are thin and hard to tell what's what",Matlab
"you plot 6 bars per day for 30 days, that's a lot of bars.  It just means that a bar plot is not a good way to represent all this data.

One option mentioned by others is you make the figure wider, and 2 rows instead of 2 columns.

Another option, is you summarize your data say by doing a weekly/biweekly average, OR summing all counties into a single bar.",Matlab
"This is what I think it says. 

So, k = 1, 2, 3, ... 10. 

there is a function topk = f(k), as in top1 = f(1), top2 = f(2), etc. 

top1 contains 1 prediction, top2 contains 2 predictions, etc. 

what percentage of the prediction was correct in each of top1, top2, .... top10 - plot the result.",Matlab
"The loop will occur for every time step, so you can't fix it by simply setting an initial value. Generally you solve this by using either a Memory or Unit Delay block so the calculation input doesn't depend on its own output from the same simulation step. Identify the variable which logically should be the result of each time step, and apply the delay there to break the loop.",Matlab
"Guess wat it is ok when code is not retrieved,me when I worked on algorithm some error in my code caused whole pc to shutdown,just like usb killer .Next time the pc never boots at all.Just compiling caused huge loss.",Matlab
"this is normal for matlab. I asked support multiple times why this happens and they can't tell me. The best I can figure out is that ML is very bad at handling memory and obviously has no autosave function. 

I've lost a lot of work over the years this way. my suggestion is to use python, but I know for school they make you use matlab sometimes.",Matlab
"Ehhh, they are fine. The same problem exists with simulink files.

I have been playing with MATLAB projects and this integrated with source control is underutilized in my experience.

My previous job used SVN and just a folder and it worked but I think a MATLAB project would have been much better.",Matlab
"Maybe I just have an old fart mentality, but I never really saw the appeal of live editors outside of introductory instructional use cases. Everything they do can be accomplished just as easily and efficiently by making intelligent use of breakpoints and screen output, but with much more flexibility.

I briefly messed around with both Jupyter and matlab’s live editor and just couldn’t find a compelling use case outside of when I was running coding 101 workshops. I do know that some people absolutely love them though and no judgment there!",Matlab
"Use the `isinf` function to find out where or whether the `data` array contains infinities:

    inf_inds = find(isinf(data))

The function `isnan` does the same with `NaN` values, and `ismissing` for instances of `missing`.",Matlab
"Yeah this is called curve fitting and interpolation.  There's a bunch of different ways.

Personally I think the 2D or 3D sparse dft would work well, as would orthogonal polynomials.

For a sail, I'd probably do: 

[sail_rotation,sail_center,points_ind,depth]=function sail_transform(PointsXYZ)
    %PointsXYZ is a matrix 3xN
    P=PointsXYZ';
    %use PCA to find the optimum rotation and center of mass
    sail_center=mean(P,2);
    Po=P-repmat(sail_center,size(P,2));
    [U,S,V]=svd(Po,'0');
    
    Pn=U*S;  %new sail points
    XY=[Pn(:,1);Pn(:,2)];  %independent axis
    Z=Pn(:,3); %dependent axis 

    sail_rotation=U; %sail_rotation(v-sail_center) is the new coordinate Space.
    points_ind=XY;
    depth=Z;
end
    
coeffs=basis_fit(XY,Z,basis_func)
    coeffs=(Z'\basis_func(XY))';
end 

    
Z=poly2_basis(XY) 

X=XY(1,:);
Y=XY(2,:);
O=ones(1,size(X,2));
X2=X.^2;
Y2=Y.^2; 

Z=[O;X;Y;X2;Y2;X.*Y]; 

End",Matlab
"Be sure that you do not less figure in between the two runs. If you close figure or select another existing figure in between the two runs you will not plot the second run data at the correct place. 

To fix it, just add 'figure(100)' at the beginning of the program so the figure no 100 is selected (and created if needed) at each run, ensuring data are plotted on the correct figure",Matlab
"i think the ' clear all ' in the beginning is the culprit. What it does is , it clears all the values of the variables every time that code is run . the program runs fine first time with NO air resistance but when you run it second time with YES  , it clears all the variable. Now the ' hold on ' needs a previous valid variables to hold on the graphs when it plots the changed variables, but in your case it is cleared because of the clear all in the beginning. 
Just comment out the clear all when you run the script second time. I think that should work.",Matlab
Also i am not sure if the while condition is completely correct. since y can be zero and if the iteration is not maximum the loop runs. so what it is doing is as the ball lands ..( y =0 but if the iteration is not maximum ..the loop will still run ...not it will again take the x component of the velocity and calculate y ..until the iteration is max.,Matlab
"You just call the error function with the data and cell array as an argument, to get the results:

    cost = error_function(x, cell_array);

**Edit:** Or do you mean specifically in the context of the `ga` routine? If you need to pass a function `f1` to another function `f2`, but also want to have access to variables in the symbol table of the function `f` that calls `f2`, without passing them as arguments to `f1`, you need to write `f1` as a *closure*, a function defined inside the function `f` that calls `f2`:

    function [x, fval, eflag] = f(x, cell_array)

        % Do stuff here, including calling f2
        % with a pointer to f1 as an argument.

        [x, fval, eflag] = f2(@f1, ...);

        function cost = f1(x)

            cost = 0;

            for kk = 1 : lenght(cell_array)

                cost = cost ...
                    + function_of(cell_array{kk});

            end

        end

    end

Closures such as anonymous functions can capture variables from the workspace they are defined in. Here the `cell_array` given to `f` is visible to `f1`, because `f1` is defined inside of `f`.",Matlab
"Excuse the notation but basically  
Time signal =  1 /N \* IFFT(frequency signal)  
where N is the length off the IFFT.  
You adjusted the amplitude of y\_2 by 0.5 prior to the IFFT   
but I don't see the scaling for the IFFT length  
which means you have a scaling factor of 0.5 \*N for the time signal.",Matlab
"Instructions from my professor: 

You are going to plot the curves:

xt = @(t) cos(t);

yt = @(t) sin(t);

zt = @(t) cos(t).\^2 - sin(t).\^2;

in three separate parts. Create three non-overlapping plots each of which shows a portion (time interval) of the curve. Each of these plots should use a different type of line, e.g. solid, dotted, and dashed. Then, display all three of these curves on one set of coordinate axes to display the full curve (still displaying the three different types of lines).

The graph I made is combining the xt,yt,zt, but I am really unsure of how to make part of the graph have a dashed line, and another part of it have a dotted line.",Matlab
"You can split the time interval into sections and plot each section separately. `plot(x,y, ':' )` will create a dotted line, `plot(x,y, '--' )` will create a dashed line. Remember to call `hold on` after the first plot. See the matlab documentation for more info: https://www.mathworks.com/help/matlab/creating_plots/specify-line-and-marker-appearance-in-plots.html",Matlab
"Thanks for your suggestion. I passed it along to my colleagues.

Looking at the list of cards supported by AMD for ROCm (for machine learning application), do you see the card you have listed there?

https://docs.amd.com/bundle/Hardware\_and\_Software\_Reference\_Guide/page/Hardware\_and\_Software\_Support.html",Matlab
"You can get the „mex“ extension and then have mexfiles that run c-funtions like you would with regular functions. Should work for C++ too but I‘m sure. You need a seperate compiler too, it‘s not hard to implement tho.

I don‘t have any experience with EtherCAT and don‘t remember exactly how I did it since it‘s been a while.
Hope I could help at least a little bit so you at least know what to research. Gool luck :)",Matlab
"How did it not work? Did you remember to

    >> clear all

before running the exercise script again, in case there was some incompatible leftover state in the base workspace since the last run?

**Edit:** the place you are defining the function might just be the issue. Did you look at the red error message?",Matlab
"You could plot just the magnitude of the error, i. e. the norm of the (x, y, z) coordinates. You'd lose directional information in this reduction. You're going to have to make a decision about what information is most important for you to show.",Matlab
"This is a problem I see all too often in published articles, technical reports, briefings, proposals, literally everywhere. People cramming too much data into figures. I guarantee nobody will ever pay any attention to or get any value out of that figure. All I see is bunch of red lines and numbers with far too many digits. 

Fortunately it sounds like you recognize that this is a problem. I don't have any specific suggestions for you, but you need to find a way to summarize the data, then summarize it again. Nobody cares about the details.",Matlab
"I think you're going to want to overload your class's disp() or display() functions. That way when one of those functions is called on your class it will call your custom function instead.

https://www.mathworks.com/help/matlab/matlab\_oop/overloading-functions-for-your-class.html",Matlab
"I believe you can change this behaviour by using the matlab.mixin.CustomDisplay class and the displayNonScalarObject method. See the docs for more info:

https://uk.mathworks.com/help/matlab/matlab_oop/custom-display-interface.html",Matlab
"I am on mobile so can't runt the code, but I think this is just drawing lines (color black or 'k') along the x and y axes. The [0,0] are just the x and y values for each line plotted, for that particular line. Does that make sense?",Matlab
"That part is an example of logical indexing. Here is some documentation on the approach: https://www.mathworks.com/help/matlab/matlab_prog/find-array-elements-that-meet-a-condition.html

The left hand side of the equal sign defines the elements that you want to set values for. The right hand side defines the values of those elements. So `v(v<32)` selects all of the elements of `v` that are less than 32. The value of those elements are set according to the expression on the right hand side.

I would recommend you use the debugger to pause the execution at those steps and inspect the values of those expressions so that you understand how the assignment is occurring.",Matlab
"What is it with people not knowing how to ask for programming-related help? If you get an error, you should spell out the error in full, propely formatted like so:

    Error: all of the red text printed by
    Matlab when an error occurs.

I don't have access to Matlab right now, so I can't actually run the code to observe the error myself.

As for the plot modifications, you should probably capture the figure handles, so that you can reference them when making modifications:

    fig1 = figure(1);

    ax1 = axes(fig1);

    ax1.Title = ""Axis title 1"";

    stem1 = stem(ax1, x, y);

See figure ([link][figure]), axes ([link][axes]) and stem ([link][stem]) properties for what you can access and modify with the dot operator `.`.

[figure]: https://se.mathworks.com/help/matlab/ref/matlab.ui.figure-properties.html

[axes]: https://se.mathworks.com/help/matlab/ref/matlab.graphics.axis.axes-properties.html

[stem]: https://se.mathworks.com/help/matlab/ref/matlab.graphics.chart.primitive.stem-properties.html",Matlab
"Im going to assume your new to coding. When you are asked to do something, you should use google to figure out how to do it. Odds are, there is a post on google about doing something you are trying to do. For instance, if you google “matlab cylindrical coordinates” there is a page that answers exactly what you are looking for. If you can’t find the answer on google, then feel free to post on reddit, but don’t expect to just submit a homework problem with no attempts of your own to solve it and to get help.",Matlab
"You want to model diffraction via ray tracing? Look up Gaussian Beamlet Decomposition. The idea is to decompose the wavefront into Gaussian beams that can be propagated using geometrical optics, then add them up again on the other end. Here's the first result from Google: https://arxiv.org/abs/2106.09162",Matlab
"Yes, you definitely could -- but I do not believe there is a built-in funciton.  Things like this will definitely be useful: [https://www.mathworks.com/matlabcentral/fileexchange/30162-cylinder-scattering](https://www.mathworks.com/matlabcentral/fileexchange/30162-cylinder-scattering)

I have some code a student of mine wrote years ago that I then twiddled that calculates the RCS of cylindrical objects: [https://www.dropbox.com/s/w6qjccw37kqwhet/cylinder\_rcs.m ](https://www.dropbox.com/s/w6qjccw37kqwhet/cylinder_rcs.m?dl=0)

An example of similar (though different in obvious ways) analysis that of is diffraction through a circular aperture: [https://www.physicsforums.com/threads/babinets-principle-effective-aperture-dipoles-matlab.990183/](https://www.physicsforums.com/threads/babinets-principle-effective-aperture-dipoles-matlab.990183/)",Matlab
"You can implement optical propagation relatively easily. I have a masters in computational optics so I personally would reference a couple of textbooks or my own notes from grad school, so I'm not exactly sure where to send you for free references that cover all the details. In brief though, you're looking for optical propagation using the angular spectrum, Fresnel, or Fraunhoffer diffraction integral. If you want to get your hands on a textbook, you're looking for ""Introduction to Fourier Optics"" by JW Goodman.",Matlab
"I'm not sure what you're asking for, but I'm guessing that part of the problem may just be vocabulary.  So let's try re-phrasing your question, and you can correct me if this is wrong.

>I have an executable matlab file that calls to a dataset on my PC.

You have some matlab code that refers to a file, by name.

>The dataset is already in a matlab format and saves to the workspace...

The file is a MAT file.

**Comment:** The purpose of a MAT file is to store one or more variables.  The purpose of the function named LOAD is to copy variables from a file to the (in memory) workspace.  The purpose of the function named SAVE is to copy variables from the workspace to a file.

>... but I'm looking for a way to run this file as a single executable while using the same dataset while on PC  ...

This is where my translation breaks down.  There are two files:

1. The file containing your code, posted above.
2. The file containing your data.

You're already executing 1.  And file 2 only contains numbers; it isn't something you can execute.  So here's where I have to make a guess.

Your code refers to a data **file** named ""datadot.mat"".  You code *also* refers to a **variable** named `datadot`.  You might be thinking that datadot-the-file and datadot-the-variable are the same thing.  They're not.

A MAT file can contain multiple variables, and the name of the file doesn't have to be the name of any of the variables.

So here are two different ways to answer your question, if my guess is correct.  The key to both methods is to ***separate*** creating the data from analyzing the data.

**Method 1**:  (Klunky, but closer to your existing code.)

Remove the following lines from your code:

    clc
    clear
    load datadot.mat

You're going to do that manually.  Now you can type

    load datadot1.mat

or

    load datadot42.mat

or even

    load i_got_this_from_r_matlab.mat

and as long as those mat files contain a variable named `datadot`, things will work.

Assuming your code is in a file named (for example) assignment1.m, then your matlab session looks like

    clear
    load mydata.mat
    assignment1

The problem with Method 1 is that you can't have more than one dataset in memory at the same time.

**Method 2:** (Smarter, cleaner, and more flexible.)

Turn the analysis into a function.

    function assignment1(datadot)
        plot (datadot(:,1),datadot(:,2),'r');
        hold on
        ....
    end

Now the **local variable** named `datadot` has no relationship to the global workspace variable that might or might not have the same name.  Which means you can call your function on any suitable variable.

Now your matlab session might look like

    clear
    load mydata.mat
    load rick_and_morty_data.mat
    assignment1(datadot)
    assignment1(data_from_rick)
    assignment1(data_from_morty)

Notice how there's one variable in mydata.mat but there's two (or more!) in the other mat file.

Note: Now you need to know the relationships between file ",Matlab
"I don't have the image toolbox, so I can't check.  
But if that is your code it appears that you are assigning the two end  points to x1,y1,x2 and y2.   I assume that this is going to two points (x1,y1) and (x2,y2) which is good, but   
now you need the formula/equation for the distance between those points.",Matlab
"Sorry, that's not possible. See below for more details. 

https://www.mathworks.com/matlabcentral/answers/321122-how-to-change-the-fontname-of-axes-labels-when-using-the-latex-interpreter#answer\_251215",Matlab
"In your objective function, include a term for error in each data set?

min obj

determine all the errors for the different data sets.

obj=sum(\[e1(:)'\*e1(:)  e2(:)'\*e2(:)       ...   en(:)'\*en(:)\]",Matlab
"This sounds like a question about mathematics more than Matlab. You're asking for a particular algorithm that may or may not even exist.

Certainly, I could suggest the brute force approach: try adding it in each possible location and see which produces the fewest inversions. I'm sure that's not the most efficient algorithm. I don't know off the top of my head what's more efficient and I have no idea whether it will be probably optimal or if that's even possible.",Matlab
"It does indeed act LIKE an if statement for the individual elements in the array.

As other people have said, this uses logical indexing and is definitely worth looking into.

If you require a little more explanation after looking into it, HMU. :)",Matlab
"Here is the solution,

    txt = 'ZKHFUWENCKERBCKEWHALIHNMKLDEGAFCSDAERFAEWHALFQA';
    k = 4; % number of characters in a shingle

We want to split the text into k-length shingles (k-shingles). To do so, first we need to split the text into two parts - the part divisible by k and the rest.

    nKeep = strlength(txt) - mod(strlength(txt),k);
    strKept = txt(1:nKeep);
    strTrimmed = txt(nKeep+1:end);

Then you can use reshape to wrap the string into nx1 cell array of k-shingles.

    kshingles = cellstr(reshape(strKept,k,[])');

If there was any string shorter than k, we need to append it.

    if string(strTrimmed) ~= """"
        kshingles = [kshingles;strTrimmed];
    end

Now count the number of occurrences of shingles,

    [pat,~,ix] = unique(kshingles);
    count = accumarray(ix,1);
    T = table(pat,count);
    T.Properties.VariableNames = [""Shingle"",""Count""];

This finds the repeated patterns,

    repPat = T.Shingle(T.Count > 1)

This should return 'WHAL'.

Then you can get the indices of the repeated pattern in the text.

    ix = strfind(txt,repPat);
    txt(ix(1):ix(1)+k-1)
    txt(ix(2):ix(2)+k-1)

Both should return 'WHAL'.

Obviously, this will only handle a fixed k-shingles, but if you can turn this into a custom function and call the function for various number of `k`, then you get what you need.


    function T = kshingles(txt,k)
        nKeep = strlength(txt) - mod(strlength(txt),k);
        strKept = txt(1:nKeep);
        strTrimmed = txt(nKeep+1:end);
        kShingles = cellstr(reshape(strKept,k,[])');
        if string(strTrimmed) ~= """"
            kShingles = [kShingles;strTrimmed];
        end
        [pat,~,ix] = unique(kShingles);
        count = accumarray(ix,1);
        T = table(pat,count);
        T.Properties.VariableNames = [""Shingle"",""Count""];
    end

I hope this helps.",Matlab
"Here's one approach that might work. 

I added comments to explain some of the tricky parts, but let me know if you have any questions or if it doesn't work.

Also, you'll need to replace the 2nd line with your own labels variable. I was using randomly generated letters to test it.

    minLength = 5; % minimum sequence length to check
    
    % Replace these ""random"" labels with your labels
    labels = char(randi(26, [1 10e3]) + 'A' - 1);
    
    n = length(labels);
    found = zeros(0, 2);
    for i = 1:n-1
        % compare labels to a shifted version of itself
        % ""match"" is ""1"" wherever they have the same labels
        match = (labels == circshift(labels, i));
    
        % Now we want to find regions in ""match"" that are ""1"". For instance,
        % five ""1""s in a row indicate a repeated sequence of length 5.
        
        % To find this we can look for places where ""match"" changes from ""0"" to
        % ""1"" and back to ""0"". For example we want to find a region like this:
        % match = [..., 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, ...]
        
        % An efficient way to find this is to use ""diff"" to look for a change
        % from 0 to 1. Taking a diff on the example from the previous paragraph
        % would look like this:
        % diff(match) = [..., 0, 0, 1, 0, 0, 0, 0, -1, 0, 0, ...]
        
        % In diff(match) a ""1"" represents the start of a matching sequence and
        % ""-1"" indicates the end of a matching sequence.
    
        dif = diff([0 match 0]);
        starts = find(dif == 1); % starting indices of repeat sequences
        stops = find(dif == -1); % ending indices of repeat sequences
        lengths = stops - starts; % lengths of each sequence
        ok = lengths >= minLength; % we only want the ones that are longer than ""minLength""
    
        % save the starting indices and sequence lengths for later
        found = [found;
            [starts(ok)', lengths(ok)']
        ];
    end
    
    % Get the repeated sequences and where they occur
    repeats = struct();
    for i = 1:height(found)
        startIndex = found(i,1);
        seqLength = found(i,2);
        endIndex = startIndex + seqLength - 1;
        sequence = labels(startIndex:endIndex);
        indices = strfind(labels, sequence);
        repeats.(sequence) = indices;
    end
    
    disp('Repeat sequences:')
    disp(repeats)",Matlab
"Try live tasks. It's available in the menu under live editor tab as ""Task""

Then choose smooth data task. 

[https://www.mathworks.com/help/matlab/ref/smoothdatatask.html](https://www.mathworks.com/help/matlab/ref/smoothdatatask.html)

Good luck!",Matlab
"Hey. On my phone right now. A few ideas. You can perhaps find the indices using the find function, look up the documentation. Will be something like indices = find(a....). And you should create a zeros(size(frames,1),size(frames,2)) array as well in the find function, so it finds the blacked out frames. (I assume they are all zeros). Then you can remove them with a(:,:,indices) = []. If this all doesn't work (because i am not sure about using the find function in the third dimension). You could always loop over a, and use issequal(a,zeros(size(frames,1),size(frames,2))) to get a boolean if a frame is black, and then delete this frame with a(:,:,ii) = []. Good luck!

Edit: sorry, I see you have trouble saving the new videos. Try using the imwrite function. Look up the documentation.:) pretty sure that works.",Matlab
"So you have 481 tifs in the folder and are writing them to the video file? Does this stack already not contain the deleted images?

I don't see an error in the code really. Although I am unfamiliar with the im2frame command. Does it not work to directly use ""writeVideo(vidObj, a)""?

Did you try other output video formats?

Did you try to play with say, just a few tifs to see if it works?",Matlab
"I did not see any obvious mistake in the way you create the video. It should work well on a PC. You may experience codec issue on Linux and Mac. 

In order to diagnose the problem, i suggest to run a sample code from the doc (th one provided with writeVideo). If the example works, then try to specify the video format as in the example. 

This should work.",Matlab
"one small modification,  to skip the if statement in the loop, for example

    allFrames = 1:10
    skipFrames = 3:3:9
    selectedFrames = allFrames(~ismember(allFrames,skipFrames))
    for iiFrame = selectedFrames 
       ... 
    end",Matlab
"unos links:

Someone asked this before on reddit :d: [https://www.reddit.com/r/matlab/comments/1qrpzf/trying\_to\_remove\_vocals\_from\_songs\_create\_karaoke/](https://www.reddit.com/r/matlab/comments/1qrpzf/trying_to_remove_vocals_from_songs_create_karaoke/)

Swetha said it kinda works: [https://www.mathworks.com/matlabcentral/answers/506350-separate-voice-from-background-music](https://www.mathworks.com/matlabcentral/answers/506350-separate-voice-from-background-music)

FEX has a tool: [https://www.mathworks.com/matlabcentral/fileexchange/35466-karaoke](https://www.mathworks.com/matlabcentral/fileexchange/35466-karaoke)  
I think this video is the same??: [https://www.youtube.com/watch?v=9uv0RwixOSY](https://www.youtube.com/watch?v=9uv0RwixOSY)

ImageAnalyst suggests ICA: [https://www.mathworks.com/matlabcentral/answers/106402-trying-to-remove-vocals-from-songs-create-karaoke-specifically-windowing-and-framing-help](https://www.mathworks.com/matlabcentral/answers/106402-trying-to-remove-vocals-from-songs-create-karaoke-specifically-windowing-and-framing-help)

Something from the docs, might be helpful: [https://www.mathworks.com/help/signal/ug/extract-voices-from-music-signal.html](https://www.mathworks.com/help/signal/ug/extract-voices-from-music-signal.html)",Matlab
"So many options to solve this!

Either track the variable names upon loading and clear the name after.

Export the loading to a separate function => separate workspace for each call of the loading function, function only returns variables read from each specific file.

I guess there's many more options to make it faster or more beautiful!",Matlab
"In MATLAByou don't assign variables with their type like in C. Try and type ""double x"" in the command window and you'll see it outputs 120. That is because 'x' is the 120th ASCII character.

If you define a function implicitly like you do for f(x), you'll need to instantiate an [anonymous function or function handle.](https://it.mathworks.com/help/matlab/matlab_prog/creating-a-function-handle.html) Then you'll be able to evaluate f(x) at any x you specify",Matlab
"Super useful stuff, just like you can call x(3,5) and get a value for the given element in array x, you can also call x(x<3) and get all the elements in x that are less than 3.  You get their values, not the index.

For example, say you had a 3-bit grayscale image array with values from 0-7 and wanted to perform histogram equalization to convert it to an 8-bit image with values from 0-255.  Histogram equalization aside, you would eventually say something like x(x==1)=17;  x(x==2)=48; etc, to set all the values to their new equivalent.",Matlab
"I think it’s because you’re setting up the code on the right as a function instead of as a script. My recommendation would be to define f(x) without the function/end. 

It’s possible that this is working fine but I expect the error is coming from evaluating that function (whether it should be defined as f=…. Instead of f(x)=….) or if the Lagrange function has trouble evaluating f(a), f(b), f(r). 

You should try and check the intermediate values of fa, fb…. To see if they are correct. If incorrect, change function definition. 

I would say, just set up: 
f=……
a=…
b=….
N=..,.
Tol=….
Langrange(f,a,b……)

If you want to evaluate different values of a,b , you can define a vector as A=[a1,a2,a3], B=[b1,b2,b3] and have a for loop (on the script side) that executes the code for each of these cases.",Matlab
"The gradient of a function will give you two functions, a partial for each variable. You'd have to use a for loop and initialize a 2x3 matrix to stuff them into because you're trying to perform a gradient on an array of functions.

    syms x y z g gradG
    g = [(x+y3); 0.8*(x3+y);(x2+y2)] 
    gradG(2,length(g))=0;
    for i= 1:length(g)
     gradG(:,i) = gradient(g(i));
    end 
    gradG",Matlab
"Not sure what your scope is, but if you take the time to understand and implement the Kaman filter yourself using matrices and vectors (tons of examples online) - it would be trivial to add in measurements from another sensor.",Matlab
"fit a polygon and find the centroid of that (eg use polyshape)

or try a blob approach and find the centroid eg. using regionprops

I haven't used KLT, your image looks like it does OK. But the image quality is good and with enough contrast that I think finding the blob might be better (idk if it's easier)",Matlab
"Couple of things. First, if you want to do this with `if` statements, you'd want your code to look something like this:

    if DOF == 1
        'do stuff'
    elseif DOF == 2
        'do different stuff'
    elseif DOF == 3
        'and other stuff'
    end

With your 'if DOF == 2` check inside the `DOF == 1' check, it won't ever get hit. Read up on how they work [here](https://www.mathworks.com/help/matlab/ref/if.html). 

However, this is not the way you want to do this! You want to use [vectors](https://web.cecs.pdx.edu/~gerry/MATLAB/variables/vectors.html) and a for loop. For a quick thought about why-typing this all out for up to 6 degrees of freedom is hard enough- imagine if you had 100 degrees of freedom? Instead, you want to do something like this:

    DOF = input('How many degrees of freedom does your robot have? ');

    alpha = zeros(1,DOF);
    theta = zeros(1,DOF);
    for i = 1:DOF
        alpha(i) = input(['Alpha ', num2str(i-1), ' value: ');
        theta(i) = input(['Theta ', num2str(i), ' value: ');
    end",Matlab
"I have worked this out previously but i don't have my code in front of me so I can't double check. 

I think that the maximum (reasonable) frequency is the Nyquist of N/2.

The approximate level should cover the first half of these, or 0-N/4.

Each detail level then splits in half.

So for the 2000 pixel direction
A1: 0 - 5 per cm
D1: 5 - 7.5 per cm 
D2: 7.5 - 8.75 per cm
And so on.

The frequency bands aren't exact and there will be some overlap, depending on your chosen wavelet of course.

Please use this as a first guess as I need to check that they aren't based of a power of two instead!",Matlab
"Hello, there are couple of ways to include multiple plots in the figure, and I wonder which way you are using here?

* [subplot](https://www.mathworks.com/help/matlab/ref/subplot.html)
* [tiledlayout](https://www.mathworks.com/help/matlab/ref/tiledlayout.html)

Which one are you using?",Matlab
"The location of titles is set automatically with the title command. There may be a preset style that has more spacing but I am doubtful. You child look at the docs of the title command to be sure.

If im remembering right you can set the position of the title manually using the ""Position"" keyword. However you would have to manually define the position of all the titles inside the figure window. I'm my view that is not worth it at all.",Matlab
"here are some alternatives if you don't want to use the subtitle space:

title({'test';\[\]})

title(\['test' newline\])

if you want more precise you can make the tile smaller and move the title up:

ax.Position=ax.Position+\[0 0 0 -0.1\]; % reduce ax height

ax.Title.Position=ax.Title.Position+\[0 0.2 0\]; % move title up",Matlab
"Hello, assuming you are using [tiledlayout](https://www.mathworks.com/help/matlab/ref/tiledlayout.html) approach, there are three ways to add space between title and axes.

    tcl = tiledlayout(2,2); 
    
    % here is what you typical do if the default works
    nexttile
    plot(...)
    title('baseline')
    
    % 1) here is how to do it using newline character
    nexttile
    title(['Add newline',newline])
    
    % 2) here is how to do it using subtitle
    nexttile
    title('Add empty subtitle')
    subtitle(' ')
    
    % 3) here is how to modify the title position
    nexttile
    htl = title('Change title position');
    htl.Position(2) = htl.Position(2) + .1;

With regards to your second question, please reference the documentation about [box](https://www.mathworks.com/help/matlab/ref/box.html). You probably need to add this to each axes.

    box on

I hope this helps.",Matlab
You compile the equation (and the rest of your text document) with a separate LaTeX compiler such as `pdflatex` and then include the images generated in Matlab there. The Live Editor is not suited for producing publication-level texts.,Matlab
"I'm not sure about the login issues, but to set your project directory on startup you could set up in a file called `startup.m` using `cd()` to move your directory on startup. You can read more about it here https://www.mathworks.com/help/matlab/ref/startup.html",Matlab
"The `short` answer is you can't. If you want a `short` answer, don't use symbolic variables. 

We don't have enough information about your problem to know how reasonable your request is. How is `phi` defined?",Matlab
"For the sake of demonstration I'm going to assume that `phi` is the golden ratio `(1 + sqrt(5))/2` and that `psi` is the polygama function.  Note that `psi` is also [Matlab function](https://www.mathworks.com/help/matlab/ref/psi.html).

Let's pretend that you created `phi` manually:

    phi = ( 1 + sqrt( 5 ) ) / 2

That would evaluate to a double: `1.618033988749895` which if we then convert to a symbolic value converts it to a rational:

    >> phi = sym( 1.618033988749895 ) 
    phi = 
    910872158600853/562949953421312

Even if we try putting `sym()` around our declaration we get the same result as the argument to `sym` is evaluated before being cast to a symbolic value -- in effect no different than what we did above:

    >> phi = sym( ( 1 + sqrt( 5 ) ) / 2 )
    phi = 910872158600853/562949953421312

Instead we should use either of two paradigms:

    >> phi = ( sym(1) + sqrt( sym(5) ) / sym(2) )
    phi = 
    sqrt(sym(5))/2 + 1  %% i.e. retains a ""more symbolic"" form

or

    >> phi = str2sym( ""( 1 + sqrt( 5 ) ) / 2"" )
    phi = 
    sqrt(sym(5))/2 + 1  %% i.e. retains a ""more symbolic"" form

 We can even do the same with functions, like the call to `psi()`:

    >> PSI = psi( sym(""1"") )
    PSI = 
    -eulergamma
or

    >> PSI = str2sym( ""psi( 1 )"" )
    PSI = 
    -eulergamma

Then if we were to do further calculations (e.g. the `cosd()` in your example) you'll get:

    >> cosd( phi )
    ans = 
    cos((sym(pi)*(sqrt(sym(5))/2 + sym(1/2)))/180)

    >> cosd( PSI )
    ans = 
    cos((sym(pi)*eulergamma)/180)",Matlab
"you can use sympref to change the way numbers are shown: [https://www.mathworks.com/help/symbolic/sympref.html#mw\_1464af98-5a29-4ac0-b0a7-3d101ea82566](https://www.mathworks.com/help/symbolic/sympref.html#mw_1464af98-5a29-4ac0-b0a7-3d101ea82566)

you can also maybe use vpa(\*expression\*,4) without assigning for display purposes,",Matlab
"Here are two relevant discussions:

https://www.mathworks.com/matlabcentral/answers/364551-why-is-matlab-unable-to-run-the-matlabwindow-application-on-linux

https://www.mathworks.com/matlabcentral/answers/388052-why-is-my-matlab-unable-to-run-simulink-matlabwindow",Matlab
Certificate is not worth much but it is a great introduction to MATLAB. Is varies in length for each concept and it has practice problems along the way. The OnRamp training is a much quicker version and can be finished within a few hours.,Matlab
"I don’t see why symbolic variables are necessary here.

Conceptually, to find the area under a 1D curve using Monte Carlo, just start by computing the area of the smallest rectangle that 1) has one side along the x-axis, and 2) contains the curve completely. Then, in this support (domain, x bounds, whatever you want to call it), generate M points uniformly distributed in this box. Of those M, determine how many points, N, are below the curve (since your curve is piecewise linear, you’ll need to program a conditional statement that decides which “line” of the function to compare against). The area is approximately (N/M) times the area of the box.",Matlab
"type 'doc function'  the documentation is very helpful.

You can put the function in a separate file with the function name as the file name or if you only need it in the one script file you can put it at the bottom of the script file.

Your basic function definition would be something like

    function letterGrades = numberTOletterGrade( numberGrades) 
    %your processing here to process a vector of numberGrades
    
    end",Matlab
"I wouldn't use any loops for this. I would write a function that takes *one* score and returns *one* grade. Then I would map that function over a vector of scores using `arrayfun`. It would look something like this:

    scores = randi(100, 25, 1);
    grades = arrayfun(@score2grade, scores);
    
    average_score = mean(scores);
    average_grade = score2grade(average_score);
    
    function grade = score2grade(score)
        if score >= 90
            grade = ""A"";
        elseif score >= 80
            grade = ""B"";
        % ...
        else 
            grade = ""F"";
        end
    end",Matlab
"Can you ask for the original dataset? Without it, it is very difficult to make any sense of this, because a lot depends on how the data is stored and organized in variables.

* Variables `scrsz`, `visibility`, `startYear`, `endYear`, `SNAvals`, `GLORIAvals`, `regLabels`, `SDRdir` are not defined
* `legLab` is defined but never used. Maybe `regLabels` instead?

The code is divided into two sections and they are almost identical, so we can focus on the first section. It looks complicated because it is badly formatted, but it is fairly straight forward. Clean up the code and it becomes more readable.

* `f = figure` part defines and create a new figure window within which plots are drawn.
* `legLab` appears to define the legend for the plots.
* `cl` seems to be list of colors used for the plots.
* `ct` is just a counter that counts the number of loops
* `for cc = [1:20,22:45,47:82]` loops through the numbers 1 through 20, 22 through 45, 47 through 82.
* `subplot(8,10,ct)` divides the figure window into 8x10 sections and places plots in each section in respective loop.
* `for vv=1:5` we have a nested loop that loops through 1 to 5
* within this nested loop, `plot` commands plot two set of plots overlaid on one another, as indicated by `hold all`.
* In either case, the data is plotted with years in x-axis and for y-axis it is extracting a vector from `SNAvals` or `GLORIAvals` based on the columns and third dimension defined by loop indices `cc` and `vv`.
* `xticks(startYear:5:endYear)` adds ticks on x-axis at 5-year intervals
* `a = get(gca,'XTickLabel')` extracts the labels assigned to x-axis ticks.
* `set(gca..` sets the font size to 4.
* `xtickangle(90)` rotates tick labels on x-axis.
* `title(...` adds the title to the plot.

Good luck. Writing your own code may vastly improve the original code if you follow proper coding practices.",Matlab
"You could output 23 actions from the actor network then concat the negative of the actions in the environment. 

You could also architect the actor network to do the same thing using a concatenation layer and scaling layer with scale == -1",Matlab
"It appears that the symbolic method failed to find a symbolic solution.  
So you could shift to a numeric approach.  Take a look at the docs for ode45:  
[https://www.mathworks.com/help/matlab/ref/ode45.html#bu3uj8b](https://www.mathworks.com/help/matlab/ref/ode45.html#bu3uj8b)

namely ""solve nonstiff differential equations"" to see an example of the system set up.  
I believe the phase portrait refers to the plot of the solution (x(t),y(t)) .  
If you follow the example in the docs then 'plot( y(:,1),y(:,2))' should give it.  
Although it could mean the phase trajectories  (ie. x(t),y(t)) from a number of initial conditions.  
in which case you need to solve the equations over a number of initial conditions and plot.",Matlab
"The problem with books is they’re usually behind all the recent updates, so while they can be a great intro, I think you’ll see limited use at the “intermediate” level- especially if you want to focus on DSP. 

My recommendation is to skip the books and dive into the documentation. There’s even a Signal Processing On-ramp to get you started for free.",Matlab
"I'm not going to do it for you, but I will point you in the right direction.

1. floor() takes in a numeric quantity but you're passing in a character array.  It's not going to do anything.  You need to give it a number.
2. fprintf() needs both the format string and then numbers to populate it.  I have no idea what 'HH:MM:SS' is supposed to be doing, but it's not a valid fprintf format string.  You need to read up on the documentation for fprintf.  As a hint, try something like this: fprintf('%2.0u:%2.0u:%2.0u', hours, minutes, seconds);",Matlab
"I think it's worthwhile to learn how to use the fprintf function, but it's definitely an older way of doing things. Take a look at the doc examples of fprintf for how to set up the formatSpec string and how to pass the extra inputs.

But if you're curious, a more modern way would be to use the built-in support for duration values, e.g. the ""seconds"" function:

    dur = seconds(time_in_seconds) 
    dur.Format = ""hh:mm:ss"" 
    TimeHMS = char(dur)

The last line just converts the duration value to a string, which normally isn't necessary. But I'm assuming the grader is checking for a character array and not a duration value.",Matlab
"What specifically is the problem? If it is MATLAB, then try the on-ramp [here](https://www.mathworks.com/learn/tutorials/matlab-onramp.html). If it is linear algebra then you will have to pull out the text books.",Matlab
"I have a few comments

1. Your logical expression is outside the find command, so all you are returning is a logical array of true values, because any output of find (0 or 1) will always be less than 20. Your logical expression needs to be inside the parenthesis.

2. Why are you splitting up the A matrix into 4 commands separated by `&`? The find command can give you row and column numbers if you request two output arguments. I suggest reading the documentation for `find`. https://www.mathworks.com/help/matlab/ref/find.html

An example:

    A = [1 2; 3 4]
    [r,c] = find(A<3)
    r =
    
         1
         1
    
    
    c =
    
         1
         2

So, if you put the row and columns together, you find that A(1,1) and A(1,2) are less than 3. I hope this helps",Matlab
"This is a **rant**, but why do people teach students use `find`, instead of logical indexing? Using find in this way is very inefficient and lead to bad coding habits. 

Some hints. 

    A = randi(19,10,10); % generate random matrix of integer < 20
    A(3,:) % the third row
    A(:,2) % the second column
    A(end-2:end,1) % the last 3 elements of the 1st column",Matlab
"I’ve also had similar issues with UDP and trying to run Simulink real-time. This was also for a flight simulator. 

However, I was having issues with the UDP Receive block that was dropping or not receiving the packets despite the source clearing blasting UDP at ~50Hz. Our simulation could normally keep up with real-time except when clicking around in Simulink blocks, the simulation would slow down. Our troubleshooting made us believe that something was going on with the Windows UDP buffer. It may have been overflowing since we were blasting a bunch of packets and the simulation was only running at 50Hz.

Are you running the simulation using the Real-Time Desktop toolbox installed AND the required system kernel? I don’t know if the kernel will help.

What we ended up doing was code generating our simulation into C++ and running the code within a real-time framework our company has. That’s resolved all of our issues with UDP traffic. You could probably do the same thing using FreeRTOS and schedule the simulation step as a real-time task. Alternatively, I think the preferred approach using Simulink is to use Speedgoat real-time hardware which is designed to network with Simulink.",Matlab
With Codegeneration we were able to achieve 1000hz in combination with dSpace HiL environments and UDP… another solution for your sampletimes are FEP3 https://github.com/cariad-tech/fep3_sdk unfortunately the MATLAB Simulink Toolbox isn’t Open source but you could integrate the FEP SDK in the generated code.,Matlab
"Thank you both for your answer. My professor's syncronization block is generating code in C++ and it has worked great till now, I'll check your options out :)

I find it weird that many times my simulation time goes perfectly with the flight time received UDP from the flight simulator, when the problem happens I am not clicking any block and the simulation time is linearly slower from the beginning! That's weird, simtime keeps the same inclination, nothing changes while running. Was it like this when you experieced the overflowing of the UDP receive block? Or did the simtime have some changes?",Matlab
"The error message is telling you that you are trying to access an array with an index greater than the array length...probably on line 209.  
If you look closer on line 208 in the for loop,  n  can be length(EKGsignal)     
nonzero1cyc array's length is less than or equal to that length, but you have an index that is length(EKGsignal) + 1...so your index is out of bounds.  
hope that helps",Matlab
"https://www.mathworks.com/help/matlab/ref/diff.html says “If X is a vector of length m, then Y = diff(X) returns a vector of length m-1.” Basically, using diff chops a value off the vector.

ETA and here’s the article on linspace, which has some examples: https://www.mathworks.com/help/matlab/ref/linspace.html",Matlab
"I'm working on a release trial 2022b.

I'm trying to run a code written on a release 2019b that works fine on release 2021b.

On my PC with version 2022b the code doesn't run, the error is:

Error using ‘ (line#) Undefined function ‘ctranspose’ for input arguments of type ‘table’. Use the ROWS2VARS function instead.",Matlab
"I wrote an extension to the `containers.Map` function that allows reverse lookup- that is, the key gives the value or you could give the value and get the key (obviously this is limited to when the value was scalar and unique). The problem is, it's very slow. Is there a faster way of doing this with dictionaries perhaps?",Matlab
"This looks convenient, particularly with the building functions for using it as in the examples you've given.  

I'm not sure I really understand the difference between using this new data type vs just using existing data types, e.g. having *gym* comprise *gym.names* and *gym.weights*, and having similar functions to work with that?  I'm not doubting that there is an advantage just hoping to gain some insight.",Matlab
"When you call `read` or `readall` on a `datastore` object, is the result a table? 

I often have to read in multiple files that each have ~500,000 rows and ~30ish columns of mixed type and end up with this 3 million row table, that I then do a lot of filtering on, and grab out the numeric data from certain rows, to perform my calculations. Once the tables are in, things actually run relatively fast. But the problem comes in both loading the tables (takes a while), and then you can't save your workspace with giant tables, because then it has to switch the the 7.3 format, and it takes up to 30 minutes to save, while making these 30 GB files on the hard drive. So, between every session I have to delete the table, and then reload it. 

I'm wondering if switching to a `datastore` would alleviate some of this pain.",Matlab
"Well if you do not post the modified code, i do not see how anybody could help. 

 So far what I understood about you problem is 'here is some code. I modified it and it does not work anymore'... 

 So if the original code was working, the conclusion is that your modifications are not correct.... But how the hell could we guess that by looking at the original code? You could have been doing any error...",Matlab
Eliminate the else and it's statement (lines 12 and 13) because in line 6 you already did what you are repeating in line 13. Eliminate the indentation in your last line (15 ) so it is out of the if loop and should work.,Matlab
I have tried to screenshot on pc but it won't work. I have tried windows key+S+shift and prtsc but it won't screen shot. I do have to go through a virtual desktop app to access matlab. Is there another way to screenshot it?,Matlab
"I have tried adjusting the graph from ./1000 to ./1500 and ./2000 to remove the 0.5 like I did with the other graphs but it won't work for this one. How can I fix it? 

I also noticed that Comal and Dallas overlap each other yet their data is different Dallas should be higher up. What could I do to fix that?",Matlab
"Per [https://www.mathworks.com/help/matlab/ref/webread.html](https://www.mathworks.com/help/matlab/ref/webread.html), webread takes `options`. 

    data = webread(___,options)

And you can define options using [https://www.mathworks.com/help/matlab/ref/weboptions.html](https://www.mathworks.com/help/matlab/ref/weboptions.html)

    options = weboptions(Name,Value)

Therefore the worklow is:

    options = weboptions(Name,Value);
    data = webread(___,options)

One of the parameters you can define in the options is `'Timeout'`, and by default it is set to 5 (secs). Increasing the timeout is probably the easiest approach. 

Good luck.",Matlab
"Ok, Ive figured it out on Manjaro, which is another arch based distro. For MANJARO, I had to delete the 2022a install manually and then download the 2022b installer.

I moved the installer to a folder i named Matlab-download in the Downloads folder. I openned teminal in that folder and then ran the command: 

`unzip -X -K matlab_R2022b_glnxa64.zip`  

to unzip it.

after using that you need to run

`rm ./bin/glnxa64/libfreetype.so*`

After that the installer should work properly.

&#x200B;

Right now im working on fixing another issue with matlab. let me know if this fixes your issue",Matlab
"A few things:

1. As written, your first line is incomplete. I'm assuming you just typed it in to reddit wrong. 

2. `diff_M` will be `[M(2)-M(1), ... , M(end) - M(end-1)]`, which means it has length one less than the length of M, which has the same length as T. This is why you got that error. 

3. You're plotting T on the ordinate and diff_M on the abscissa. Are you sure that's what you want? 

4. `diff_M` is only the difference between consecutive entries of M. Are you sure you don't want the (approximate) derivative? They're not the same thing. 

If you wan't to plot the derivative of 1/T, you should learn about [anonymous functions](https://www.mathworks.com/help/matlab/matlab_prog/anonymous-functions.html). If you use them right, you don't need to make a vector of T's at all:

    M = @(T) 1./T;
    Mprime = @(T) (M(T+1e-4) - M(T))/1e-4;
    fplot(Mprime)",Matlab
I have the exact same problem. I also tried to install it on a new arch laptop but I get the same errors. Oddly enough a couple weeks ago I successfully installed matlab on my desktop which also runs arch. I guess there's a package installed that is missing on my laptop and your system but I don't know how to find out which one it is. Hope someone else can help,Matlab
"Some hints:
- You already know the length of vectors you will use, so preallocate the memory space you need. `f=int32(zeros(1,49));` and so on...
- You don't have to use 2 vectors `f` and `y` to store Fibonacci numbers. All you need is the sequence of Fibonacci numbers up to k=49.
- `hold on` is a command used in plots. It makes no sense here.
- If you use `Value=f(k)/y(k)` in the `for` loop, the old value is actually replaced at every loop. You have to use a vector of length (49-1) to store the ratios.",Matlab
"Hello, this is an important topic and I personally don't have experience in climate data, I did use Mapping Toolbox to plot geography data [https://blogs.mathworks.com/loren/2016/01/20/mapping-uber-pickups-in-new-york-city/](https://blogs.mathworks.com/loren/2016/01/20/mapping-uber-pickups-in-new-york-city/)

However, for climate data, there is Climate Data Toolbox   
 [https://www.mathworks.com/matlabcentral/fileexchange/70338-climate-data-toolbox-for-matlab](https://www.mathworks.com/matlabcentral/fileexchange/70338-climate-data-toolbox-for-matlab) and that may be closer to what you are interested in. There are YouTube videos that walk you through how to use it.

Good luck!",Matlab
"The second one is better because of readability. Better yet,

    B = arrayfun(@someFunc, A);

People obsess over marginal ""performance"" differences when 99% of the time it doesn't matter at all. Go with what's most readable or intuitive.",Matlab
"Iirc when it comes to multidimensional arrays, it is preferential to populate down a column due to memory 'location'. If you have a 2D array and populate it starting at column 1 row 1, and move down to column 1 row 2, etc, then you are populating memory locations that are next to each other.

If you started at column 1 row 1, then populated column 2 row 1, etc, then you are jumping around. This will be slower than the previous way.

I'm sure someone will come along and correct me here if I've gotten this wrong.",Matlab
"Nested loops actually slow down Matlab a lot on large data sets and arrays.  This is because each loop creates a new copy of the output receiving variable while deleting the prior loop's copy.  Additionally, when the function is executed, it will create a new workspace each time while copying the arguments into the new workspace (since Matlab does not pass arguments by reference).  So the second option can be significantly faster by reducing the number of copy operations.  Most of the Matlab included functions will work in multiple dimensions with one function call, and this should be used where possible/reasonable.",Matlab
"> I also get this error:

> Error in surfaceBalloon (line 4)

> surfaceBalloon = (pi * R^2) *(2 + sqrt(1 +M.^2)) 

The error says more than that. The error message will have another line explicitly saying what the problem is. Include that in your question. 

Also, let us see your code. Without seeing your code, it's impossible for us to help.",Matlab
"You know V and M. That means you can calculate H. You can also get an equation to calculate R by doing some algebra. Once you know R, calculate A. 

What is the entire error message you got? 

I think I did this exact same Zybooks problem when I was in a Matlab class 2.5 years ago.",Matlab
"My guess is since true is a built in function name, when you overwrote it, matlab was calling that one instead when it was loading/booting, and it wasn't doing or returning what it was supposed to, so it got borked.",Matlab
"This is a very cool idea. I sometimes DJ for a social event and I have a mess myself. I have Windows 10 and you may have to do it it a bit differently if you have a Mac. I used [audioinfo](https://www.mathworks.com/help/matlab/ref/audioinfo.html).

If you convert `char` to `string`, you can use `arrayfun` instead for loop.

    loc = ""C:\Users\username\Music"";
    s = dir(loc + ""\*.mp3"");
    mp3files = arrayfun(@(x) string(x.name), s);
    meta = arrayfun(@(x) audioinfo(loc+""\""+x), mp3files);

If you haven't used string arrays, read more about it in my recent post. [https://www.reddit.com/r/matlab/comments/x9i2sa/whats\_the\_benefit\_of\_a\_string\_array\_over\_a\_cell/](https://www.reddit.com/r/matlab/comments/x9i2sa/whats_the_benefit_of_a_string_array_over_a_cell/)",Matlab
"Try to separate the game logic from the UI. For the game logic, you essentially just need to write a function that takes a matrix of 1s and 0s and checks whether there are any four 1s connected in a line. My first thought would be to convolve the matrix with the following four kernels. If you get any 4's in any result then you know there must be four 1s in a line. 

    [1 1 1 1]
    [1 1 1 1]'
    diag([1 1 1 1])
    flip(diag([1 1 1 1]))

After that it's mostly just a matter of coding up some sort of UI, which can be as simple or complex as you like depending on the features you want. After each turn, use the function you wrote to check if the player has won. There's a bit more logic and maybe some special cases that you have to think about, but that's the bulk of it.",Matlab
"Well, to create your example array you could just do

    x = [0:0.2:1, 1.5:0.5:3, 5:5:50, 60:10:100];

If you wanted to do it not quite so manually, then I would look for a function that approximates what you want, where you can pass in uniform numbers and receive back numbers with an increasing step size.",Matlab
"If you plot the numbers in your example as a function of their position, you'll see that the resulting function is strictly increasing and convex. This should give you a clue for one way to proceed:

1. Create a vector x of N increasing evenly spaced points, where N is the total number of points you want to have. For example, x = linspace(0,1,N).
2. For some strictly increasing convex function f (you can choose f to be any strictly increasing convex function you like, where different f's will provide different arrangements of spacings), let y = f(x).
3. Re-scale the output so that points range from 0 to 100: y = 100*(y-y(1))/(y(N)-y(1)).

A particularly easy one to implement would be:

    x = linspace(0,1,N);
    b = 2;      % parameter b>1 controls convexity (higher=more convex)
    y = 100*x.^b;    % using the power function for f;
                     % note the .^ (not just ^), so that we apply the 
                     % function element-wise to x
    plot(x,y)    % plot relationship

Given that x ranges from 0 to 1 here, so will x^b, and therefore y will range from 0 to 100. Thus, we don't actually have to bother with the re-scaling step in this case.",Matlab
"While I would usually recommend finding a matrix solution, This is a good opportunity to practice using a while loop.


arr =[];

n = 0;

d = 0.1;

while n <= 100

   arr(end + 1) = n

   n = n;

   d = d * 2;

end


This would create a geometric growth of the array. You could change this to another method you prefer.",Matlab
"Typically, you get Simulink model that works with the microcontroller and you can load it using [open\_system()](https://www.mathworks.com/help/simulink/slref/open_system.html) command.

More details 

[https://www.mathworks.com/help/mcb/gs/hardware-connections.html](https://www.mathworks.com/help/mcb/gs/hardware-connections.html)

Examples

[https://www.mathworks.com/help/mcb/examples.html?s\_eid=PRP\_24999](https://www.mathworks.com/help/mcb/examples.html?s_eid=PRP_24999)

Good luck.",Matlab
"What exactly are you trying to do?

Typically, the first input arg is a column vector and you get a group count, as you already know. If you pass a matrix in the first input arg, you are asking it to shape the output in a different ways. In this case, by passing \[1,2,3\] , you are  asking it to return the result in 1x2x3 3D matrix. Why on earth anyone wants it I have no idea, but you can do it if you want to.",Matlab
"Apart from using interp1(), also read up on how you can import simple datafiles easily with readmatrix() or readtable().

Also check how you can make arrays quickly by yourself https://www.mathworks.com/help/matlabmobile/ug/creating-matrices-and-arrays.html specifically the one example using ‘:’",Matlab
"Here is an example. First, I plotted the curve to see if this is something we can interpolate.

    temp = -40:5:40;
    voltage = [2.44, 2.42 ,2.4, 2.38, 2.35, 2.32, 2.27, 2.23, 2.17, 2.11, 2.05, 1.99, 1.92, 1.86, 1.8, 1.74, 1.68];
    figure
    plot(temp,voltage)

The plot shows a curve that we can use curve fit on. Since our inputs are row vectors, we need to [transpose](https://www.mathworks.com/help/matlab/ref/transpose.html) them into column vectors and then use [fit](https://www.mathworks.com/help/curvefit/fit.html).

    f = fit(temp',voltage','poly2');
    figure
    plot(f,temp,voltage)

The fitted curve is very close to the actual data. You can use [feval](https://www.mathworks.com/help/matlab/ref/feval.html) and more granular new temp to generate new values for voltage. 

    new_temp = -40:40;
    new_voltage = feval(f,new_temp);

I hope this helps.",Matlab
"The `val ` *is* an instance of the class. Just like with Python, the name of the variable does not matter. The first argument of a class method is always the object that calls the method, the only exception being class constructors.",Matlab
"I think this might be something that differs between ""value objects"" and ""reference objects"". Value objects behave like you describe, I believe: their methods have to take the object as input, and they have to return a new object as output (obj = obj.myMethod(obj,input);).

Because this object you're working with subclasses ""handle"", that makes it a reference object instead of a value object, as a different rules apply. I don't know much more, but hopefully that gives you the search terms to find what you need.",Matlab
"In MATLAB, you have two types of class. 1) value class 2) handle class.

In this case, in the class definition, it is defined as a handle class `classdef myClass < handle`, which means you are creating a child class based on handle superclass. Without this, the class becomes a value class.

Inside the handle classes, you define `properties`, which are like variables in the normal script or functions, but are associated with the object. So you can see the values like `obj.a`, `obj.b`, etc., like as if it is a struct.

When you use a class, you need to instantiate it as an object, like `obj = myClass(a,b)`, and there has to be a method for instantiating an object. This is called constructor method.

There is `methods` section inside the class, and the first method you define is the constructor, and it always takes a form `function obj = myClass(a, b)` using the name of the class itself - you can't use a different name, like `somefun`.  Input arguments are then used to populate the properties of the instantiated object. If you do not specify a constructor method, then the constructor method in the superclass will be inherited, and all it does is to return a object populated with the properties using input arguments.

You can add more methods in the class, but those methods takes the form of `function outargs = somefun(obj, inputargs)` \- not that it must refer to the object.

    classdef myClass < handle
        properties
            a
            b
            c
        end
        methods
            function obj = myClass(a,b,c)
                obj.a = a;
                obj.b = b;
                obj.c = c;
            end
            function out = somefun(obj)
                out = obj.c + obj.a + obj.b;
            end
        end
    end

To instantiate

    myObj = myClass(1,2,3);

To use the object

    result = myObj.somefun()
    result
        6

I hope this is helpful.",Matlab
"Check out file exchange https://www.mathworks.com/matlabcentral/fileexchange/34908-connect-4-a-game

I recommend the online courses that you can take through the university. https://www.mathworks.com/academia/tah-portal/fundacion-universitaria-navarra-31578545.html “Get free access to online courses”

Hope this helps and good luck",Matlab
"  
Take a very close look at the conditions for good bars on line 18.  
You want the condition to be true if the measurements are \*within\* specification.  
I also didn't see a check for weight.  
My guess at 28 30 and 32 although I'm not sure of the second parameter in the mean function, but the first parameter is the boolean vector  (eg. 0 and 1).  I'm quite sure you want measurements that are within the specification.",Matlab
"Hey, double check your conditions for line 18, paying particular attention to width and height. Do you need to isolate those whose width is *between* (3.98,4.02)? Do you need to isolate those whose height is *between* (1.995, 2.005)?",Matlab
"I've never used it. However, quick search through the documentation shows that VideoWriter is a class and writeVideo is a method of the VideoWriter class. This means that you don't have to pick. Create a VideoWriter object, then use writeVideo on that object.",Matlab
"I appreciate the responses.  I'm not well educated regarding object oriented coding methodology, so the doc was a bit opaque to me.  These explanations will have more wide-spread utlility for me.  Class->Object->Method .  Cheers,/jd",Matlab
"You may want to look at   


    TargetRange+(SpeedofLight*rem(tt(ii),3))/2; 

tt(ii) goes in steps of tsampling   so rem(tt(ii),3)  is always tt(ii) for your example.  
SpeedofLight\*tt(ii) is the total distance traveled up to t(ii), not the distance change.  
One approach if you have a known signal that repeats is to form one period of the signal in a vector and then repeat it using repmat().",Matlab
"I use matlab to manage a database of research data files. I have matlab code that inventories new files, finds duplicates, extracts metadata about the files, renames them, puts them in an archive directory, and uploads metadata to the Posgres DB.

I also used matlab to train image recognition models for a variety of simple video classification tasks to help categorize unlabeled data videos.

I also used matlab to train a somewhat more complex (in some ways; simpler in others) model to identify behavioral micro-states in mice from body part tracking data.

I've also used it to model WWII rotor cipher machines for fun.. and much more besides.",Matlab
"I have used Matlab for a few non-work related stuff in our lifes, e.g.:
- Create a Matlab plot of our wedding ring (our ring has a sinusoid wave pattern) so that we can let the engravers know where the engravings should be (wedding date and our initial) relative to the peak of the sine wave.


- We have a list of wedding guests in an excel sheet and we need to print out labels for the wedding invitation letter which include the guest names and their addresses. The label was to be printed from an excel. It's laborious and prone to human error to write it by hand or to copy-paste the name and address from one excel sheet to another. So I wrote a Matlab script to read the guest names and addresses from one excel sheet and then write them to the label excel sheet (with preformatting and stuff). Then we can just directly print out the label excel sheet into a label paper without additional work. Of course, attaching the label is still a manual work, but at least we don't have to bother writing every single one of them.


- We have a side business which uses a third party software that generates its a few reports from the business such as machine usage, employee orders, and gratuity in a csv and excel format. In the end, we have to consolidate these info so that we can import it to our own excel sheet to determine income/expense, tax, and payroll. We have to do this every two weeks (biweekly payroll), and it takes 3-4 hours to do manually. So I wrote a Matlab script to parse through the report, and convert it to a format that our excel sheet can directly take.",Matlab
"I just played around with `uigetfile` a little and notice that when you turn on multiselect, it just returns a 1xN cell array where each cell is the filename. So

    file = uigetfile(MultiSelect=""on"");
    length(file)

That seemed easy... Am I missing something?",Matlab
"Sometimes if it truly is thousands of files, I’ll just make sure they’re in their own folder and call dir([folderName ‘*.png’]) or whatever the extension is. If I need different data sets, I just change folderName (or use uigetdir)

and then call length() on the output of dir()",Matlab
"You can do it this way. This is just one ""quick and dirty"" way and there are many other better options.

    url = 'https://finance.yahoo.com/quote/AAPL?p=AAPL&.tsrc=fin-srch&guccounter=1';
    webpage = webread(url);
    webstr = string(webpage);
    div = extractBetween(webstr,'<div class=""D(ib) Mend(20px)"">','</div>');
    tbl = table;
    tbl.dataSymbol = extractBetween(div,'data-symbol=""','""');
    tbl.dataField = extractBetween(div,'data-field=""','""');
    tbl.value = str2double(extractBetween(div,'value=""', '""'));
    tbl

And this is what I get.

&#x200B;

|dataSymbol|dataField|value|
|:-|:-|:-|
|""APPL""|""regularMarketPrice""|157.37|
|""APPL""|""regularMarketChange""|2.91|
|""APPL""|""regularMarketChangePercent""|0.01884|
|""APPL""|""regularMarketTime""|NaN|
|""APPL""|""marketState""|NaN|

I hope this helps.",Matlab
"The assignment tells you directly what to do (replace calls to the `input` function with your function arguments), so the next step is to read Matlab documentation on functions to see how input and output arguments are declared and used: <https://se.mathworks.com/help/matlab/functions.html>.",Matlab
"> Cell In [35], line 135, in ConvVAE.shape_computation(self, x)

> 129 print(f""Flattened encoder output shape: {x.shape}"")

> 131 # parallel_net = parallel_net.to(0)

> 132 # model.to(device)

> 133 # mu = self.mu(x).to(0)

> 134 # logvar = self.log_var(x).to(0)

> --> 135 mu = self.mu(x)

> 136 logvar = self.log_var(x)

> 138 print(f""mean shape: {mu.shape} & logvar shape: {logvar.shape}"")


It looks like the method shape_computation is changing the device",Pytorch
"There is no way you are using 64-bit on the GPU.

All the CuDNN code is 32-bit for the very simple reason that non-Tesla GPUs have between 1/32 to 1/64 FP64 throughput compared to FP32.

See https://www.reddit.com/r/CUDA/comments/iyrhuq/comment/g93reth/

So under the hood your FP64 stuff is converted to FP32 when sent to GPU.


And on Tesla GPUs the ratio is 1/2.",Pytorch
"A Receiver Operating Characteristic curve is produced by plotting the true positive rate against the false positive rate for a variety of threshold values of a binary classifier. The fact that it's a 3D CNN is not relevant.

When calculating the ROC curve, having a threshold low enough to give you the point at (0, 0) can result in a bit of numerical weirdness, same with the point at (1, 1). You should consider inserting those points manually.

Unless your issue is that you're not *starting* at (0, 0), you're *ending* at it, which is actually normal; the lowest threshold values are associated with the upper-right-hand portion of the ROC graph.",Pytorch
"I would recommend the first option. The instructor takes a programmer’s perspective while teaching how to use PyTorch. The second video has too many references to other tutorials and web pages. At times, the instructor spends time on theory of the deep learning concepts. So if you are interested in a quick walk though of PyTorch, the first video would be my recommendation",Pytorch
"It's because the data loader calls `dataset[idx]` but that doesn't work on data frames. For example `df = pd.DataFrame({""a:[1,2,3], ""b"":[4,5,6]}); df[0]` will give you the same KeyError.

To correct it, create a new class that has the data frame in it, and implement the `__len__` and `__getitem__` methods and pass that to the data loader.",Pytorch
"This might be helpful

https://discuss.pytorch.org/t/how-to-modify-the-input-channels-of-a-resnet-model/2623

https://discuss.pytorch.org/t/transfer-learning-how-to-modify-the-first-conv2d-layer-of-alexnet-to-accomodate-for-9-channel-input/4063

Basically you need cut out the first layer as well as the last layer then create a sequencial model with first layer being a 2 channel convnet followed by the cut out model then a last layer with the number of classes that you have

The examples in the links above are for 4 and 9 input channels but can be modified for arbitrary number of channels",Pytorch
"You don't need to store backprop gradients manually. The parameter tensors' grad field is populated when backward is called (via DAG). PyTorch handles them automatically and clears them after optimization. 

Now coming to your question, what is your model and what GPU are you on?",Pytorch
"Just load the model for inference, see how much memory it occupies. Then tweak the size of your batches. 

To be fair, it may be difficult to train a network on MNIST even with 4gigs if the network is averagely complex.",Pytorch
"Squeezing a neutral net onto a GPU with under 4GB of VRAM to work with is going to be pretty limiting. Even GPUs with  12GB (k40, rtx 3060, etc...) have a hard time fitting basic pre-trained models into their memory (eg; ResNet-50 takes around 10GB). It can work for basic nlp models / structured data, but forget images. 

Try extracting features on the CPU (assuming you have more RAM there), doing PCA to reduce the dimensionality, then training on GPU with those.",Pytorch
I’d like to add that sometimes deleting variables no longer used (del my_var) and running garbage collection have been successful for me (import gc; gc.collect()) as well as clearing cache on the gpu. Just my $0.02,Pytorch
"I think you should explain more about what you are trying to do, and perhaps spending some time on toy projects to gain more experience in pytorch and ML before trying to dive straight in.

It's unclear what sum((6==5)) is trying to do.",Pytorch
You could make a tensor with a dim for every possible value and then multiply it with 1 if equal else with zero. creating a mask of sorts. It is totally if the mask isn't differentiable. The final loss will be.,Pytorch
"It looks fine, but if you wonder about the increase, from my experience it is because of the high LR. Are you using LR scheduler there? Might reduce the max LR.

But that is not a big problem if the curve converges tho so don’t worry",Pytorch
"If you're computing and plotting True Positive Rate by False Positive Rate correctly and your detection threshold goes from one extreme to the other, the curve should have (0,0) at the start, because it describes a decision threshold in which the model *rejects* all data points.

The decision threshold should start before the lowest score and end after the highest score to include the extremes where all samples are either rejected or accepted.

A TPR of zero means there's *no true positive* detected.

An FPR of zero means there's *no false positive*.

So in other words, at (0,0) everything is either a true or a false *negative* (e.g. model rejects everything, whether that's correct or not). That happens when the decision threshold is beyond all scores (lower or higher depending which metric you're using).

As the threshold goes from one extreme to the other, the number of true positives (TPR) and false positives (FPR) increases until these rates are both 100%, at which point everything is either a true or a false *positive* (e.g. model accepts everything, whether that's correct or not).",Pytorch
"Conjecture - due to complexity of the model it need some optimization iterations to get a ""somewhat good"" location in parameter space where it find a spot which generalizes well. 
Maybe your loss function misses (or simply does not emphasize it's importance) some fine details which could explain why the training loss does not behave similarly. This is just me in the tank so everything should be taken with a mountain of salt",Pytorch
"Usually you use it if your loss landscape is too steep at a few points.  This can cause your gradients to be massive, in turn causing a massive step, which can ultimately lead to your weights overflowing.  

The most common presentation of this issue is seeing NaNs, so when I have NaNs in a Project I will often times implement gradient clippin",Pytorch
"Your batch size is 32, thus your input is of shape (32,784). Computations will be done in parallel, so it means, give me the input of shape (1,784) then I will handle the parallel computation for you.

Regarding the weight’s shape, it is (out_features, in_features). I don’t know why they decide to do this https://pytorch.org/docs/stable/generated/torch.nn.Linear.html

So the multiplication of Linear is (1,784) x (784,100), and done in parallel for 32 elements.",Pytorch
"I would delete this post as I've solved it myself, but I'll put it here and explain why my idea doesn't work well anyway.

I would give my model a parameter of ""R_number"" (Say, 8), which is how many steps I would wait before I calculate my loss. 

I would then append predictions and actuals until I had as many steps saved as that number. When I did that, I would calculate and return a loss based on all 8 steps.

If I didn't have that many, then if you return None it skips loss calculation (and backprops).

The reason this was a stupid idea for me is as follows:

I have a batch size of 1. I still have to generate all those gradients and backprop which I couldn't do previously.",Pytorch
"    dataset = Aset(
                    path,  
                    transform=transforms.Compose([heart()])
            )

have you tried to create an object/ instance of heart class before passing into your Aset class? like:

    my_heart = heart()
    dataset = Aset(
                path,  
                transform=transforms.Compose([my_heart()])
        )",Pytorch
"1. is your data mix of both scales?
2. depends on your dataset

the function is just transform your data into a same range/ scale.

check this: [https://stackoverflow.com/questions/65676151/how-does-torchvision-transforms-normalize-operates](https://stackoverflow.com/questions/65676151/how-does-torchvision-transforms-normalize-operates)",Pytorch
"`tgt` is perhaps the worst named parameter in the entire library, as it really does not make it clear as to what it is. `nn.Transformer` implements the original Encoder-Decoder structure transformer proposed by Vaswani et. al. The first block, the encoder, computes self-attention between the elements of the input sequence. The second block, the decoder, takes in two sets of inputs: the sequence from the encoder, and a set of queries to the decoder. It's this set of queries that should be passed in as `tgt` to `nn.Transformer`. Not every model uses both components, some use only the encoder, some use only the decoder, and some use both. You need to figure out what gets passed to the decoder as the queries. If the answer is ""nothing"" then you probably want only the encoder.",Pytorch
"I may be wrong but this is over thinking it. All portrait photos taken with the recent iPhone models actually contain depth map by themselves. The rest of composition and rendering is pretty straightforward -- check foreground then insert time / weather after it, if it is not overly occluded, otherwise put the text in front of the foreground.

Salient object detection would definitely work, but I don't see a reason as an Apple's PM would spend so much effort on developing this minuscule feature with unpredictable accuracy. ps. with apple's proprietary RGBD photo I would lock the users to use iPhone, and it is more accurate than salient object detection anyway.",Pytorch
"Regarding your problem in general: you might see better results by using permutation equivariant and (if needed) permutation invariant transformations in model instead of augmenting through adding permutations.

Problem from [this paper](https://arxiv.org/pdf/1612.04530.pdf) looks very similar to yours by structure, they needed permutation equivariance as well, the only difference apprently is that you need to reverse order of outputs in some cases?

Other relevant papers:

\- [https://arxiv.org/abs/1611.04500](https://arxiv.org/abs/1611.04500) 

\- [https://arxiv.org/abs/1703.06114](https://arxiv.org/abs/1703.06114) 

\- [https://arxiv.org/abs/1810.00825](https://arxiv.org/abs/1810.00825) As I understood, set transformer is useful when not only permutation invariance is needed, but output also depends on some kind of interaction between set elements",Pytorch
"Normally, validation doesn't just involve computing the loss, it also involves computing some non-differentiable metrics (such as accuracy). Validation is also usually a lot faster than training since it's usually a smaller split and you can run under no\_grad or inference\_mode which are much faster too. It also gives you an opportunity to check that your model yields the expected results of a random model.

You don't *need* to run validation first. But it can be helpful, particularly if your training process is very slow. A crash in validation after 5 minutes is annoying, a crash in validation after several hours of training will make you want to throw things.",Pytorch
"Did you try to install it in a brand new virtual environment? Looks like some other packages are colliding with it.

A few other things:
1. Looks like cuda 11.6 is the newest release, if you have a newer version of cuda installed that should be just fine.
2. It doesn't look like any recent pytorch releases only support python 3.7+",Pytorch
"Haven't done much on torch, but while running TF OD API, I usually run the validation on my CPU (since it's scheduled for every 1000 as against training for every 100 steps)... I get to see the training and validation metrics on Tensorboard and Inference on validation set... This determines when I stop training to avoid over fitting..... I do generally have a separate hold out set for offline evaluation.... IMO, the sanity check on evaluation set, gives you a handle on how the model is learning....",Pytorch
"I started my career by working in data ~Sciencygineering in 2016 and still going.. in these years all the MLengineers Data engineers i have ever known started their career with exactly same knowledge if not less. 

Working knowledge of 

Docker, kubernetes is needed for containerised deployment.
Apache Airflow is required for ML ops pipeline 
Python(numpy, pandas, sklearn, scipy, tensorflow, pytorch, nltk,spacy,opencv etc and so on ... for actual model, network and mlops pipeline build and monitoring

Python(flask,django)or react based for api dev

AWS  AZURE  GOOGLECLOUD anyone but I started my learning using  Heroku cloud skills are transferable.

Tip for using other cloud services you get free credits and they are basically useless when you are trying to do ml dl work 1 model and the credits are done but if you have already trained your model then these credits can be stretched for some time. I use protonmail to create dummy emails and create new cloud trail environments with free credit.( but frankly heroku is more than enough and its best to get started)

Final advice from experience and learning the hardway:

Don't ever pay a single penny to learn something the best lessons are free and chaos but this chaos makes you the mater of what you learn.
Don't wait until you master everything to interview for a job nobody masters everything.",Pytorch
"As a tutorial on transfer learning this is fine. 

For context, imagenet became the standard after the Caltech 101 was too easy. Using resnet pretrained on imagenet is like using a Tesla to win a horse race. Yes it's better but not surprising",Pytorch
"PyTorch provides layers for those operations as well as objects for training the parameters of those layers.

When you’re done training you’ll have a PyTorch model (composed of the aforementioned layers) whose parameters you can “freeze” (I.e. stop updating) and which you can then use to process new inputs (which is called inference).",Pytorch
"the syntax is each comma-separated element in your brackets refers to a different dimension of your tensor. So you are attempting to select element 0 from the 1st dimension, element 2 from the 2nd dimension, and element 6 from the 3rd dimension, but your tensor is only 1-dimensional, hence your error. You are on the right track though - in that you can select a bunch of indices at once. You just have to pass all the indices to the 1st (only dimension), like so

    t[[0, 2, 6]]",Pytorch
You can use `torch.masked_select`  to directly remove all Nan values. It takes your [input tensors and a boolean mask as inputs](https://pytorch.org/docs/stable/generated/torch.masked_select.html?highlight=masked%20select#torch.masked_select) so you just have to create the mask tensor and you are done!,Pytorch
"Strings are already not differentiable, that's a mathematical concept that only really applies to numbers. You should look up how your model is generating the text, likely word embeddings, and work out how to split it up in that numerical space.",Pytorch
"You can use a model with fewer trainable parameters. Two easy ways of achieving this are:

1. Use a model with fewer parameters. You can either choose to reduce the number of parameters in the layers of the CNN or choose an entirely different model architecture for this purpose.

2. Use dropout and/or regularization layers with higher values.

P.S. Under fitting is when your training loss as well as test loss are high.",Pytorch
"I am currently dealing with this with a very high dropout, so in the first epochs, the test accuracy is much better than train accuracy, for several epochs, the difference is reduced to almost null, and the model does not overfit. I am wondering if this approach is correct and accurate to use, since in the first epochs, test accuracy is higher than train accuracy.

Thanks again !",Pytorch
"I assume you mean python's set(), which shouldn't work, but I think [torch.unique()](https://pytorch.org/docs/stable/generated/torch.unique.html) might work.

Another thing that comes to mind is to minimize or constrain (torch.clamp()) variance of result in the loss, if that's applicable. This might produce more similar words instead of duplicates, though...",Pytorch
"usually after an activation layer: [https://sebastianraschka.com/faq/docs/dropout-activation.html](https://sebastianraschka.com/faq/docs/dropout-activation.html)

you may refer to this 2016 paper: [Analysis on the Dropout Effect in Convolutional Neural Networks](http://mipal.snu.ac.kr/images/1/16/Dropout_ACCV2016.pdf)",Pytorch
"I'm reading paper on set transformers (https://arxiv.org/abs/1810.00825) and there authors are solving task of counting unique characters (see 5.2 in the paper). Wanted to share, might be somewhat relevant.",Pytorch
I like torchvision a lot. I startet to use the detection framework when there was only FasterRCNN. Now there are a lot more models. In my opinion this reference part of torchvision is really important for researchers.,Pytorch
"You could perhaps create a new N+1 fully connected layer for the classifier, then copy the original N weights and biases, and continue training from there.
As for how much fine-tuning a model like that would affect the performance, I'm sure there's a lot of biography about the topic, but the best approach might be trying it yourself.",Pytorch
"Great question and a very realistic scenario.

1. any NN based model or for that matter any model that uses an optimization framework to fit inputs with the outputs (class labels) falls under ""closed set"" machine learning. These algorithms by nature of the math are incapable of incrementally expanding the ""closed set"" (eg: set had 10 labels and now there are 11 labels). Once trained with a fixed set of classes, they always try to map any new class (unseen during training) to the trained set of classes
2. One needs to detect the ""drift"" and re-train the model from scratch with data from all the classes, because of the nature of the optimization framework.
3. The is one body of work called ""open-set learning"" that attempts to map unseen classes to a default class. 
4. One can collect all data that was mapped to the default class, analyze the data to determine class labels and retrain a new model with only these new classes. Lets call this new model as MODEL2. Let the original model be called MODEL1. Then we can use chaining.
5. In chaining, we take the test data-point and pass it to MODEL1. If MODEL1 says that it is unseen class (falls under the open set) then pass this data-point to MODEL2 for it to classify. This way MODEL1 need not be retrained with all data from scratch

I cant see any other option to solve this problem. I would love to hear alternatives to this approach.",Pytorch
"To my naive eye, this seems like a setup for class incremental continual learning. You don't want to forget the previously learned classes, but you also want to learn reasonably well on the newly added class. Does this make any sense for your setup?",Pytorch
"Too bad the performance is measured vs CPU and not some kind of GPU.  Like, how does this stack up against a 3090?  I have no idea what this Mac CPU performance is like compared to any other kind of benchmark.",Pytorch
"Did a quick test myself, I’m using M1 Mac Mini with 16GB RAM, the results are not good. Seems issues is on Apple not PyTorch.

With the same program and hyper parameters, training 1000 steps on CPU took 18 minutes, and only consumed 2-3GB RAM. But on GPU after 15 minutes the machine run out of RAM and terminated, didn’t finish 1000 train steps. Not to mention there are lots of operations that are not supported.",Pytorch
"Yeah, you are stripping all the gradients.  Maybe you could explain what you are trying to accomplish in some more detail.  Generally, data augmentation would happen in the dataloader — anything you do in the forward should be a differentiable operation.",Pytorch
"We have been using pyspark extensively for distributed data munging and feature vector generation. However, while training NN models we need to load just enough data for the batch, instead of loading all data into memory. The approach mentioned in this article works well https://blog.munhou.com/2020/01/16/Data-Pipeline-From-Pyspark-to-Pytorch/",Pytorch
"Try this one:

```
docker run --gpus all -it --rm nvcr.io/nvidia/pytorch:22.01-py3 nvidia-smi
```

The image ships pytorch in a conda environment, cuda version torch and other dependencies. Additionally:

> No other installation, compilation, or dependency management [other than Docker, NVIDIA driver and NVIDIA Container Toolkit] is required. It is not necessary to install the NVIDIA CUDA Toolkit.

So I guess you can ditch Miniconda's version and use this as your base image.",Pytorch
"That error in your title means it was trying to install putorch but could not find and appropriate version / build. Visit three pytorch website and go to the link for installing previous versions, and install the version mentioned in your error message.",Pytorch
"could try this from pytorch lightning, not from pytorch, might need to modify your current codes

[https://pytorch-lightning.readthedocs.io/en/stable/common/early\_stopping.html](https://pytorch-lightning.readthedocs.io/en/stable/common/early_stopping.html)",Pytorch
"[https://pytorch.org/tutorials/beginner/blitz/neural\_networks\_tutorial.html](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html)

Work through basic examples, start easy, understand how pytorch works, learn to work with tensors.",Pytorch
"Remove the for loop and if you want the enumeration, in the input you have implicitly the batch num if my memory isn’t wrong, it’s been a long time I don’t work with ML if not I think the dataloader provides that capability.",Pytorch
"I would not recommend that.
Common rule is to split the data in three. As the test set is not to be until the final model is choose. 
You are like to use the validation set to do early stopping and tune hyper-parameters. This will leak information into the validation set and so the result are likely to over optimistic.",Pytorch
"You can use the pretrained BertForSequenceClassification model for this purpose. I am not sure of the exact name of the API, so check again. Another way to implement this would be to change the fully connected later of the BertModel into a linear layer, which is exactly what I believe is done for the sequence classification model.",Pytorch
"While I haven't gone through your code to scrutinise it, I've dealt with that error before.

In my case I removed any in place modification of a tensor in my model and that got rid of it.

For example I got rid of anything that looked like


A = A * 2

return A


And replaced it with 

B = A * 2

return B

Edit: if you want to track down the error, you can see the version of your tensors at any point in your model with tensor._version",Pytorch
"I solved this kind of error by replacing
```
a += b
```
with
```
a = a + b
```

Counterintuitive, isn't it?
Moreover the original version comes from code that did certainly run at some point with older PyTorch versions. There must have been some kind of breaking change",Pytorch
"You can do something similar to what they did here: https://github.com/lightvector/KataGo/blob/master/docs/KataGoMethods.md#training-on-multiple-board-sizes-via-masking

You basically store a mask of valid positions next to the inputs, and apply that mask after every convolution to keep things in check.",Pytorch
"[pyhf](https://github.com/scikit-hep/pyhf)

This package implements a statistical analysis framework commonly used in high energy physics that uses the auto-differentiation capabilities of pytorch to carry out the optimization for maximum likelihood estimation.  Unlike in typical deep learning applications, the parameters in this type of model are either interesting physics parameters or nuisance parameters that represent uncertainties associated with various aspects of the experimental process and its modeling.",Pytorch
"I often take it out when I'm too lazy to compute gradients myself. E.g., any optimization problem. I also have started using JAX for this type of work as well.

For example I wrote a little extended Kalman filter library where the user specifics motion and measurement functions but they don't need to specify the Jacobians.",Pytorch
"Assuming you have access to the command line, you can force kill anything on the GPU:

/#show GPU details 

nvidia-smi

/#at bottom it should have a list (maybe just 1) job, with a job ID

kill -9 JOB_ID

/# where JOB_ID is the job ID shown after Nvidia smi",Pytorch
"Is this from an RNN? I’ve seen similar gradients on RNNs due to vanishing gradients.

Also it could be an issue getting stuck in local minima, trying to better initialize your weights if starting from scratch could help

Edit: totally missed the discriminator/ generator part but still I guess it might be a vanishing gradient issue if the model is too deep. Check your learning rate as well, or add a more complex scheduler",Pytorch
I often had issues with installing torch using the standard channels. If you go to their website they provide the correct pip and conda install commands. As far as I remember they also provide a list with previous versions,Pytorch
"From the [pytorch previous versions page](https://pytorch.org/get-started/previous-versions/#v110), you can just download the wheel from their site (older versions are not on pypi) and install it. Here are the commands for v1.1.0. 

    # CUDA 10.0
    Download and install wheel from https://download.pytorch.org/whl/cu100/torch_stable.html
    
    # CUDA 9.0
    Download and install wheel from https://download.pytorch.org/whl/cu90/torch_stable.html
    
    # CPU only
    Download and install wheel from https://download.pytorch.org/whl/cpu/torch_stable.html",Pytorch
"Well, you are probably doing something slightly different.  Could be different default values for the optimizer or doing like that.  With identical hyperparameters you should be able to achieve identical results in most cases.",Pytorch
You need to check everything: from the model parameters initialisation to the way you load the data into the model. Check also the parameters of the optimizer are equivalent between frameworks. There is no reason you shouldn’t be able to achieve the same performance because both frameworks do essentially the same.,Pytorch
"If this is their dqn tutorial keep in mind that that method is pretty noisy and will collapse pretty easily. Playing with hyperparameters can help, but if you want something more stable look into other methods. Maybe PPO?",Pytorch
">result = torch.nn.functional.conv2d(z\_test, w, stride=1, padding=0) works but this doesn't use the weights of w, just the shape with the conv2d internal weights, or have I misunderstood?

According to it's documentation it will use the weights you pass in. https://pytorch.org/docs/stable/generated/torch.nn.functional.conv2d.html 

Why do you think it will not use the weights but instead the shape?",Pytorch
"Hi, your link is not working (your repo is maybe private). 
If your loss is not decreasing, lot of things can causes that. Like your network is maybe too limited, or you have a problem in your data. Have you look at your results and the expected results ?",Pytorch
"Pytorch vision has built in something like this: [https://pytorch.org/vision/stable/feature\_extraction.html](https://pytorch.org/vision/stable/feature_extraction.html)

Not sure about language models but u could try declare it 

`model = transformer(args)` 

then try access it 

`desired_layer = model.some_layers`",Pytorch
"1x1 2d conv is a very standard approach for learned channel reduction while preserving spatial dimensions, similar to your approach but no flatten and unflatten required.

You’ll see it in a lot of image to image regression papers doing similar things.

https://paperswithcode.com/method/1x1-convolution",Pytorch
"You can’t combine both memory pools as one with just pytorch. Furthermore both are different gpus so sli is out of question. Deepspeed memory offload comes to mind but I don’t know if stable diffusion can be used with deepspeed. 

Since you’ve 8gigs of vram, try reducing the output image resolution. 

Or even better, just use colab.",Pytorch
"I'm not expert on ML but from a software design standpoint, the ""correct"" way would be to not even store the 2D matrix of weights but instead store only your amplitudes/phases/frequencies and then make a kernel that evaluates that at runtime.",Pytorch
"Some comments:

- have you used a pretrained backbone? If not, try that

- is the size t varying or constant? If constant then throw the rnn over and just flatten the first two dimensions into a t*c sized dimension

- if it is varying, you may also want to look into Temporal convolutions, as they are better in detecting changes from frame to frame

- other option as well: transformers",Pytorch
"Pretrained networks are backbones that are already trained on Imagenet dataset. That means that the model does not need to learn all the features from scratch when you use it for a new task. Even if the task is different and the images are different, performance is almost always better when using pretrained networks as an initialization of the model.

In general: do not use RNNs if you could replace the RNN by a CNN. Which is the case for you. You could use a CNN with inputs t*c that replaces the RNN. This is possible since you know that t is constant.

Don't worry about the transformers then... This is just a fancy variant of time series modeling.. maybe better stick to the CNN with a pretrained backbone

Edit: link to pytoch/torchvision pretrained networks: https://pytorch.org/vision/stable/models.html",Pytorch
"I think the easiest way to do it is creating a custom subsampling method in your dataset class.
It will look like this:
In the __init__ you create a data structure holding your whole dataset and you subsample it in custom method that you call each epoch from training loop. This method will create a list (or other data structure),  which you will reference in the __get_item__ , that way a data loader will have the updated dataset from which it creates an iterator each epoch",Pytorch
"You should use binary crossentropy loss (nn.BCELoss) and your last activation function should be sigmoid.

Also, look up Datasets and Dataloaders for loading your data. It's not necessary but it's nicer code IMO",Pytorch
"I'm just going to mention here the experience of someone who ran [gpu.land](https://gpu.land) (doesn't exist any more). He did something similar, monetized it (very cheap) and then had to shut down because people were running crypto miners on it. I hope you have a plan to avoid that type of abuse.

Otherwise I'm rather interested.",Pytorch
"The autograd functionality is not exclusive to `torch.nn`, which makes it more flexible.

When you make computations with tensors, the operations are recorded. When calling `.backward()` on a tensor, autograd computes the gradients of all tensors that `require_gradient=True`. It makes sense to call backward on the loss simply because it is the last node in the computation graph.",Pytorch
"Pytorch has a dynamic graph. Your model is an abstract concept and it is defined as a set of connections from inputs to an output, and finally to a loss, via the weights. In each iteration you could have a slightly different model. 

So when you apply the backward method to the loss, it is the direct application of calculating the gradient on whatever is your model currently (as it was defined from the way you built it), and it tracks back the connections between modules and layers up to the starting points.",Pytorch
"Generally, the model is wrapped via an optimizer: optimizer = Adam(model.parameters(),…), but this is not always the case. Sometimes you want to exclude things such as the bias term of BatchNorm in the optimizer for better speed and other tricks. 

Model.parameters() contains all parameters in the model, but not in the optimizer.",Pytorch
">     w = w - lr*w.grad.data

This line is overriding the Variable instance with a newly created tensor, and then when the second loop iteration happens the new tensor doesn't have a grad set.

You can use `-=` instead to mutate the tensor in-place. Additionally you should put it inside `with torch.no_grad()` to make PyTorch happy.",Pytorch
"The latest builds do take advantage of Apple silicon, however be warned that they are not as fast as you might hope.  They are much faster than pytorch on Intel Macs but not as fast as a good GPU with CUDA.  There are some instructions for installing the latest here:  [https://towardsdatascience.com/installing-pytorch-on-apple-m1-chip-with-gpu-acceleration-3351dc44d67c](https://towardsdatascience.com/installing-pytorch-on-apple-m1-chip-with-gpu-acceleration-3351dc44d67c)",Pytorch
"Found a solution:

```
@app.route(""/json"", methods=['GET', 'POST', 'PUT'])
def getjsondata():

    if request.method=='POST':
        # print(""received POST"")

        data = request.get_json()

        #print(format(data['z']))
        jzf = [float(i) for i in data['z']]
        jzft = torch.FloatTensor(jzf)
        jzftr = jzft.reshape([1, 512])

        z = jzftr.cuda()
        c = None                   # class labels (not used in this example)
        trunc = 1
        img = G(z, c, trunc)

        #img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)
        img = (img * 127.5 + 128).clamp(0, 255).to(torch.uint8)

        # turn into PIL image
        pil_img = transforms.ToPILImage()(img[0]).convert(""RGB"")
        #pil_img = PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB')
        pil_img.save('newtest.png')

        response = serve_pil_image64(pil_img)
        response.headers.add('Access-Control-Allow-Origin', '*')
        # response.headers.add('Content-Transfer-Encoding', 'base64')
        return response


    return 'OK'

def serve_pil_image64(pil_img):
    img_io = BytesIO()
    pil_img.save(img_io, 'JPEG', quality=70)
    img_str = base64.b64encode(img_io.getvalue()).decode(""utf-8"")
    return jsonify({'status': True, 'image': img_str})

```",Pytorch
"The above runtime error is solved with [this github commit](https://github.com/buttercutter/gdas/commit/b7f53c1d7d5c51597f1b8ed06aa3a7d329a4ff0d)

However, [the loss](https://github.com/buttercutter/gdas/blob/b7f53c1d7d5c51597f1b8ed06aa3a7d329a4ff0d/gdas.py#L897) keeps lingering **forever** at values around 2",Pytorch
"It all depends on what you want to train, but usually you would load the image and corresponding txt file in your `__getitem__()` function and return an `(img, ground_truth)` tuple.

If you want to do object detection, your ground truth should be a format where you have all object labels and coordinates. For classification only the labels are sufficient. As for what output format you exactly want, that depends on the loss function you use. If you create your own loss function, then ofc you are free to choose a suitable data format yourself (tensor, numpy array, pandas dataframe, ...)",Pytorch
"Take a look at YOLOs dataloader, or more specifically the dataset class. When you call dataset[idx], it invokes the __getitem__(idx) method, which returns the image tensor and labels. What's your objective? How would you need to change that __getitem__ method to return what you'd like?",Pytorch
"Adams (if you are using it) should has an option for L2 regularization. Please refer to the documentation. As for L1, you might have to use a self-written function, which I borrowed from stack exchange. The function goes under your module/model class.",Pytorch
"1. Instance segmentation masks in FiftyOne are defined to be inside of the corresponding bounding box. The shape of the masks varies because they will always be reshaped to be visualized inside of the box when viewed in the FiftyOne App. You can convert each instance segmentation to a full-image semantic segmentation using:

&#8203;

    dataset.compute_metadata()
    sample = dataset.first()
    frame_size = (sample.metadata[""width""], sample.metadata[""height""])
    detection = sample[""ground_truth""][""detections""][0]
    
    segmentation = detection.to_segmentation(frame_size)
    full_img_mask = segmentation.mask

2) In terms of how to train a segmentation model, this Pytorch example using MaskRCNN is a great place to start: [https://pytorch.org/tutorials/intermediate/torchvision\_tutorial.html](https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html)

You can also see how to use FiftyOne datasets directly in your Pytorch dataloaders with this blog: [https://towardsdatascience.com/stop-wasting-time-with-pytorch-datasets-17cac2c22fa8](https://towardsdatascience.com/stop-wasting-time-with-pytorch-datasets-17cac2c22fa8)",Pytorch
"Hi I want to collaborate email me sukhmanghum66778899@gmail.com
Edit: can you please also provide me with some more info about what kind of project is it and what kind of collaboration u need  from me.",Pytorch
"The weights file is like a python dictionary where you can read the names of the layers which will be the keys of the dictionary and the weights of that layer will be the value corresponding to those keys. You just read the weights.pt file, parse it as a dict object, change whatever you want inside treating it as a dict and save it as a new pt file.",Pytorch
"If you look at the torch docs it looks like they are loading the model at the top of the script outside of a function call to avoid this problem.  One of the notes talks about doing that to avoid loading it every time.

https://pytorch.org/tutorials/intermediate/flask_rest_api_tutorial.html",Pytorch
"Couple of choices:

* Right here, in Reddit
* Freelance platforms (Upwork, Fiverr, etc.)
* In any kind of general forum/communities that involves ML, DS, Deep Learning, etc.. That also includes the official Pytorch Forum (https://discuss.pytorch.org/)

If you need something secure and simple, then probably the Freelance platforms are the way to go. If you wish to do the more organic form, and pay someone in Bitcoin, do either one of the rest.",Pytorch
"it is compatible with pytorch 1.12, but it isn't that fast and some functions doesn't work. I can't figure it out right now but I think it was unable to use BCEwithlogitloss (it can be wrong, but seriously some functions are not supported yet)",Pytorch
"As soon as you mention paying, even the most helpful person in a community will put you in a black list. 

Come up with a solution by yourself first. Then post in the communities “hey I did it this way by following some resources on the internet, how can I improve it or how does this part work in actual?” .",Pytorch
"Available now! Article 1: PyTorch, torchvision, and simple inference examples [https://blog.genesiscloud.com/2022/deployment-of-deep-learning-models-on-genesis-cloud-torchvision](https://blog.genesiscloud.com/2022/deployment-of-deep-learning-models-on-genesis-cloud-torchvision)",Pytorch
"I would suggest increasing the input size (and maybe the step n at which you sample frames), it might allow your model to extract more comprehensive conditional probabilities among the features.

edit: I understand this is for an academic project but IMHO this task shouldn't require deep learning",Pytorch
"If you can't do what you want in an nn.Module with existing functions then unfortunately I think you've found the best you're going to (the custom autograd function tutorial from the pytorch docs).

The reason those methods are static is that you're defining a function in two parts (the function and the derivative of a function) which is not a stateful object like an nn.Module. The class is just a container for the two parts of the function. `ctx` is a ""context"" object, it is the way you send things from your forward pass to your backwards pass since you're defining a ""pure function"" (in the mathematical/functional programming sense) so you're not able to have any true state. You just put all the state (e.g. the inputs) into the `ctx` object and then pull them out later",Pytorch
"Look at the deep learning with pytorch book, Sebastian raschka's new ml and deep learning with sklearn and pytorch, has some advanced topics.

Look at courses like CMU 's deep learning, NYU 's deep learning, etc
Pytorch lightning has put up University of Amsterdam 's course on its website",Pytorch
"Luckily you don't have to save your model after each epoch, you could just save it after X iterations and pick it up from there if needed (of course you'd need to know which batches you've already visited).",Pytorch
"Set aside a train validation and test set. Train on the train set (no surprise here) and after each epoch (or every n epochs) use the validation set to evaluate the model. Stop training when the validation error does not further reduce. Test the final accuracy on the test data, but do that at the very end to not pollute it",Pytorch
"Go on the official website of PyTorch there you find the proper pip command to install it.
""Pip install torch"" is not sufficient to properly install it. OS as well as cuda version are missing the way you are trying to install it.

It usually is not a pip issue :)",Pytorch
"If you're just learning PyTorch, I strongly recommend using [Google Colab](https://colab.research.google.com/?utm_source=scs-index), as it's installed by default. You don't want to get bogged down with installation troubles at this stage, and Colab will spare your CPU / GPU from some wear and tear. Plus it's free..",Pytorch
"hey! I am currently doing this!

I would recommend you look into `torch_geometric`'s examples in GH. They provide this very handy [link pred example](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/link_pred.py), but there are others in the `examples` directory that you should check out.",Pytorch
"It's an issue with mlagents, whatever class you're registering is the wrong type. Did you try googling your last error and posting an issue on the mlagent GitHub? I mean your stack trace doesn't give a whole lot of info without the context of your source code.",Pytorch
"Sure, you can index along the channel axis, for example:

    x = torch.randn(1, 8, 66, 66)
    x04 = x[:, ::4, :, :]   # select channels 0 and 4
    x15 = x[:, 1::4, :, :]  # select channels 1 and 5

    print(x04.shape)        # (1, 4, 66, 66)
    print(x15.shape)        # (1, 4, 66, 66)

and then just use convolutions or anything else as you normally would.",Pytorch
"Well, the first thing I'd do is set up github actions so that your test suite runs automatically on every push.  Then I'd look at generating automatic test coverage reports. From my perspective, tests are useless if they aren't being run and reported on so making sure that happens without your involvement is key.

The other thing I'd do is write some comments -- you have as far as I can tell zero comments in the entire codebase. You shouldn't need to read the entire test suite's code to know what it's testing, and this will hurt when you come back to this in 6 months.",Pytorch
"Would be a gem if cloud GPU platforms could provide a beginner-friendly solution to be able to train over multiple GPU instances while streaming data from a single cloud storage platform. 

Also, an easy-to-work-with method to spawn a variable number of instances based on the size of the data. 

All of these currently can be done, but are a pain in the ass for people who aren't too familiar with the tooling required.",Pytorch
"My only complaint with lambda is the lack of persistent storage.  If you could shut an instance off without losing the data, I would probably move half of my AWS workload there.  That said, having an API to start/stop instances and run jobs like sagemaker is a huge reason for me still running stuff on AWS even with the absurd cost.",Pytorch
"A good example is this project template https://github.com/ashleve/lightning-hydra-template. It uses a lot of cool things such as

- testing
- logging
- formatting and style checking as pre-commit hook
- config management with hydra

The main purpose of the template is combining lightning and hydra in a neat way, but you might aswell just use it as inspiration to build a project with your own toolstack.",Pytorch
"Unless the inputs are fairly small it probably won't matter. If they're all the same size/shape in terms of features (on both the input and output) then you can do it by concatenating the inputs along the feature dimension, and then creating one conv that takes in all 3, and outputs 3 times the output feature size, but set the groups parameter to 3 on the conv. That way the first third of the input (which should be X1) would be convolved using the first third of the weights (which would be equivalent to conv1), to produce the first third of the output (F1). This is probably not faster in practice though since concatenating the arrays will not be fast. Micro-optimisations like this typically aren't worth it, you're likely saving seconds on a model that trains for days.",Pytorch
I go through the full dataset once and delete any images that are missing or have some other bad quality (like the average color is <=1/255). Remove the reference in your file that lists the file names and labels. You only need to do this once when your dataset changes then you know you only have good samples going into the dataloader.,Pytorch
"You should really put an effort into asking the right things and provide us with the right information. You provide nothing but an image of an error in an exe yet you ask a question than can potentially have dozens of answers. No lib or python versions, no code, no MRE. This is not the way. Please, read [this](https://stackoverflow.com/help/how-to-ask) guide and take your time to prepare your questions. We cannot really help you with so little information. Help us help you.",Pytorch
"Kind of hard to say without the code, but 6G is not a lot of memory for training a NN (definitively possible, but keep in mind that most other people who runs have at least 12G I would say). 

Without any more details all I can say is:

\- Try reducing your batch size. If it fits with a small batch size (start really smart), it's just a matter of the GPU not having much memory and you'll have to either use small batch size or try to reduce the size of the examples (I'm more NLP than images so not sure how, maybe lowering resolution or something)

\- If if doesnt work even for a small batch size, check that you zero grad the loss after each batch, else it will keep growing. 

I think there are also techniques where you can train 1 layer out of 2 at each iteration, thus reducing memories, and you could also try looking into using 32 bits precision instead of 64 bits. Other users are probably more experienced than me however in memory management.",Pytorch
"Like u/Pixel74 says, 6G is not very much for training models like this. It's not uncommon to need 24GB or more for larger models, even multiples of this (training large image generative models on machines with 96GB of VRAM). 

&#x200B;

Whatever your settings are, they're too much for your hardware. Share your hyperparameters and more details and maybe we can provide more feedback.",Pytorch
"You do need the model class to load the model, but you can just import it from your other python file or some library.

If you dont want or need that, you can use `torch.jit.script(model).save(path)`. Then you can load the model with `torch.jit.load(path)` without the model class.

https://pytorch.org/tutorials/beginner/saving_loading_models.html",Pytorch
"Simple Linear Regression model should have been implemented and you shouldn't see `NotImplementedError`. As for fallback environment variable, maybe use it in the beginning of your code with `os.environ['PYTORCH_ENABLE_MPS_FALLBACK']='1'`. But yes, I certainly think there shouldn't be any fallback for a simple linear regression. Please also try `pip install -U torch` before running your script to upgrade pytorch to latest version.",Pytorch
"640x480 is pretty big by CNN standards. By the time you do that in a batch, add network parameters and gradients (gradients are the significant majority of memory usage at train time) it's not surprising that you ran out of memory. Try reducing your batch size, down to 1 if you have to. If you want to have a larger batch size than you can fit, you can do multiple forwards-backwards calls before calling optimiser.step(), allowing you to effectively trade time for memory.

If you can accept a lower resolution you probably should. You could also try using torch.cuda.amp to do mixed precision (this will save you memory, and may gain you speed if you're using a 20 series card or later).",Pytorch
"Check the following if you are building a model from somewhere else:
- you have their downsampling layers 
- you initially downsample the image if they do
- do you have the same layer channel outputs

Check this about training:
- use Mixed Precision training
- What is your batch size? Maybe decrease it
- Use gradient accumulation/mini batch training to get a larger batch size",Pytorch
"I'd suggest you make custom classes of Modules and insert the forward logic into the class' forward function. In this way, tensorboard graph will encapsule everything that is run for that class inside in a box.

As a general rule, I'd suggest you do NOT implement epochs inside your forward function.

Best recommendation I can give you is point you towards [https://www.pytorchlightning.ai/](https://www.pytorchlightning.ai/) for general best practices. It enables you to do everything you can do in pytorch while also organizing your code better and optimizing for you.",Pytorch
"Look up flops online. If you want to view flops and prameters check out torchinfo https://github.com/TylerYep/torchinfo. 

Some lightweight layers barely add computational burden but can increase performance. See CBAM and SE blocks. 

Also make sure to use mixed precision training. 

You might also get an edge using knowledge transfer from a big network to an efficient one.",Pytorch
"https://discuss.pytorch.org/t/different-learning-rates-hyper-parameters-for-every-element-of-a-tensor/28636/2

Proposed solution is to have your different neurons in separate tensors. The regular optimizer is compatible with one learning rate per tensor.

In the forward you then can construct your tensor from the subtensors with e.g. a `cat` operation


Orther solution could be to multiply the `.grad` by a scaling tensor to get the effective learning you want for each neurons. Does not work for all optimizers though. IIRC, this can work with SGD, but not with Adam",Pytorch
"The error is telling you exactly what is wrong and where it is located. It's happening in torch_scatter/utils.py on line 12. You're argument ""size"" needs to have the same number of dimensions as your input.",Pytorch
Without seeing the code in questions it's hard to say. Your google collab link is behind a password / access wall. I would recommend you look at the HuggingFace implementations for these for comparison.,Pytorch
"You may want to read the documentation on PyTorch's reproducibility module

[https://pytorch.org/docs/stable/notes/randomness.html](https://pytorch.org/docs/stable/notes/randomness.html)

It will explain everything you want to know in detail. Basically, you'll use torch.seed() in various ways",Pytorch
"I'm doing research in computer vision and the data is always converted from 0-1. Thats in the papers and code I'm reading anyway.  

My guess is it affects the magnitude of loss functions, operations like batch norm and some activation functions. Its easier for networks to learn when the data is scaled and shifted to be zero-mean and going from 255 to zero mean and back to 255 might affect learning.",Pytorch
"It depends, how are you trying to use them? Pytorch itself doesn't care what's in tensors or how you want to interpret things, an ""image"" is not really a core concept.

Typically during training you convert everything to floats with range 0..1. Some torchvision utilities might expect uint8 with range 0..255.

You'll have to ask specific questions to get specific answers.",Pytorch
"The recall is correct

Let us first define accuracy:

(How many instances we got right)/( how many instances we have in total)

The recall is defined as
True positive/(true positive+ false negative)

In other words how many instances is correctly classified ( true positive) out of the total instances that should be classified with this class; the total instances will either be correctly classified (true positive) or incorrectly classified (false negative)

Let us say for class 1 we have a total of 100 instance in the dataset and the algorithm correctly identify 80 instances belonging to class 1 (true positive) and the other 20 instances are falsely identified as one of the other classes (false negative)
The recall will be 80/(80+20)= 80/100 or 0.8

Regardless of the other classes outcome if we get back to the definition of accuracy above we have 100 total instances of class 1 and we correctly identify 80 of them as being in class 1 that will make the accuracy 80/100 = 0.8 which is the same as the recall 

You can also think of it as if the algorithm is trying to decide whether an instance belong to class 1 or to other class which will make it a binary classification (does it belong to class 1 or not)",Pytorch
"Havent used the MNist one, but for segmentation I created a zero tensor of the same size as the label. Then set the value to a desired number only for areas where the label hat the class.

For my 2D labels i used. 

Remap = torch.zeros((label.size[0], label.size[1]), dtype = …., device =….)

Remap[label == class_integer] = desired_value.",Pytorch
"Hi. Something like this should do the trick:

```
import torch
from torch.utils.data import Dataset
class MyDataset(Dataset):
    def __init__(self, dataset, class_idx):
        self.dataset = dataset
        self.mapping = torch.arange(len(dataset))[dataset.targets == class_idx]
    
    def __len__(self):
        return len(self.mapping)
    
    def __getitem__(self, idx):
        return self.dataset[self.mapping[idx]]
```",Pytorch
"A few things:

* You should pass your arguments in by name for readability (and ensuring you're passing the right values to the right arguments), at least after the first few/positional.

The Conv2d constructor is:

    torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, 
    bias=True, padding_mode='zeros', device=None, dtype=None)

So you're currently setting kernel_size (the size of the filter, nothing to do with the output size image) to (2, 1). You probably want that to be 3x3 or 5x5. You probably want (2, 1) to be your stride, not your dilation. So you should do `Conv2d(3, 3, (3, 3), stride=(2, 1))`

(Note you can set padding to be kernel_size//2 - 1 to maintain shape (other than stride effects). So you probably want padding to be 1 for 3x3, 2 for 5x5, etc.)

* Calling `T(y)` essentially runs the `forward` method of the class. It does not know anything about this `self.main` network you have defined. Your forward method currently just returns the input, so you should change forward to be `return self.main(input)`.

And less important but still good practice IMO:


* It's customary to use `x` for input and `y` for output, so I would rename your `y` variable to `x`.

* It's customary to use capitalization for class names (`trial` -> `Trial`) and lower case for variable names (`T` -> e.g., `model`).",Pytorch
"If the images are vastly different, I could suggest clustering. You can use VAEs to get image representations, and then use some form of clustering - graph partitioning or density based. Then you can assign labels to these image classes. After that, you can train a classifier.",Pytorch
"You're right about everything: modules do NOT inherit parent caller's environment. They are using what is in my opinion pretty bad practice: they are accessing another module's imported modules via importing that module. 

I'm looking here https://github.com/ultralytics/yolov5/blob/master/models/yolo.py and I see:
`from models.common import *`

That `common.py` file does `import torch.nn as nn`. So the `yolo.py` file is basically accessing `common.nn` (but imported via the star, which I also think is bad practice lol).

(EDIT: FYI I don't see this ylmt.py file in that repo, but it looks like the yolo file is similar to what you're talking about, maybe they renamed it or something)",Pytorch
"As the other commenter said, you can stack or concat your two tensors to form one. And then you'll likely want to pass them through any number of layers to do feature extraction. How you select which layers, where, and parameters for each is at the heart of machine learning. You can find ample tutorials about convolutional neural networks online, including on the Pytorch website. 

In order to extract features, you'll need to train your model. What are you trying to train it to do?",Pytorch
"If you've saved that kind of data with your checkpoint, then yes, but by default, if you just saved the state dict of the model, then no. The state dict is all you have. You can probably walk through the state dict and deduce the settings of your network (assuming you're looking for things like number of layers and layer sizes), but you're not going to recover more than that.",Pytorch
"Weird. 2 useful tips to free up some memory though:
- Use torch.GradScaler for mixed precision training. 
- use “del x, y, z” (with xyz as your Tensors/Variables) to delete saved tensors once you dont need them anymore.",Pytorch
Look on github. Panoptic Deeplab or Deeplabv3+ (i forget which one) use weighted cross entropy for semantic seg. There is a data preparation script which contains a formula to generate the weight vector,Pytorch
"We can't know for sure without code whether this is why you are running on CPU. 

I would recommend installing conda package manager if you havent already. This way you can seperate different version of python/CUDA and all your packages without having to worry what is installed to the base system. It also looks for depencies when you install packages so it makes it much harder to have incompatible packages in the same environment.

Edit: And CUDA is backward compatible so the download link for a CUDA version less than yours should work.",Pytorch
"In addition to other comments, don't instantiate a new tensor (your ""torch.tensor(losses)"") at the end. Instantiate at the beginning:

    losses = torch.zeros(len(matrix_lengths))
    ...
    losses[i] = MSE stuff
    loss = losses.mean()

You could also just say `loss = 0` up front, then `loss = loss + MSE` inside (and optionally divide by batch size at the end). Note, do NOT use the ""+="" operator. If you have any questions on the ""why""s of any of these, let me know.",Pytorch
"Cuda is backwards compatible, so try the pytorch cuda 10 version. 

If not you can check if your GPU supports Cuda 11.3 ans upgrade. However, Cuda 11.3 only supports newer Nvidia GPU drivers, so you might need to update those too. 

In that case, make sure to switch your graphics driver back to your graphics chip (not the graphics card), or you will end up with a black screen before the upgrade.

If your GPU does support cuda 11.3, but you want to keep cuda 11.2, make sure to run everything inside a virtual conda environment.",Pytorch
"It depends on how you're storing your data. If its some sort of vector type data made up of just numbers, you can try storing your data in the HDFS format.

This format lets you randomly access the file at any index at quite high speed (this will still be a bit slow if for example, you're using a HDD to store your data).

Another method is to use an [IterableDataset](https://pytorch.org/docs/stable/data.html). In this, your dataset has an '\_\_iter\_\_' function. You can split your dataset into say 10 \* 5Gb, and implement your dataset such that it loads 1 file, then iterates through it returning the required data, then once you've reached the end of the file load the next one.",Pytorch
"Lots of options out there.  Depends a bit on compressibility — if you are lucky and it is text data or otherwise compressible, you can possibly fit it all into a v2 feather file with compression and actually have it all in memory.  In any case, read up on custom datasets and you’ll find a number of ways to load data on demand.

There are some prerolled options like torchnet’s ListDataset that you might try as well, and I know huggingface has some built in options as well, so depending on whether you are already in a framework you might have already got a solution.",Pytorch
"I would store the dataset as memory maps - this way I can randomly access any index without loading the whole sequence into memory, and also it's super duper fast for iteration over the dataset, while requiring very little memory. It does take more disk space, though. Something like this (after the dataset memory map has already been created):

    import torch
    from mmap_ninja.ragged import RaggedMmap
    
    val_images = RaggedMmap('val_images', wrapper_fn=torch.tensor)

[https://pypi.org/project/mmap-ninja/](https://pypi.org/project/mmap-ninja/)",Pytorch
I’ve been through this before. It was a huge pain and we finally gave up and switched over to ONNX runtime and exported our PyTorch models to ONNX. Getting ONNX runtime into unreal was fairly painless.,Pytorch
I was able to run torchscript models at runtime using a little wrapper over libtorch stuff in UE5 EarlyAccess2. But the exact same code doesn’t work since Prevew1. The engine started to mess up with libs at the dll loading stage (just stuck at 75%). Something is definitely broken there.,Pytorch
"You're input size is wrong. So you will need to either perform some additional preprocessing to get your samples into the same shape that is expected by the model, or you will have to modify the model architecture so that it can accommodate the sample size you are providing. The best way to do this might be adding additional convolutional layers prior to the linear layers. But it will take some tweaking and careful math to make things align. 

I would recommend doing a side by side comparison. Push thru a sample that is the expected size for the model arch, and print out the way the shape changes as it passes thru each layer. Then do the same with one of your samples. You should see pretty quickly where or how they don't match up.",Pytorch
"the ""optimizer"" part in the tutorial is literally the definition of gradient descent so it's like using SGD.

As for the fact that you rnn.parameters is not working perhaps there were breaking changes to pytorch after that tutorial was written.",Pytorch
"You should create a basic training loop without any of the extra things, check if the error persists and then add the extra features one by one to find which one is causing you trouble. Always start with a basic config, always overfit only one batch to find errors. Then scale the training complexity",Pytorch
"Hard to tell with that little information, I would start by tracking the time each batch takes and break it down into which parts take the longest. I cannot find a way how to help you any better by just staring down the code, without knowing the hardware. :) Which GPU are you using?",Pytorch
"The BSD is permissive, but you can go to the GPL, which obliges to cite the creator when modifying the source, the GPL is contaminating, but also protective. BSD allows you to build on your work too, but you don't have to be quoted",Pytorch
"1. if you're using p100, fp16 could be slower than fp32
2. you don't need to check`if gradient_accum > 1` every iteration. a minor optimization. not to mention you're not re-scaling loss when logging, so your training loss will be artificially deflated with gradient accumulation
3. not a speed optimization, but if you're using gradient accumulation with resnet your batchnorm running stats will be all messed up",Pytorch
"Hard to know with all that stuff going on. Try stripping your training process down and use process of elimination to see what fixes it. 

Do you know that the extra time is actually spent in the training loop? If you have a lot of data or preprocessing to deal with, maybe profiling your entire training program would illuminate the issue. Then start profiling the training loop in finer detail and see where the time is spent. Just using print statements is easy if you’re looking for a quick method

One thing that often trips me up are inappropriately large batch sizes, since memory issues are sort of hard to nail down and sometimes affect efficiency unexpectedly. Try reducing the batch size and see how the discrepancy in time between first and later epochs changes

I would probably start with profiling everything and perhaps there’s one offender that stands out. If that doesn’t work then start checking memory usage and the rest",Pytorch
"If I understand pytorch correctly you can just store the output of the source layer in a variable and insert it into the target layer to create a connection. That way it should be easy to create skip connections by just copying the output of the source layer and adding/multiplying/concatenating it to the input of the target layer.

/e: word",Pytorch
"    class Model(torch.nn.Module):
        def __init__(self):
            self.layer = torch.nn.Linear(128, 128)

        def forward(self, x):
            x_clone = x.clone()
            x = self.layer(x)
            x = x + x_clone",Pytorch
"This might help, it has the explanation with code:

https://www.analyticsvidhya.com/blog/2021/08/all-you-need-to-know-about-skip-connections/

In short:

> Coming to Skip Connections, DenseNets uses Concatenation whereas ResNets uses Summation.",Pytorch
"Since your picture is of a U-Net structure I am assuming you mean the skip connections of the encoder-decoder architecture, and not of the micro structures what many people here are refering to (ResNet block with skip/identity connections or DenseNet)

If that is the case, check this out: https://github.com/godspeed1989/kitti_completion/blob/master/sparse_model.py

Class Encoder. The “endpoints” are your skip connection. They are appended during the forward pass of the encoder and later reused in the decoder.",Pytorch
"Try to check a bit the subrredit, this question is being posted way too much, and answered properly, you maybe have to check your training loop, use autocast and check if you’re storing unnecessary tensors after grad.",Pytorch
"AWS has official support for this use case:

[https://aws.amazon.com/blogs/machine-learning/announcing-the-amazon-s3-plugin-for-pytorch/](https://aws.amazon.com/blogs/machine-learning/announcing-the-amazon-s3-plugin-for-pytorch/)

[https://github.com/aws/amazon-s3-plugin-for-pytorch](https://github.com/aws/amazon-s3-plugin-for-pytorch)",Pytorch
"Usually, L1 is used to create sparsity, heres an explanation why: https://stats.stackexchange.com/questions/45643/why-l1-norm-for-sparse-models

Ofc this does not do exactly what you want since you dont care about the values as long as they are not 0 (for whatever reason). However, im not aware of any differentiable loss that would do what youre looking for.",Pytorch
"`loss.item()` is causing a blocking synchronization and copy from GPU to CPU. You can keep running_loss on the GPU and only sync it to CPU ever K batches instead by using `.detach()` instead of `.item()`.

See https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html#avoid-unnecessary-cpu-gpu-synchronization



Also with newer versions of pytorch you can do `model.zero_grad(set_to_none=True)` instead of doing it manually in a loop.

Another slowdown could be in the data loading and preprocessing, I'd recommend making sure you're using pillow-simd and not running any transforms that warp the image (rotations, shear, etc) because those can be pretty expensive.",Pytorch
"This might help: https://www.synopsys.com/blogs/software-security/open-source-license-compliance-dependencies/amp/

Ps:  the “notices” file in pytorch can help with the transitory dependencies as well:  https://github.com/pytorch/pytorch/blob/master/NOTICE",Pytorch
"It took me a while to read the code comments to make sense of this post.

The loss returned by `forward()` is already a mean (of that batch), no need to multiply it by the batch size.

Your ""epoch loss"" can be an average of batch losses in that epoch, or the sum of all batch losses in that epoch. It makes little difference as these amounts are proportional to each other.

Edit: to make sure that the loss is being computed for each input, you can check the shape of `loss` before `loss.mean()`: the shape should match your batch size.",Pytorch
"Doesn’t matter.  It will change your effective learning rate, but once you tune that hyper parameter it will fall out of the wash.

I usually like my learning rate to be independent of the batch size, but that is the only consideration.",Pytorch
"Maybe something like this

    import torch
    
    X = 2
    a = torch.zeros(5, 10) 
    idx = torch.argsort(torch.rand_like(a), dim=1)[:, :X] 
    a[torch.arange(a.size(0)).unsqueeze(-1), idx] = torch.rand(*idx.shape)


It avoids the loop but creates a rand matrix with the same shape, not sure if it fits your case",Pytorch
"Best bet would be to start with something more simple like a data structure or matrix (non torch) and then do operations on that before converting it to a torch tensor. (Worst case scenario), but if you can picture it there’s always a way.",Pytorch
"[torch.profiler](https://pytorch.org/docs/stable/profiler.html) already handles CUDA asynchronous functions by default if CUDA is available or if `ProfilerActivity.CUDA` is passed.

Some usage examples:

+ https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html
+ https://www.deepspeed.ai/tutorials/pytorch-profiler/


> and wouldn't that slow it down significantly? Or only at the very end?

All profiling slows down code, it's an extra step done before and after all function calls. You should disable any/all profiling for actual training or deployment. It serves only to gain insights on where the execution is taking most time, how many times the functions are being called per step or during the entire execution, memory used, and some other things.",Pytorch
"I suggest to start with already existing architectures, checkout MONAI. Easy to setup and good tutorials. Also pytorch-summary or you can visualize in Netron https://github.com/lutzroeder/netron

When you have established baseline, then you can think about working on architecture, which to be honest, is rarely the case as having more and better data is more important.",Pytorch
"How much data do you have?  Have you found a means to incorporate transfer learning from a pre trained model or does it need to learn all the low level feature extraction from scratch?  And how long are you training it for?

I do kind of suspect that the other poster’s recommendation of using conv2d might be useful.",Pytorch
"Read the official documentation and tutorials. Read up on relevant papers and research that overlaps with what the job will entail. 

When I've been on research teams in the past, the managers and colleagues are much more interested in familiarity with ideas, approaches, and other relevant and recent research in the field than they are with my ability to code.",Pytorch
"Type pytorch in the Kaggle code section and filter by votes. You’ll get a bunch of tutorial notebooks.

But you don’t need two weeks to learn how to make a basic neural net as long as your data is simple and clean. The documentation gives you code you can pretty much cope and paste unless you have a bunch of pre processing",Pytorch
"Are you sure your x\_train has that shape? Aside from the obvious MNIST training set being 60000 images not 6000 images, it is often presented as flat features (i.e. 60000x784) rather than image features (60000x1x28x28) and some dataset sources also won't provide a channel dimension for grayscale images (i.e. 60000x28x28). That would be the obvious problem.

As to the difference in semantics between x\_train\[0\] and x\_train\[:1\] they are different things. x\_train\[0\] is ""get me the element 0 from this list/array"", x\_train\[:1\] is ""get me the sequence of elements up to element 1 from the array"". The second one is semantically different because it needs to be consistent with other values such as x\_train\[:2\] giving you back 2x1x28x28, so it should return 1x1x28x28 if applied to a 4 dimensional feature.

If this is literally your code then as the other user said, you've misspelled x\_train when you unsqueeze.",Pytorch
"The normal cross entropy loss function that is available in torch.nn.functional is all you need. It works based on the shape of the input that you provide it.
[cross entropy loss function doc](https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html#torch.nn.functional.cross_entropy)",Pytorch
"Hmmm I thought PyTorch baked the CUDA dependencies in it.
In any case, download the CUDA toolkit for aarch64, and make sure LD_LIBRARY_PATH includes the path where cublas.so (and all the other cuda .so files) lives.",Pytorch
"Well the easiest solution would be to ""flatten"" the hierarchy to 1d so class 0 dataset 1 would be a new class 01 etc. So you'd be classifying 30 classes with one classifier. Not the most elegant solution but if you've got enough data it could do the trick.

Otherwise you could do a multi head classification",Pytorch
"In your running_acc calculation you are creating a reference to the graph for that batch, you need to detach the value before account it to running_acc.

Basically running_acc is the head of the computation graph for the entire run. Generally any time you want to keep values outside of the batch, you want to call detach or item.",Pytorch
"Not sure where exactly something goes wrong but to approach such an issue you should always print out your shapes. To do so easily, create a nn.Module class that just prints the shape and returns the input. Add multiple of those to your sequential to find the layer that behaves unexpectedly.",Pytorch
"Having 53760 neurons takes much memory. Try adding more `Conv2D` layers or play with stride. Notice that most of the wide-known CNNs (LeNet, VGG, etc) project to 1024-2048 neurons. Also, try `.detach()` to data and labels after training. Lastly, I would suggest to take a look at [https://github.com/rentruewang/koila](https://github.com/rentruewang/koila). Have not tried yet but it should be helpful.",Pytorch
">The issue I am getting is that the neural network seems to retrain with the first import statement.

this could be about importing python module/ package issue, can check about [this article by realpython](https://realpython.com/python-modules-packages/).

Probably can be solved by adding ***.***

    from .Model import NeuralNetwork",Pytorch
"It might be helpful if you could also attach a picture of your Model file. I feel like there are some other lines of code in your [Model.py](https://Model.py) file that are not inside the if \_\_name\_\_==""\_\_main\_\_"": block. Can you try putting them inside the block?",Pytorch
"I believe the torch.load function is looking for a string that represents a file-path to your saved weights. The confusion is that you have named your in-memory model object ""model"" and the name of your model weights file is also ""model"". Try this for line 5:

&#x200B;

`model.load_state_dict(torch.load(""./model.pth""))`",Pytorch
"To store with hdf5, check out the RealPython article on storing a bunch of images. You are doing the same thing, but with 1x1024 shaped data.  https://realpython.com/storing-images-in-python/).

Also, this sounds like it might be an x-y problem, and there may be an easier way to solve your underlying task. What is driving you to store the raw data like this?",Pytorch
"Thats quite a vague question but if your model isn't enormous, you can have a batch size of 1 or 8 or whatever fits in memory and run a couple epochs. You can also reduce the resolution of your small test/inference set. Just be careful doing this as models with batch norm will shit the bed with such small batch sizes and you wont be able to infer very well.

I used to run code on my trusty acer aspire lightweight laptop (i5, 8gb ram, no GPU) in this fashion but looking back it was not very efficient. Again I'm not sure what your models, test sets or budget are but this should work.

I would definitely encourage people to use VSCode with SSH extensions that allow you to simply debug and run your code in app (on your laptop) from a remote server. This cuts down on a lot of fiddling around in your workflow between doing inference testing and getting a proper training up and running. I'm currently running code on a remote machine I have access to but I think official VSCode extensions are out there to do the same with cloud services like Google Cloud GPU/Collab, AWS, IBM Cloud. 

Personally, if the laptop is for travelling, I would want something lightweight and thin so I can pull it out anywhere. Good battery is a bonus. Theres nothing wrong with going with personal preference. Pytorch seems to run on M1 Macs, so if youre a fan of apple why not. I would be more inclined to put money into my at home desktop experience and less on my travel setup but you may be on the move a lot more. I don't really enjoy gaming on a small laptop screen without my peripherals either and laptops with GPUs eat a lot of battery and get quite hot.",Pytorch
"as mentioned by u/napoleonthegreatest \`einsum\` can solve your problem.

    import torch as th
    
    x = th.randn(20, 4, 300)
    y = th.randn(20, 300)
    
    # permute the dimensions of y.
    y = y.permute(1, 0) # y is (300, 20)
    
    # multiply over the last dimension of x and first dimension of y and reduce by sum over the resulting last dimension
    result = th.einsum('cwh, hk -> cw', x, y)
    
    print(result.shape)
    (20, 4)",Pytorch
">with my own loss function that requires some matrix algebra and a loop over the data, and I think I am doing something wrong

I already know your mistake. You get a warning that the gradient is empty because it can't be computed.
Because you are using Python-Lists and loops and not just tf.functions.
Everything inside the loss-calculation has to be done with tf.funcs.",Tensorflow
"Not sure I understand the question but let me take a stab. I’m also not an expert and a learner myself so don’t take this too seriously. 
Let’s say for instance your input is an image since that is mainly what convnets are used for. If u read in the image as a matrix and do some preprocessing on it in a special way then feed that into the network, I think it will work. I always view a neural network as trying to mathematically represent the relationship between an input X and an output Y. 
In this case, your special encoding is the input and the desired output is your target. 

It should be fairly simple to test, just feed your data into a neural net and see if it learns",Tensorflow
"It's a bit complicated to find the ideal number of tfrecords unless you do a benchmarking.

You can use parallel interleaving technique with autotune option to read data as fast as possible

https://www.tensorflow.org/guide/data_performance",Tensorflow
"I solved this myself: 

Instead of 

    !pip install -q tflite-model-maker
!pip install -q tflite-support

Use this

    !git clone https://github.com/tensorflow/examples
    %cd examples/tensorflow_examples/lite/model_maker/pip_package
    !pip install -e .

There will be an error to restart the runtime, IMPORTANT\* restart the runtime from the code-block and not the whole runtime.

This should now load Tflite in 3 minutes and not the hours that were happening with me.",Tensorflow
"You'll need `ImageDataGenerators`. Since you can't hold the entire dataset in memory, you actively load the entire dataset batch-by-batch using a data generator.

It's very straightforward, most of the work is done for you. If you need me to elaborate further, let me know and I can link you some repos.",Tensorflow
"Any model available from tf.keras.models has been trained on imagenet. You can use these weights to train by passing the param weight=""imagenet"" when you instanciate the model. 

Now which model to use is up to you, resnet50v2 would be a good start.

You can check https://keras.io/guides/transfer_learning/ for a tutorial on transfert learning and fine tuning.",Tensorflow
"From my experience, you can get away with a couple hundred per class if there is only 2 to 3 classes to train for. At 15 classes, the success will entirely depend on how ""visually obvious"" the features are between classes. If you do not have trouble identifying between classes by looking at the pictures, then I trust 300 per class will work.

One way to increase your dataset is through data augmentation. You can use keras data/image generator as the data source while training your model. It has a preprocessing stage where you can randomly select, flip and rotate the images prior to the training step. This effectively makes many versions of your dataset and increasing it.",Tensorflow
"Hi, the issue is that the variables should be created in build and not in the function call. I will further explain why. When you call the layer within the tape to calculate the gradients, the tape calculates the gradients for each weight of the variables. If you create a variable within the function call, the number of weights would be increasing with each call. To avoid this error, you should move the creation of layers to your init. You are currently creating and calling the Avg and Conv2D in your call. You should create them in the init. Avg is not causing an issue with variables as it doesn’t have parameters, but you are creating the same layer each time you call your model. It is not efficient. It would be better to call it only once. The layer Conv2D is the one causing the issue. Crease an attribute in the init to store the Conv2D and then use res=self.conv(out). TL;DR: create the layers inside the init and assign it to a variable name of your choice (self.my_conv) and without the calls (out). In the call you just do res = self.my_conv(out).",Tensorflow
"I use an add-on chip that that comes with google's visual diy kit, and it handles the model inference. Unfortunately, it doesn't seem to be for sale anymore but found something similar on amazon, the [Intel Movidius Neural Compute Stick.](https://www.amazon.com/Intel-NCSM2450-DK1-Movidius-Neural-Compute/dp/B076751BN8) 

If for some unlikely reason that doesn't work, nvidia sells a jetson nano that can often replace a pi and handles inference even faster without an add-on board. GL!",Tensorflow
"Tensorflow generators need to be infinite generators, which is what leads to your problem. A python generator with yield will stop and error once you have looped on the dataset. It is a bit tricky to code a proper generator for tensorflow, but fortunately you don't need to. I would advise you to create a tf dataset (if the dataset fits in memory) using the tensorflow dataset api https://www.tensorflow.org/api_docs/python/tf/data/Dataset. In particular, use the ""from tensor slices"" method. You can take a look at this tutorial https://www.tensorflow.org/tutorials/load_data/numpy for a concrete example
If your dataset needs to be created using a generator, you can try the ""from generator"" method https://www.tensorflow.org/guide/data#consuming_python_generators although I don't advise using it as it may lead to some unexpected problems if you don't handle your generator properly. 

Either way, for better results you still want your data to be wrapped in a tf dataset object, as it will handle shuffling and batching properly.

If the data does not fit memory, I would advise you to export your dataset in the tfrecord format, if you are interested I can give you some more information about that.",Tensorflow
"Well, prepare the data before so that you don't have to ""remove"" things in the worst possible time. There is a reason to hard code a batch size and don't touch it.

Forget about your function, really! Look at https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly",Tensorflow
"Don't convert tensors to numpy. It will make the layer unusable. Try to use tensorflow functions, or try to use tensorflow.experimental.numpy

Considering what you wrote, probably you want to use reduce max, and specify the axis on which the 1d tensors are stacked https://www.tensorflow.org/api_docs/python/tf/math/reduce_max

Imagine you have a (batch, dim, 4) tensor, you would want to reduce in the 2 axis",Tensorflow
"Sorry, but what kind of question is this? If you want to learn what machine learning is google it. When you understand it you will see why it can be better than throwing a dice. 
If you have specific questions you can ask them here.",Tensorflow
"You can prune weights, that would be kinda like feature selection if you remove all weights associated with a particular input. For example, the weights of a dense layer are stored with shape (n_inputs, n_units). If you set to 0 all the weights in a row, that input would be ignored. You could have a custom dense layer with a mask. You multiple the weights and the mask to obtain only the weights that should be considered. Once you find the weights the can be removed without greatly affecting the accuracy, you could recreate the model with the correct number of inputs and weights.",Tensorflow
"Do you really think getting a random item from a list of most liked is a *good* way of building a recommendation engine?

I worked an e commerce site before, you know what our best rated and most popular item was? A very average 39 cent screw.",Tensorflow
"You can use a map that returns only the features and another one that returns the labels. As the dataset has features and labels, you create a function that returns features intead of features, labels. [This code should work.](https://pastebin.com/ci8CMWMy)",Tensorflow
"You calculate the losses within the tape scope so that the gradients are calculated for each of the variables. Then you pass the gradients to the optimizer and the tensorflow variables so that the optimizer decides how to change the weights using the gradients. Different optimizers update differently the weights. If you don't use apply gradients, the weights of your model will not change. The weights would keep the values they were initialized with.",Tensorflow
"This is not how you handle data which does not fit the ram. You need to define a data loader which reads data from disk, and you need to train your model on the whole dataset. An elegant solution would be to export your dataset in the tfrecord format, maybe in chunks of 1Gb (something like 1000 samples, or at least big enough to contain one training batch). There is a guide on the tensorflow documentation on how to write and read tfrecord files. It will be a bit cumbersome at the beginning, but the performance boost is worth it",Tensorflow
"Exactly that. On a high level, what you’re doing here is defining what the graph for the model should look like. Going from top to bottom: in the first layer you define the input shape expected by the model, then for the dense layer the first brackets specify the parameters for the layer and the second brackets tell the layer it’s gonna do a forward pass with the data in “inputs”… and so on for the other layers.",Tensorflow
"You cannot modify the values of a tensorflow Variable in the call function of a layer. It will throw an error. You could copy the weights into a constant, apply the normalization and then use that constant in the convolution. However, If you only need to normalize once, I would recommend that you use a custom constraint or callback. The constraint can normalize the weights after the weights are updated. As for the callback, you can make a callback that is called on_train_batch_end that normalizes the weights after each batch.",Tensorflow
"Tensorflow is just an automatic differentiation library. What you're interested in is neural networks?! Technically, a neural network with at least one hidden layer can approximate ANY given function. This is known as the Universal Approximation Theorem. Of course the approximation is sometimes easier said than done (e.g. the network might not have enough representation capacity or it might get stuck in a local minimum).",Tensorflow
"This webapp is a great visual intuition for you question. Try selecting the circle dataset or others and play around with the amount of layers and neurons in each layer and activation functions (which provide the non-linearity to the neural network).

https://playground.tensorflow.org/",Tensorflow
"Using the same batch size will undercut one set of GPUs. If the batch size is too small, the big GPUs will look bad. If the batch size is too big, the small GPUs will look bad. You should wedge (use a range) the batch size across all the GPUs.",Tensorflow
"First option is better. YOLO is enough for both classification and localization. Also in second, you need to train another network which is inefficient for this task. Because with small backboned networks like mobile net, squeeze net etc. you cannot achieve performance of YOLO's feature extraction. With big backboned networks, training time would be too much. It's better train YOLO, maybe optimize hyperparameters of YOLO, rather than train 2 network.",Tensorflow
"Don't use python, use tensorflow to perform your computations. Python (and numpy) is worthless for anything where performance matters, at least if you have a GPU available. Even tensorflow eager mode will beat it, but I recommend using autograph via `@tf.function`.

Edit: See the documentation here: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#get_weights, it mentions that you get a numpy array. What you should use instead is the `trainable_weights` or `weights` property.",Tensorflow
"Clear the backend cache. Tensorflow greedily claims GPU vRam, the previous iteration of your code is still held in memory so the check for available memory fails. 

I use the tf.keras.clear_backend function at the top of the loop.",Tensorflow
"I would use nvidia-smi before you run the program a second time.   See if it lists any attached processes, and if so, kill them.    If that is the fix, then you need to find out why that process is not exiting properly.",Tensorflow
"Tensorflow will grab as much GPU ram as it can when it starts up even if it doesn't need that.  An annoying thing about this is you need to explicitly tell it to STOP THAT CRAP.   I usually add lines such as this at the start of my script to force it to only take up the memory it actually needs. 

    physical_devices = tf.config.list_physical_devices('GPU')
    for device in physical_devices:
        tf.config.experimental.set_memory_growth(device, True)

There's a few others that work, but that one I know from my experience will usually work.",Tensorflow
"Same problem. If you ever get around to fixing it that would be great...

So far I click the restart kernel and run all option which frees up the memory. Nothing else has worked but this solution is kinda slow...",Tensorflow
"So a few things:

1) the only difference between video and image is that video is LOTS of images. So whatever model you run will still predict against a single image in your use case.
2) now that we know that, your code loads an image from a file, figuring out along the way of its png/jpeg/etc. That has to go and instead you need to pass already loaded image data (which will be received from whatever you are using to gather video data) directly to the function

3) if you want to do this from the code you have, this will be a LARGE amount of work. I definitely suggest you dig more into what packages already exist that can do what you want and use their documentation to get the output you desire.

But in general: load model, receive video data, break down into individual images, predict label, draw label / box around the labeled item, resubmit the image to the video stream. The model should always be pre-loaded and not constantly recalled back again and again.",Tensorflow
"You can chain several predictive models together if you like. If you really want to design a single end to end neural network you can look into how object detection algorithms like YOLO or RCNN generate bounding boxes and unique classifications. 

Probably a fun project but I suspect you’ll find that some of those steps are best solved by “dumb” algorithms rather than trying to encode them into a neural network.",Tensorflow
Random thoughts: The E-MNIST dataset has all 26 handwritten letters of the English alphabet. I also imagine you might want to do some sort of image rescaling data augmentation to train on different-sized characters.,Tensorflow
"About 3 months ago my friends and I started playing Domino Cubano (Mexican Train Dominoes) and were getting really into it. At the end of each round, you need to count your remaining domino pips. My friend nerd sniped me saying how cool it would be to just your phone at your dominos and it counts for you. I've never done anything in CV, ML, or AI before this so I saw it as being an awesome project idea to let me learn.
  

  
Knowing I wanted this to be something you could do at a table with friends, I knew this had to be something that performs well enough on mobile devices. Installed apps can sometimes feel overkill so I wanted something lighter-weight (i.e. web app) so the inference runs completely in the browser with tfjs. Running on a Pixel 5, I usually get between 6-8 FPS and the accuracy seems to be pretty good so far.
  

  
After taking a picture, I allow the user to change the value from each bounding box if it was incorrect or add a new box by clicking on the screen if one wasn't found (I wanted to use this to help me understand real-world performance). When confirming the values are right, the image is saved in the browser IndexedDB storage; essentially making the entire application only need to download the model and other static assets.
  

  
I ended up using a YOLOv5 nano model (I know how this community feels about YOLOv5 but it was very easy to get trained + exported to tfjs and performs pretty well). I started with a MobileNetv2 SSD model but I was seeing \~1 FPS on mobile which wasn't great. My training set is \~150 pictures that I took and annotated myself on a double-twelve domino set, and I recently made additional augmented images to add to the set to help add more samples to account for poor lighting conditions, different domino set colors, additional angles, etc.
  

  
I also have been experimenting with some other models (YOLOv7, YOLOv5 exported model changes) so hopefully, I can get something that performs even faster on mobile eventually.
  

  
I partly wanted to put this out there to fish for some ideas on improvements, suggestions, users, etc. This is a pet project and would be willing to share my training data (any recommendations on where/how to share it?) to help out anyone who is curious about this.
  

  
Let me know what you think!
  

  
https://pip-tracker.netlify.app/",Tensorflow
"It’s my understanding that the range of perception around each pixel is increased by adding more conv layers.

By adding strides or max pooling the resolution of the image is decreased and conv layers will learn features per ‘scale’

I’m also a beginner however, would love to know more.",Tensorflow
"It's really the same as with regular dense networks.. Lower layers learn more generic features (lines etc.), when progressing up the network, it learns more sophisticated features (faces etc.). Pooling layers basically measure how much each region being pulled is similar to the filters applied to it",Tensorflow
"I have never seen any machine learning algorithm come up with something correct that it wasn’t trained to do or come up with something good that required creativity AND function. You’re good, design your chairs.",Tensorflow
"You guys gotta learn a bit about how Python works.

Module not found errors are some of the easiest things to debug, since it's very explicit and direct. It literally means that the file or module does not exist. Here's the thought process that should go through your head:

**1. Does the module really not exist?**

Go to your virtualenv or wherever tensorflow is installed. It should be something like `<installation_path>/lib/python-3.x/site-packages`. When Python says module not found, it means it literally cannot find a file with the thing you are trying to import. If you poke around and try to find `tensorflow/python/checkpoint.py` you will see that it truly does not exist. If you look into `tensorflow/python/__init__.py` to see if there is an exported thing named `checkpoint`, you will see that there isn't. So the error is not lying, unless you are looking at the wrong Python installation path.

**2. Does the thing I'm trying to use still exist?**

If you assume that the code is correct, then the only two possible reasons that the module doesn't exist are that someone deleted it in an older version, or it got moved to a different location. The latter is easier to verify since you can find it if it simply got moved, so let's start there.

The thing you are actually trying to use is named `checkpoint_management`. The error is being thrown by the line from `tensorflow.python.checkpoint import checkpoint_management`. Ok, so now let's see if `checkpoint_management` actually got moved.

Even though `tensorflow/python/checkpoint.py` does not exist, I can see that `tensorflow/python` still does, so let's start by doing a code search here:

    .../lib/python-3.x/tensorflow/python
    $ ack checkpoint_management

(`ack` comes from [ack-grep](https://beyondgrep.com/), a better version of grep, but you can just replace it with `grep -r`)

Immediately you'll see a ton of results like this:

    ...
    training/session_manager.py
    from tensorflow.python.training import checkpoint_management
    
    training/checkpoint_utils.py
    from tensorflow.python.training import checkpoint_management
    ...

So, regardless of how it happened, `checkpoint_management` is now currently under `tensorflow.python.training`, which means you should fix your import line to import from there instead.

Maybe it got moved, or maybe the source code had a bug, which means your assumption that the code is correct was wrong. Either way, you have what you need now.",Tensorflow
"If you want to run tensorflow from a VM and control it from a web UI, maybe your best bet would be deploying it through a docker image in a jupyter notebook
https://hub.docker.com/r/jupyter/tensorflow-notebook",Tensorflow
"Sounds like deepdream:

Train NN classifier
Run an image through, get classifier opinion
For example it says that there is a living room, but we want for it to dream up dog-like features on it so we do following:

Treat input image as NN weights, and ""dog"" prediction as true classifier output. Now compute how we should change input image for classifier to predict more ""dog"" in the image, like in training we compute how we should change NN weights to get closer to proper answer. Just this time we change input image by adding gradient to it, instead of changing weights

For your task i would do it like this:

Train NN that classifies recipes into various features that completed dish has: how spicy, how salty, how close to cooking in various cultures

This may be done with hand crafted dataset, or with autoencoder (like face generation but applied to cooking recipes), if done with autoencoder you will have to then make sense of features it generated, if handcrafted you will have to make some objective metric of how close to some culture dish is which might be hard

Then take the classifier (or encoder), and ""deepdream"" desired recipe:
Take original recipe, predict what dish it would make

Change feature vector of resulting dish to dish that you want

Deepdream original recipe so it would predict the dish you wanted

There are some colab notebooks that allow you to play with deepdreaming and jnderstand it better

Other approach might be to make network that predicts recipes from dishes, if you have dish features - recipes pairs",Tensorflow
"Not entirely sure what the context of the question is, but one way is to freeze the pretrained weights in forward direction then put the weight component into the reverse model and see if performance can be improved by unfreezing layers/weights one by one.",Tensorflow
"It's hard to give a concrete number about how many samples of a search are ""enough"", since it depends also on the number of hyper-parameters you have. Also consider that for a given set of hyperparameters, the result of training will vary depending on the random initilization of the network. The best bet, as already suggested, is to use a Bayesian search approach that takes this into account.

I know you're looking for answers pertaining to random search, but honestly, I'd never use random search.",Tensorflow
Ok so if anyone has this issue is seems like using mixed precision on cuda 11.5 can have a convergence issue in some cases that it won't in a newer version. Turning off mixed precision fixed this problem for me.,Tensorflow
I use the directML plugin with my AMD GPU. Works perfectly out of the box. [https://docs.microsoft.com/en-us/windows/ai/directml/gpu-tensorflow-plugin](https://docs.microsoft.com/en-us/windows/ai/directml/gpu-tensorflow-plugin),Tensorflow
"Two options: directml and opencl.

Directml is pretty good. Theres a plugin, but theres also a 1.2 version. 

You can also write your own gpu kernels with pyopencl. If you wan't a pytorch experience with opencl, try this little library:

https://github.com/iperov/litenn

For opencl you must first download the AMD drivers, or the equivalent khronos headers.",Tensorflow
"Not to slander TensorFlow on /r/tensorflow, but working with Transformers with this framework is damn near impossible. Last year, I attempted re-implementing STCN in TensorFlow and failed rather spectacularly.

Because `KerasTensor` is an internal class within Keras, I was able to find 0 usable documentation when I faced a similar error. The best I could do was print statement debug the traceback for clues and fix the type-disparity.",Tensorflow
"1. Yes it is. With this what we achieve with this aproach is that we have different environments with different dependencies and requirements. If something goes wrong you can always delete the virtual environment and your system python won't be affected by it. Even you can have different environments depending on the python version that you need.

2. Yes, every virtual environment is a clean python environment, so you will have to install all your dependencies again.

I recommend you to read about poetry. https://python-poetry.org/ we use it in my company and its quite good for managing python packages and dependencies in a comfortable way.",Tensorflow
"Disclaimer: I am a ML researcher and I teach an AI course in my university, I have a vested interest in this field, and I might be biased towards the field of AI

Remember a time when people say that computers would replace the average office and administrative worker back in the 1980s? Well, it didn't replace the workers, but it definitely reshaped office work for the 90s and beyond. 

To think that AI will have no impact on in one's field is naïve, but to think AI marks the end of humans in that field is overselling the state of AI.

First the bad news (maybe not so bad after we go through everything), most CAD software already have API interfaces for programs to programmatically control the CAD software, machine learning can already work with CAD software... now the good news, 

I used https://stablediffusionweb.com/#demo and fed it the prompt ""futuristic chairs"" and it produced these following images  

[https://imgur.com/gallery/4zu8f15](https://imgur.com/gallery/4zu8f15)  
Not too bad eh?, but as an industrial engineer you might spot a few fatal flaw in the images that they created. They are not physically possible (image 1+3), use too much material (image 2),  not ergonomical (image 3+4)  or unstable (image 2+4). 

Let's try a prompt that stable diffusion would have better success on ""A painting of robots fighting in the style of Salvador Dali"" 

[https://imgur.com/gallery/NaTv4np](https://imgur.com/gallery/NaTv4np)

Scarily good right? but an art enthusiast can probably see flaws in those AI reproductions that we art novices cannot. 

AI definitely has a disruptive impact on art. Quite recently we see headlines like [https://www.nytimes.com/2022/09/02/technology/ai-artificial-intelligence-artists.html](https://www.nytimes.com/2022/09/02/technology/ai-artificial-intelligence-artists.html) and  it wouldn't be a stretch to say that we are not too far from reading in the headlines that that an AI generated a top-selling piece of music... and then the fireworks will begin... copyright laws... As it stands (at least in the US), only a human can own copyright (See: Naruto the monkey selfie lawsuit)  but when the likes of Sony and other music labels (and Disney ) gets involved be ready for all of that to change. 

Enough segue, back to industrial design: is it possible to code the AI to specifically fit your design constraints and generate new images based on your design constraints? definitely... it is trivial? not really. the way AI is trained (currently) depends on differentiable loss, and it is not easy to convert our human notions of ""fitness"" into mathematical equations that we can use to optimize our neural networks. Will the crowd-sourced researchers eventually make it such that it becomes easy? maybe, but probably not in the near future... there are so many things we have to research and do in AI and we don't really have the resource for it, unless someone decides to spend millions for a few years for a team to dedicate their time and ho",Tensorflow
"When you define a Tensorflow Dataset, these are going to be read from memory when they’re needed at runtime. For this reason, you have to consider two things:

1) by default, when the dataset is read from memory at runtime, the order in which the data entries are read from dataset is random, ie if you have 5 batches in your test ds, the content of batch n1 is going to be different every time you run it, and this might be the first reason why you always get different accuracies all the time. If you wish to always have the same images order, you have to state it when you define the test_ds

2) As data is loaded when needed at runtime, any preprocessing operation is also repeated every time an image is loaded. If you have any preprocessing operation that involves randomality, every time you load data you’ll get different values in the test_ds.",Tensorflow
"The last bit of the path is not a folder but the name of the checkpoint.  If you put no filename, it will save in that format you see with resnet50.index.  If you end with .hdf5 it will be an hdf5 file.

To save in resnet50 folder you should end /Resnet50/checkpointname
Also you can use string formatting to change name based on epoch.  I believe as you have it the newest checkpoint simply overwrites the last.",Tensorflow
"Code for https://arxiv.org/abs/1708.05031 found: https://github.com/hexiangnan/neural_collaborative_filtering

[Paper link](https://arxiv.org/abs/1708.05031) | [List of all code implementations](https://www.catalyzex.com/paper/arxiv:1708.05031/code)



--

To opt out from receiving code links, DM me",Tensorflow
"For ML related stuff I've always liked jupyter more due to the ease of plot visualization and more interactive development. I think pycharm pro has jupyter notebooks integrated though. Also pycharm handles import paths for you. This is great if you don't need to share the code or open it from somewhere else, less great if you have to fix some imports (but nothing too complicated).",Tensorflow
"If you're new to ML (and asking ""What would be my approach..."" implies this), I would highly recommend learning ML (machine learning) with a data problem and use classical ML techniques. NNs (neural networks) are tricky and they hide problems. There are lots of great problems out there to work on in classical ML that will let you learn how to do pre/post-processing, manage resources, pick models, about different techniques, hyper-parameters, modelling... Also, I'm not sure this particular game is a great option for what you want to do. A straight forward solution uses an image classifier (lots of information on the web about that) and then 1 line of code. You could try and do the whole thing with an ML solution but I think it will get more complicated than you think (especially with NNs which, again, hide problems) and could become very frustrating very quickly.

I suspect you will run into a few issues if you want to work on this. The size and rotation of the images changes for each card. Both of these will cause issues and you will need to figure out how to deal with them. There are a few techniques you could use and I would probably start by taking advantage of the fact that scale and rotation doesn't made to the end result, it only matters to the NN. If you want I can make a suggestion but I'll leave it at this for now so you can come up with some ideas.

You will need to create a data set of pictures. This data set should have some pre-processing done to make it usable, hence my previous paragraph. You are wanting to build a classifier. In your case you will need to have 1 output neuron for each of the different images, ie. 1 for dragon, 1 for hammer...

If you really wanted to, you could use a NN to process two images and find the matches. It is not an efficient way of doing things and will be prone to unnecessary uncertainty/errors. I would suggest a different method. You use an NN to figure out what images are on each card and use image labels to create an array with 8 elements (1 element/label for each image). You will have two of these 8 element arrays, one for each of the two cards. Then the actual matching part is just performing a set intersection between the two arrays. The common value is the answer. In Python it's 1 line:     set([""A"", ""B"", ""D""]).intersection( set([""B"", ""C"", ""E""]) )     which gives {""B""}.

Personally I prefer simple, fast solutions. To classify the images on these cards you don't need an NN, a simple decision tree would do. There are other metrics that you can calculate from the image which are not affected by scale or rotation. Depending on your machine, you could cut the time required for training from hours (maybe even days) to a few seconds. I would also expect this to run much faster.

Be a bit clever and come up with a simple way to solve the problem. You can always go more complicated later and this will give you a good benchmark to try to beat later on.

Please don't take this as a discouragement. I work i",Tensorflow
"Im not really up to date any more and not an expert by any means but i would try it like this.

Take a picture of each card and label it. The labels array should include each possible icon. Icons that are present on the card should be marked with 1, icons that are not with 0. (To make sure the model is working as intended you should split your dataset in two, but make sure that each icon is present on the training dataset)

Now you can create you model, as output layer you need one ""neuron"" for each icon.

To ""play"" you run the model twice, so for each opened card once. After you collected both output arrays you can merge them and search for the highest output value.",Tensorflow
"If you make the dataset and you are using tensorflow, it is worth exporting your dataset as a TFRecord, unless it is made of images (in that case there is no significant performance boost unless you are using a tpu).

Personally, I export all my dataset in the TFRecord format, since it also features compression, and it makes loading it really easy and fast",Tensorflow
"The k80 compute capability is 3.7, t4 is 7.5. Current top of the line is 8.6

It might be a better value in terms of computation per $, but you'll likely run into a lot of models the k80 just won't run, for example anything using half-precision.

https://en.m.wikipedia.org/wiki/CUDA#Version_features_and_specifications",Tensorflow
"A GPU's architecture is really important if you are looking at continued software/library support down the road. Just get a relatively modern GeForce (2x or 3x series, the 4x is on the way). The options you're looking at somewhat outdated ones that you'll mostly find on cloud backends.",Tensorflow
"Firstly, you're going to want to make sure that whatever GPU you choose, is able to run optimally in the current environment you're setting it in. Do you have the appropriate supporting components in your computer to support the GPU you want? Do you have enough PCIE lanes available to support the amount of bandwidth you require for your ML training using the TF frameworks? Just something to think about. I see too many people install a GPU they think they need for their work in a PC and 'hope for the best'. 

To answer your questions, it's always optimal to get a newer GPU for lasting support. The cards you mentioned are still supported by current drivers but no one knows for how long. An 8 year old card is starting to show it's age considering how fast new gen GPUs are getting released. 

You're probably better off going for a GeForce card. They still support CUDA and can be used for so many different applications. Issue might be getting the right amount of VRAM for your needs. RTX 3090 might be the only Geforce card that caters to your VRAM needs at the moment. 

I have VMs that are accelerated by 3090s that i'm currently offering for free. You can definitely test it out and see if that card suits your current needs. Reach out if you want. Would be a pleasure.",Tensorflow
"I solved this myself after stumbling over another question on SOF that was unrelated but gave me an AHA moment.

My problem was here:

`spec = model_spec.get('efficientdet_lite4')`

`spec.tflite_max_detections=50`

Instead, I needed to change the whole spec of the model:

`spec = object_detector.EfficientDetLite4Spec(model_name='efficientdet-lite4',`

`uri='`[`https://tfhub.dev/tensorflow/efficientdet/lite4/feature-vector/2`](https://tfhub.dev/tensorflow/efficientdet/lite4/feature-vector/2)`',`

`hparams='',`

`model_dir=None,`

`epochs=50,`

`batch_size=64,`

`steps_per_execution=1,`

`moving_average_decay=0,`

`var_freeze_expr='(efficientnet|fpn_cells|resample_p6)',`

**tflite\_max\_detections=50,**

`strategy=None,`

`tpu=None,`

`gcp_project=None,`

`tpu_zone=None,use_xla=False,`

`profile=False,`

`debug=False,`

`tf_random_seed=111111,`

`verbose=0)`

&#x200B;

From there I could train the model and I could detect 50 detections on the Android side of things.

This has given me a headache for a few weeks. I'm an Android developer and nowhere near competent in Python or Tensorflow/ Lite.",Tensorflow
"Here's a pretty decent walkthrough in the readme: [https://github.com/mrdbourke/m1-machine-learning-test](https://github.com/mrdbourke/m1-machine-learning-test)

Bonus is that repo has a few nice tests once you're set up to measure the perf",Tensorflow
"It's possible with miniforge,  here is the link https://github.com/conda-forge/miniforge 
It's exactly the same as miniconda, but oriented to the arm64 architecture, I have a M1 2021 and it worked for me.",Tensorflow
"The point when doing kfold is to get a better estimate of performance not train the best model. The best model is using all the data available to you to train.

Each surrogate trained on each fold is assumed to be fairly representative of the final model. If your performance metrics differ significantly between folds then you have other problems.",Tensorflow
It's appropriate. MSE just averages the sum (loss 1 + loss 2) you described later. You can also weigh the two losses differently or learn them using different sub-networks (following a combined feature extraction component). Whatever is suitable.,Tensorflow
"Code for https://arxiv.org/abs/1911.09070 found: https://github.com/kentaroy47/efficientdet.pytorch

[Paper link](https://arxiv.org/abs/1911.09070) | [List of all code implementations](https://www.catalyzex.com/paper/arxiv:1911.09070/code)



--

 Code for https://arxiv.org/abs/1708.02002 found: https://github.com/facebookresearch/Detectron

[Paper link](https://arxiv.org/abs/1708.02002) | [List of all code implementations](https://www.catalyzex.com/paper/arxiv:1708.02002/code)



--

To opt out from receiving code links, DM me",Tensorflow
"I haven't tried but I suppose you can do it if you install Windows on the MacBook (given it is not an m1/m2 mac)

Under all relatively modern MacOS versions it won't work since there has been absolutely no support for Nvidia GPUs in MacOS since high Sierra (which had limited support) because Apple and Nvidia had some kind of beef.",Tensorflow
"If you use tensorflow serving, the new session overhead goes away. We have a few medium sized models (250K to 750K parameters) in production in a ad bidding platform. The entire bid request has a hard 10ms end to end budget. Our models run on CPUs on AWS ECS (Fargate) - pretty modest hardware. The 98th percentile latency is 3ms under load (~40,000,000 requests per day).",Tensorflow
"Code for https://arxiv.org/abs/1705.07832 found: https://github.com/yaringal/ConcreteDropout

[Paper link](https://arxiv.org/abs/1705.07832) | [List of all code implementations](https://www.catalyzex.com/paper/arxiv:1705.07832/code)



--

To opt out from receiving code links, DM me",Tensorflow
"Generate an image and run it through https://www.tensorflow.org/api_docs/python/tf/keras/utils/array_to_img

With scaling=True

Doesn’t look like you’re converting your prediction back to rgb (0, 255).",Tensorflow
"I developed an android app to run an image segmentation model sometime ago: https://github.com/jinensetpal/vision

However, I doubt inference of a self driving car model at the FPS required to be usable is practical.",Tensorflow
"the keyword you are looking for is online learning, and prequential evaluation

anyway, here is a link to get your started

https://machinelearningmastery.com/update-lstm-networks-training-time-series-forecasting/",Tensorflow
"You probably need to activate eager execution.. something like tf.config.experimental.enable_eager_execution(). It will transform your Tensors in EagerTensor which support the .numpy() method.

However, it might break other parts of your code.

Edit. Addendum and typo.",Tensorflow
"Even if you are using Eager Execution, there are certain places in TensorFlow where Graph Execution happens anyway--like inside tf.data pipelines or compiled Keras models.

In these situations, the numpy() method will not work unless you wrap your call with tf.py_function() or another way to re-enable Eager Execution.",Tensorflow
"I'm a total noob myself so I can't give you too much help here, but the shapes are defining the dimensions of a tensor (basically a multi dimensional matrix).  So this is probably about your input tensor not being the shape the model expects or maybe the output or your validation data doesn't match the shape of your input data or something.

Basically your using two different sized tensors somewhere.

Again, I'm a total noob so I can't help more than that.",Tensorflow
"Do.. you mean small boxes where the letters should be? I'm new but I saw that happen when the output character(~ID) is not existing in the character set of the string. Basically what ever gives out the text string at the end does not support that languages symbols/characters.

Either find out and change the encoding of the function/code that generates the string or probably easier to translate after the generation of the english words",Tensorflow
"Cuda 11.2 and CudNN 8.1 are compatible Cuda versions  for TF 2.6 .

If you don't wont to worry about downloading and setting path for Cuda file location, you can do it through Conda.

Check the updated instructions from here .([https://www.tensorflow.org/install/pip](https://www.tensorflow.org/install/pip)).  (and I suggest 2.8 or higher as 2.6 had stability issues)",Tensorflow
"I noticed when I downloaded tf that it actually came from NVIDIA!! I thought it might all be from some dude in Norway so that's a good sign but I did notice that TF seems to be only up to CUDA 11.2 at the moment --> [https://www.tensorflow.org/install/source#gpu](https://www.tensorflow.org/install/source#gpu). I bought a latest Nvidia 11.7 gaming PC specifically for AI but looks like I'll be playing Doom Raider or something for a bit yet ...

&#x200B;

It worked!! 

Fresh Anaconda env & then a ""pip install tf-nightly""  


(tensorflow210\_py310\_cuda112) C:\\Users\\USER>python
  
Python 3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) \[MSC v.1916 64 bit (AMD64)\] on win32
  
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
  
\>>> import tensorflow as tf
  
\>>> print(""Num GPUs Available: "", len(tf.config.list\_physical\_devices('GPU')))
  
Num GPUs Available:  1",Tensorflow
"Odds are incredibly slim (to the point I’d say “no”). Many ML or data science jobs ask for a graduate degree (Masters or PhD) as well as a few years experience in their postings. However, if you have good understanding of a lot of the principles under ML, and you have connections or can hustle for yourself, you can probably get yourself an internship position.",Tensorflow
"You won’t be judged much after you have interview. Getting it will be difficult. I think I’ve interviewed 0 people without at least bachelors degree (almost all cs/math or similar) and I’ve interviewed roughly 50 people across two companies for ml engineering roles.

Even bachelors in cs usually fails resume screen if they don’t have some software/ml internship or research experience. Generally you either need strong bachelors resume or masters/higher.

If I had to get a role without any degree I’d likely prioritize startups with less then 30 people. Companies you often apply directly to cto with an email/resume. They are more lenient on resume review and if you can get few years of working experience as an ml engineer anywhere it’s easier to job hop to different company you prefer. Experience is more valued then education but initial experience will be hard to get at most companies without education.

There are other tricks you could do. I remember one classmate getting a published paper at major conference that got a conference talk as an undergrad independently. An achievement like that + some networking at conference can get you a job. Conference review is often double blind although it’s challenging to write a good research paper without a mentor to guide you.",Tensorflow
"Try disabling your GPU in Tensorflow by using this:

import os
os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""

Then run the model, it'll run on your cpu and ddr4/5 ram which is obviously more than your GPU.",Tensorflow
"Yes, you have to calculate the average of each dimension. I took a course sometime ago and it was related to the average and variance per dimension. If you don’t find it, I can search the formula and share it with you when I go back home.",Tensorflow
"As others have mentioned, Keras is a high-level library that uses Tensorflow under the hood. For a beginner, Keras would be better than PyTorch. If you want more customization, then you would switch from Keras to Tensorflow or even a mix of those. Tensorflow now comes with Keras.",Tensorflow
"If you are familiar with scikit-learn linear regression,  there is an equivalent model in the rapids framework that is gpu accelerated out of the box.

I'm sure you could use TF too, but not exactly sure what you are asking there.",Tensorflow
I'll check on it every once in awhile. Have it set to email me if it's done or it crashes. If it's a brand new thing I might wait an epoch or so to make sure it works. If it's new and really slow I'll set it to email me after every validation step.,Tensorflow
"I've followed the zero to mastery course about tensorflow and it mainly works with keras the entire time. The course can be purchased on udemy for like 14 bucks during a sale, which is very often.

From the top of my head it starts from your usual sequencial Perceptron, then goes to convolutional networks for image processing, transfer learning, natural language amd then time series, very complete",Tensorflow
"The best way to learn it is to start with numpy and build nuerel networks, covets and the like from the formula yourself. Once you understand the shape and transformations, the actual block code style of keras because far more pleasant to look at.

Atleast this is how I learned keras. Without this way, I didn't know how to build a model. But now I know that the architecture generally follows a certain flow so I'm looking through the docs for certain stuff.",Tensorflow
"If you want to just gain the overall view of Keras, Check youtube videos and github from lawrence moronoy(Developer advocate - Tensorflow).

It will cover use  CNN, LSTM/BIdirectional LSTM  for text/image/sound classification/time series prediction.

You can also opt for course from coursera which will validate your knowledge and bound you to a time for complete the course. Rest of areas like Generative adversial networking , debugging your model etc, You will accumulate in time once you are part of any Tensorflow community.",Tensorflow
"There are a few ways to format your data for this tutorial. One option would be to create two folders, one for each 'species' that you want to segment. Within each folder, you would then have a folder for each image, and within that folder would be the image and the corresponding mask.
  

  
Another option would be to create a single folder for all of your images, and then have a separate folder for all of the masks. Within the mask folder, you would have a folder for each image, and within that folder would be the mask for that image.
  

  
Whichever way you choose to format your data, you will need to specify the path to the image and mask folders when you run the tutorial.",Tensorflow
">Should I be worried about it starting with such high loss?

Yes, you are most likely dealing with an exploding gradient caused by a high learning rate.
Why the model didn't blow up the first time i don't know, but you should decrease the LR in your pipeline.config",Tensorflow
"You may be overfitting on features that are vertically invariant? Just a guess, but it is highly data-set dependent.

If your real-world dataset does not ever have examples of data that are flipped, then you are training on data that is not representative, and thus you will be identifying features that are not helpful & that degrade your performance.",Tensorflow
"Data augmentation is used to gain more accuracy, therefore by definition you should have less accuracy on your original dataset. That being said, you should always use data augmentation if you do not have enough (millions) of images. It is hard seeing the lower accuracy, but suck it up, as your model is actually more usefull now. Good luck!",Tensorflow
"Go and try it. Worse case scenario is it's not worth it and you pull it out.

Splitting the bandwidth between two cards likely won't make a difference to you. It could increase the load times between maps in video games. I would test it out myself (if I were you) to see how long loading screens lasted. But your FPS should be, near as makes no difference, the same. (I have no personal experience with this though so it is more of a guess than anything, you'll have to test it our for yourself.) Bulk assets are generally passed during loading screens and small, fast bursts of data occur to update various parameters during general game play. It is possible that you will notice textures load in when you move to different areas of a map (quick to pass, low quality textures get replaced by slow to pass, high quality textures as they become available).

I am hoping to build a new machine later this year and I will definitely be keeping my 1080 as a second card along with whatever the new one is. Perhaps I'll use the 1080 to help train models faster, perhaps I'll use it so I can train 2 models at the same time, or maybe I'll use it for data processing to prepare data for the main card to train with. Lots of possibilities.",Tensorflow
"As others have mentioned, Karas might be easier to start with, but be careful, if you want to make something a bit more custom, TF can be a mean beast. Personally I would not recommend TF for anything, other than projects that involve high throughout inference pipelines, maybe. I’m a very happy Pytorch user, it’s perfect for research projects, small and big. It also has a very responsive community, reasonable documentation and many repo’s using Pytorch in a variety of areas. Good luck!",Tensorflow
"As a person that does deep learning infra and platform for a living... This will not work at all.

Those 2 cards are worlds apart in terms of Cuda and compute capability support. Most likely you'll run into mountains of Cuda errors if you try to do it. Even if you do get it working, if you use synchronous gradient update, you will be slowed down by the 970, so your 3070 will run as fast as the 970. 3070 can run prolly 4x faster if not wayy more than the 970.

Honestly, unless you know what you are doing with your set up, it's best to just unplug the 970 or at least always have it unseen when running in tf. Multi gpu training is already hard and buggy as it is... Adding an asymmetrical gpu to it just makes it worse.

One possible application though is maybe... Just maybe you can run training and eval in parallel. But idk how that will work properly unless you use dockerized environments",Tensorflow
"It's depends of the model that you are using. The only way to find out is testing. Program some different preprocessing functions, with different masking classes. It's the only way to find out this kinds of problems. Do assumptions and testing.

&#x200B;

Be careful with overfitting.",Tensorflow
"Totally fine. I don't know any useful tool that requires you a full desktop environment rather than providing web-based GUIs like tensorboard, jupyter etc

You also save resources when you solely work with terminal over ssh",Tensorflow
"I have to say, I love this idea. I find it really interesting that webgl on my android mobile seems slower than my desktop, but the inverse with web assembly (slower on desktop vs mobile - mobile wasm is actually surprisingly fast ~150ms for inference). I've been experimenting with a browser based project (who wants to download an app these days) which will mostly be used on phones, and this project gave me lots of good ideas. I'll upload pictures from each device but you could also just hook up something like Google Analytics and have it send this to you each time someone runs it. Food for thought. Thank you for this though!",Tensorflow
"Am I correct to assume you've overridden the keras.Model#train\_step, or that you are not using it at all?

If the model has multiple outputs, then you can log each individual loss (as well as individual metrics for each loss) like this:

```python
input_tensor = tf.keras.Input(..., name='inputs')
outputs = {
  ""output_a"": Dense(10, activation='softmax')(input_tensor),
  ""output_b"": Dense(1)(input_tensor),
}
model = Model(input_tensor, outputs)
model.compile(
  loss={""output_a"": ""sparse_categorical_crossentropy"", ""output_b"": ""mse""},
  loss_weights={""output_a"": 0.9, ""output_b"": 0.1},
  metrics={""output_a"": [""accuracy"", ""sparse_categorical_top_k""],
           ""output_b"": [""mse"", ""mae""]})
```

In the example above, the final loss function will be:`0.9*crossentropy(labels['a'], output_a) + 0.1*mse(labels['b'], b)`.

In case you did override the `Model#train_step` method, then you need to compute them manually and return them at the end of the step:

```python
from keras.engine import data_adapter

class MyModel(tf.keras.Model):
  def __init__(self, **kwargs):
    super().__init__(**kwargs)
    self.loss_a_tracker = tf.keras.metrics.Mean(name='loss_a')
    self.loss_b_tracker = tf.keras.metrics.Mean(name='loss_b')

  @property
  def metrics(self):
    return super().metrics + [self.loss_a_tracker, self.loss_b_tracker]

  def train_step(self, data):  
    x, y, sample_weight = data_adapter.unpack_x_y_sample_weight(data)
    with tf.GradientTape() as tape:  
      output_a, output_b = self(x, training=True)  
      loss_a = some_loss(y['a'], output_a)
      loss_b = some_loss(y['b'], output_b)
      loss_t = 0.5*loss_a + 0.5*loss_b

    self.optimizer.minimize(loss, self.trainable_variables, tape=tape)

    self.loss_a_tracker.update(loss_a)
    self.loss_b_tracker.update(loss_b)

    metrics = self.compute_metrics(x, y, p, sample_weight)

    return metrics
```

In the example above, `metrics` will be a dictionary of `(metric-name, value)` for all losses and metrics (including loss_a and loss_b, as we are returning them in the metrics property.
Furthermore, you only need trackers (`tf.keras.metrics.Mean`) if you want to have epoch-level values as well, as they keep track of the average of the metric value over an epoch.

There is an example of this in the official docs: [keras.io/guides/customizing_what_happens_in_fit](https://keras.io/guides/customizing_what_happens_in_fit/).",Tensorflow
"Yo this is not nearly enough information, for example do you declare model anywhere? 

I’d really recommend trying to get your hands dirty in a debugger like in visual studio code and figure this one out for yourself. Look into stuff like 

-	What object is it complaining about? Model?
-	if so, why is model None? Was it something else earlier and then changed to None or has it been None the whole time?

Stuff like that. Good luck don’t forget to have fun!",Tensorflow
"
I see you've posted a GitHub link to a Jupyter Notebook! GitHub doesn't 
render large Jupyter Notebooks, so just in case, here is an 
[nbviewer](https://nbviewer.jupyter.org/) link to the notebook:

https://nbviewer.jupyter.org/url/github.com/arjun-majumdar/Autoencoders_Experiments/blob/master/Conditional_VAE-MNIST_TF2.ipynb

Want to run the code yourself? Here is a [binder](https://mybinder.org/) 
link to start your own Jupyter server and try it out!

https://mybinder.org/v2/gh/arjun-majumdar/Autoencoders_Experiments/master?filepath=Conditional_VAE-MNIST_TF2.ipynb



------

^(I am a bot.) 
[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) 
[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) 
[^(Author)](https://johnpaton.net/)",Tensorflow
"Code for https://arxiv.org/abs/1312.6114 found: https://github.com/enalisnick/stick-breaking_dgms

[Paper link](https://arxiv.org/abs/1312.6114) | [List of all code implementations](https://www.catalyzex.com/paper/arxiv:1312.6114/code)



--

To opt out from receiving code links, DM me",Tensorflow
"QR codes are not that hard. Basically :

1. you want to read black and white shapes, that will be your data
2. you want to detect specific ""anchors"" that will help you understand what directions to read the data

Square is easier to read, obviously, but any shape can work. You just have to write your own logic to detect the anchors and read the data.

It's not really a problem I would solve with Tensorflow though. Basic pixels analysis works wonders here.",Tensorflow
"I don't think ML is even necessary - just old school image processing and computer vision. I've never specifically looked into how it's done, but I would guess a generalised Hough transform would find you the three anchor points, from which you can reorient, apply an affine transform, and then crop to get a clear image of the QR code. Then you simply read off the mean pixel values in each patch where you a priori know the code is located. 

Square codes are obviously the most space efficient and easiest to read off after locating the code, but any arbitrary configuration would be possible. In fact, people [have gone pretty wild](https://youtu.be/kW39Mt5kscQ) with different ways of encoding the information.",Tensorflow
"Lol posting in r/tensorflow you know you're going to get nothing but TF/Keras recommendations right (TF and Keras are used together, these days you'd rarely use one without the other)?

I would break it down a little more and think about the task itself. What is it you're wanting to do? Image classification, object detection, video classification, object tracking, etc. Once you have the tasks broken down then find a library/framework that does what you need it to do.

E.g. If you consider it an object detection problem it is: detect and localise all the pedestrians in a frame, and classify them by their (intended) action. IMO the easiest way to do this would be with [mmdetection](https://github.com/open-mmlab/mmdetection), which is built on top of pytorch. Just label your dataset, build a config, and boom you have a model. Inference with that model in only a few lines of code, you won't really need to learn too much to get started.

E.g. If you consider it image classification (you already have the pedestrians extracted and just need to classify their intent), you might find that easier to do with Keras, just butcher one of the examples on [keras.io](https://keras.io). You might also find [fast.ai](https://fast.ai) more to your liking.

Basically, don't choose your foundation library (i.e. TF or PyTorch) for an applied problem like this. Choose a high-level framework that will do 90% of the work for you, and just use whatever backend it prefers.",Tensorflow
"if you batch up your tf.dataset, the total size of it is irrelevant.  
If your total RAM usage is still unacceptably high, it's possible that your model is extremely large (many weights). Try inspecting the size of the various objects in your namespace - it might help you quickly identify the problem.",Tensorflow
"I don’t get why you are bothered by the ram usage? If every batch has the same size the training will take the same ram for every step. So by using half of what you have everything is fine. 

However if you want to train a big model I would suggest that you train it in a cloud. Google colab lets you train on a good GPU for free.",Tensorflow
Do you already have a working pipeline? Then just time the code. Most basic way would be something to use something like time.time() (or whatever the method is called again) before and after the code. Then calculate the difference.,Tensorflow
"Do you see a difference between the first inference after the model was initialized and the following ones? 

It’s funny that google seemed to forget to document which hardware they used for the benchmark. There is even an unsolved issue on GitHub about that ([Link](https://github.com/tensorflow/models/issues/10415)).  But on stackoverflow someone seemed to look into the config files and saw something about a tesla 100 ([Link](https://stackoverflow.com/questions/62879752/tensorflow-2-0-object-detection-api-model-zoo)). So it seems to be the same.

Edit: Sorry, for opening a new comment. In my defence: the Reddit app is quit bad.",Tensorflow
"Converting the strings to a date is easy. You only need to extract the key words from the text and use regex for creating your delta time that will be added to the current date. I did it once for work. Watson was used to find the dates and then we did a string to date converter using regex. The dates were typically presented in many formats, but they were always a single date or a range of dates ( June 10-20 or June 10 to July 5). We also used this library. 

https://daterangeparser.readthedocs.io/en/latest/",Tensorflow
It seems you forgot to specifiy an activation function for the final layer of your classifier. In this case you should be using the 'softmax' activation. If you adjust this your code will run just fine.,Tensorflow
"I mean if you're just looking for a classification model , depending on how many classes you need. There is the teachable machine, which is just a plug and go without having to delve into the CNN of machine learning, which is what I assume you mean with AI.

I think you can configure it for embedded systems which is also a plus. Anyways check it out , it might be enough to solve your problem.",Tensorflow
Odds are that he was using [this](https://www.tensorflow.org/tutorials/generative/style_transfer) example to create a style transfer model so he could stylize his original art. There is also StyleGAN which has an example implementation [here](https://keras.io/examples/generative/stylegan/) (though this example uses it to create faces). Odds are that he took one of these models and either adapted it himself or found a place that does it for him. Other sites include the Wombo AI Dream and huggingface models hub (search with the Text-to-Image filter).,Tensorflow
"As /u/puppet_pals mentioned, this happens because of tracing to compile the functions into more efficient code (execution graphs). It is also worth mentioning, that this is common in tensorflow. You can read more about this on this [article, the tf guide](https://www.tensorflow.org/guide/function). The eager execution is sometimes confusing things here.

Because of this behavior there are some pitfalls that you can run into, like how print statements would work only once (when traced), and then be ignored in compiled functions. That's why you need to use tf logging tools for example to get around that, since tf knows how to compile them.",Tensorflow
"Quantization is an optional step that you need to define if you want it. So no, by default the weights are not quantized.   


I actually don't know the other steps that happen when a model is converted to tflite. If you (or someone else) find(s) a good ressource that explains that it would be awesome to share it.",Tensorflow
"It looks like there is a stackoverflow thread about this:

[https://stackoverflow.com/questions/41415629/importerror-no-module-named-tensorflow-python](https://stackoverflow.com/questions/41415629/importerror-no-module-named-tensorflow-python)

Are you running TF on your system install of Python? This can make it hard to recover from library conflicts. If you are using a virtual environment, that's enough to help when you need to reinstall everything.

The best way I found to run TF on windows is with WSL 2 and Docker. 

Docker helps because the official image includes with everything needed to get started with TF. No need to install the CUDA software that can a pain to maintain the proper version across multiple projects.  With docker, even if you completely ruin the environment, it's easy to start fresh.

If you need any help setting up the environment, check out this video:

https://www.youtube.com/watch?v=YozfiLI1ogY00",Tensorflow
"Consider that the base model has experience recognizing image objects, this is a distinct type of recognition that may be related to your problem. Other categories of base model, like speech recognition may not be useful at all.",Tensorflow
"I didnt find any substantial difference between my tflite, quantized tflite and original model in terms of accuracy. But I'm not entirely sure it is a general result, you should evaluate your converted models still to check",Tensorflow
"Which GPU do you have? Make sure it's compatible CUDA version happens to be also compatible with your specific tensorflow version. 

You can check for your GPU's CUDA version [here](https://developer.nvidia.com/cuda-gpus)

You can check the compatibility between Tensorflow and CUDA [here](https://punndeeplearningblog.com/development/tensorflow-cuda-cudnn-compatibility/)",Tensorflow
"You can simply ignore the detections you don’t want. 

You would need to fine tune the model to produce only two outputs (as opposed to however many it produces now). The tensorflow [docs](https://www.tensorflow.org/tutorials/images/transfer_learning) describe how do to this in detail, but basically you need to replace the last dense layer in your model (the prediction layer).",Tensorflow
">So, I'm trying again, without the marketing bullshit.

It's still just self-promotion.  You're not really engaging the sub or sparking a discussion or anything.  You're just linking to the marketing material that's hosted elsewhere.",Tensorflow
"> Is there a way to change that?

Word of advice: if you're heavily relying on a library that does something differently than the way you have it set up, you're better off conforming to the library than trying to force it to work with you (especially if your setup just uses ""random"" directories).",Tensorflow
"There are multiple answers on SO that say there is no difference ([https://stackoverflow.com/questions/52121533/what-is-the-difference-between-the-lite-and-the-tflite-formats](https://stackoverflow.com/questions/52121533/what-is-the-difference-between-the-lite-and-the-tflite-formats))   Some tools may only ingest models with .tflite extension, the models themselves are (allegedly) the same.",Tensorflow
"First, wrap that in a try-catch block and log out exceptions that you catch. Then, if you're making a request into a local server, there's no reason to make another request in to the same server. Just make whatever is running on the second endpoint into a function and import it into the first one and call it directly. If they're actually two different apps for some reason, then check req.ok and see if that's true once the request has resolved. If that's not true, then log out what's on the request response. And also log out what's on your incoming request. Better yet, use a debugger. They're super easy to set up and use in Python. 

In essence, log out every line until you find which one is causing you issues.",Tensorflow
"Check my GitHub. I am replacing layers with new layers in order to reduce the number of weights. You can find the code in the compress_layer method in multiple classes. 

https://github.com/GabrielGlzSa/DeepModelCompressionUsingReinforcementLearning/blob/main/CompressionTechniques.py",Tensorflow
Run a small check: go through you image folder (either manually or code a if else statement). Cuz the error is never a lie: something you have or did is causing it. I would go through the folder with an if else and some regex to check all the files are formatted correctly. The best guess I could give you if the files are correct is some other file or folder is being added (potentially a hidden file/folder?).,Tensorflow
"Probably not the answer you are looking for, but I did run constantly into issues with CUDA on Windows and just gave up.

Just one last sanity check: Print out the physical devices tf can see:

https://www.tensorflow.org/api_docs/python/tf/config/list_physical_devices",Tensorflow
"Micropython has a pretty big overhead.

Tensorflow would probably work better if you worked in one of those USB transformer accelerators. You could find it by searching Rasp.Pi USB tensorflow.

Would need to see if someone did something similar though, I didn't see some ESP-tensorflow mix yet, but it's useful.

If you can build it it's a nice portfolio or even product piece.",Tensorflow
"[https://keras.io/examples/timeseries/timeseries\_classification\_from\_scratch/](https://keras.io/examples/timeseries/timeseries_classification_from_scratch/)

I think this may be a baseline for your model",Tensorflow
"Tensorflow in macs does not work really well, add ij that the M1 architecture is only for macs, plus macs don't have gpu support, so in general training will be really slow. I would advise you to try to run your code on Google colab (which is free although with some limitations)",Tensorflow
"Can't really provide an answer on this, but can provide my thoughts for what they're worth.  Full disclosure, haven't worked with TF ODAPI since the TF 1 implementation and haven't been done much ML over the past year. Perhaps someone with deeper experience can provide a more informed answer.

My take away was that the test set was running *sort of like* a validation set, and then I had my own 'proper' test set that (I felt) required a higher level of generalization that I would run inference on after a training period to evaluate the overall model performance. To be honest, I don't know if this added any value, though it certainly helped me feel better about my process. But in my case my data was generated so I had effective infinite variety and could afford to do that. YMMV.",Tensorflow
"Depends on how you ""increase the size of data by 100x"". Mini-batch training is a training regimen where true gradient is estimated using a batch of training examples, which is usually sampled uniformly at random. Mini-batch training will get you the same results whether or not you have one or multiple epochs eith the SAME number of total batches, assuming they are sampled at random (batch-wise gradient updates). Things are completely different if you are doing a full-batch training.",Tensorflow
"Lets break it down:

\`\`\`

tf.keras.applications.ResNet50(  
include\_top=False,  
input\_shape=None,  
pooling='avg',  
\#                    classes=NUM\_CLASSES,  
weights='imagenet')

\`\`\`

returns a model.  You are invoking that model on the inputs:

\`\`\`

resnet = tf.keras.applications.ResNet50(  
include\_top=False,  
input\_shape=None,  
pooling='avg',  
\#                    classes=NUM\_CLASSES,  
weights='imagenet')(CNN\_Input)

\`\`\`

so your variable is actually holding a Tensor, not a resnet.  You'll want to do:

\`\`\`

resnet = tf.keras.applications.ResNet50(  
include\_top=False,  
input\_shape=None,  
pooling='avg',  
\#                    classes=NUM\_CLASSES,  
weights='imagenet')

x = resnet(CNN\_Input)

CNN=Flatten()(x)

\# ...

\`\`\`

This should solve your issue",Tensorflow
"Can you check your tensorflow version and make sure it is compatible with cuda 11.7 ?

There also looks like a bit of data augmentation lines going on here. Maybe eliminate those to start with.

Looks like an old piece of code and maybe 'tf.io.read\_file' is depricated and replaced.

Maybe try running it on google colab if the dataset is not too huge. Colab will always have the compatible versions of cuda and tensorflow.",Tensorflow
"Are you sure that you are **testing** your model on the test set? Looks like the train and test sets are shuffled but not one to one, meaning that the correct y for a specific input is mapped to another input. Manually check it by plotting the first image on your set, predict and observe the result. And I assume that you did not encounter overfitting since your validation accuracy is %90.",Tensorflow
"If you know about Android development ; search the following on the web

1) how to train custom yolo ( you will find tutorials have most of your categories (if not the procedure is pretty much the same))

2) yolo Android 
            1) in this you will find tutorials for converting your yolo to tf model then the latter to a tflite model
             2) next you will find a app in which the model is used ( basically to use your model, you just have changed the model path and few parameters in the code (Java/kotlin) 

When searching and following the tutorials, be sure to follow it for the same yolo version",Tensorflow
"AFAIK, tflite conversion is possible only on SSD models... If you are using something like centernet architecture for pose estimation, you can prune/quantize to make it lighter for deploying it to low power edge devices....",Tensorflow
"Try removing the colormode and preprocessing function from the image generators.   
[Here's the working notebook with lower accuracy.](https://colab.research.google.com/github/gopalakrishna-r/d2l/blob/master/convolution/VGG16EmotionDetection.ipynb)",Tensorflow
"I am currently researching model compression. Check the adadeep paper. They use reinforcement learning to compress models for mobile phones. You won’t be able to use it as it requires a server with a lot of resources, but you can look at what approaches they use to compress dense layers : w1, w2. You can use those approaches to reduce the number of weights. A model with millions of weights can be reduced to thousands of weights with minimal accuracy loss.",Tensorflow
"If you copy paste the network from one site to another then modify it, without understanding what you copied, it is going to be very difficult for anyone to debug.
Is the data the same shape / type? Did you go backwards from the error code to the line that caused the error?

We need more information. Just posting a notebook here and asking for help doesn’t show that you’ve tried to fix it yourself or what you’ve attempted.

From what I see, the error is “no algorithm worked!” Which tells me there’s an issue with understanding what you are trying to accomplish.",Tensorflow
"These things are so disjoint, it'd be like asking ""what's the difference between an engine and a drive-thru?""

Like, they're related, but not so much so that asking what the ""difference"" between really makes much sense.  You'd be better off asking ""how do they work together?"" or something, but even then, you'd be getting a lot of different answers since they work together in a lot of different ways.

My suggestion is to not worry about trying to understand what these things are in general, but, rather, try to understand what they matter to you, i.e., focus on ""depth"" rather than ""breadth"" while you're trying to figure everything out.  For example, if you're interested in NLP, then you probably don't need to worry about OpenCV right now, and you'd be better off just ignoring it until you get to a point where you can't ignore it any longer.

Either that, or you need to be more specific with what you're asking here, cause this question is quite loaded.",Tensorflow
"Although these terms are all related to the field of machine learning and computer vision. Their meanings couldn't be more different.

I can explain them individually if you want to, but I don't think it will help much, because (pardon me for my assumption) you're probably a newbie to the field of machine learning, and the fact that you're confused by basic concepts means that you have much more to learn before building and functional application.

My advice is that you should start from the basic and work your way up before actually work with those frameworks and write your own program. You're getting ahead of yourself but no need to be ashamed, many newbies are like this as well.

This may sounds a typical unhelpful Stackoverflow answer but it's just my honest advice.",Tensorflow
"I'm not too familiar with tfjs, but given the models need module calls to load/run, I would imagine they need to use javascript and therefore script tags.

I looked at face-api.js, and it may be possible to improve performance by shedding out unnecessary models? If you dig into the source and extract only the bits relevant to the inference you need, you could get some improvements in performance.

There's also a chance you're reloading the model(s) every time you call an inference. If that's the case, you can resolve that by only initializing once, it'll help considerably!",Tensorflow
"If gpu usage is below 30% you should be targeting other factors. 

&#x200B;

Do you have a dataloading bottleneck? Does the gpu have to wait for new data to come it between every sample?

&#x200B;

Do you have same batch size?",Tensorflow
"Don't ever try to run TF1x OD API in any format viz., through PIP, Conda or Docker installation... Eventhough, TF officially supports TF1.5, it is advised to use TF2.x for OD API.... I was running TF2.x OD API in conda in both my Ubuntu as well as Windows OS...... Very recently moved to docker and it took a week how to bind host volumes, ports and replicate training/evaluation and inferencing routines... TF2.x docker image is created from source (Bazel Build), and the way it was using my GPU resources without memory fragmentation was totally different.... Stay away from any colab versions, if you want to get your feet wet on TF OD API...",Tensorflow
"To calculate matrix determinant you need to use tf.linalg.det: https://www.tensorflow.org/api\_docs/python/tf/linalg/det

Also in your example you don't need Session. Furthermore, you shouldn't use Seeeion in TensorFlow 2: https://www.tensorflow.org/api_docs/python/tf/compat/v1/Session 

Your code with modifications:
```
import tensorflow as tf 
import numpy as np

matrix1 = np.array([(2,2,2),(2,2,2),(2,2,2)], dtype = 'int32') 
matrix2 = np.array([(1,1,1),(1,1,1),(1,1,1)], dtype = 'int32')

# print(matrix1) 
# print(matrix2)

matrix1 = tf.constant(matrix1) 
matrix2 = tf.constant(matrix2) 
matrix_product = tf.matmul(matrix1, matrix2) 
matrix_sum = tf.add(matrix1,matrix2) 

matrix_3 = np.array([(2,7,2),(1,4,2),(9,0,2)], dtype = 'float32') 
#print(matrix_3)

matrix_det = tf.linalg.det(matrix_3) 

print(""matrix product = "", matrix_product,""\n"") 
print(""matrix sum = "", matrix_sum,""\n"")
print(""matrix determinant = "", matrix_det,""\n"")
```

This is the output I get: 
```
matrix product =  tf.Tensor(
[[6 6 6]
 [6 6 6]
 [6 6 6]], shape=(3, 3), dtype=int32) 

matrix sum =  tf.Tensor(
[[3 3 3]
 [3 3 3]
 [3 3 3]], shape=(3, 3), dtype=int32) 

matrix determinant =  tf.Tensor(55.999992, shape=(), dtype=float32) 
```",Tensorflow
"This video could be helpful[https://www.youtube.com/watch?v=ya5NwvKafDk](https://www.youtube.com/watch?v=ya5NwvKafDk)It was recorded 2 years ago and I'm not 100% sure if a ""skills list"" changed somehow during this time  
Curriculum mentioned in video: https://www.notion.so/Getting-TensorFlow-Developer-Certified-Curriculum-ff8385b6f9284fdfbc930ea06ce8749c",Tensorflow
"Best way to complete the certification Coursera Machine learning Certification from Lawrence forum. That is designed for familiarising with TF certification exam .

https://www.coursera.org/professional-certificates/tensorflow-in-practice",Tensorflow
"it depends on how you save your checkpoint? Have a look at this:

[https://www.tensorflow.org/guide/keras/save\_and\_serialize](https://www.tensorflow.org/guide/keras/save_and_serialize)  


If you save it as a .ckpt, I guess not.",Tensorflow
"For example, my network keeps detecting my hand as a wild turkey.  I can teach my network that hands are not turkeys by giving it pictures of hands and no detections.  I'm guessing this kind of thing isn't done, which is why no one has commented (?)",Tensorflow
"From what I remember writing custom loss functions, TF expects one loss per item in the batch, so gradients should be calculated independently for each element in the batch. You typically take the mean or sum of those losses then for optimization though, but I don’t think that affects independence. 

Disclaimer: I haven’t done a TON of custom losses, so there could be more to it than I know.",Tensorflow
You could also try other approaches like low-rank factorization to reduce the number of weights by inserting a smaller dense layer in between. If you are interested in other approaches you can search for AdaDeep. I am using their paper as reference for my work. They cite multiple techniques and use reinforcement learning for choosing which to use in each layer of a model.,Tensorflow
"The error is raised when keras layer is called withot argument


Please check simple steps to reproduce the exception and fix for them here: [The first argument to `Layer.call` must always be passed.](https://fixexception.com/keras/the-first-argument-to-layer-call-must-always-be-passed/)",Tensorflow
"Installing TF from docker is the best way forward, if you find building TF from source..... Building TF from source has always been a pain and it takes time and exits out during Star of build, midway or towards the end, leaving one with nothing.... What I have observed, using TF with docker and enabling XLA will suffice on a 8GB GPU for training TF higher resolution models..... I do not see much of GPU memory fragmentation, while using Docker.... Will advice to read Datamines docker images... They have one for every possible combination of TF2x, Cuda and OpenCV....",Tensorflow
"Thank you for the replies and helpful suggestions. I know using the official TensorFlow docker images is an easier way. Nevertheless, I have to build from the source. I'm going to send a pull request to TensorFlow's repository, and before sending it, I also have to run unit tests on my proposal. Of course, The prepared official package is not built from the code I'm writing. It is why I'm struggling to build TensorFlow from the source.",Tensorflow
"None of TF1 versions are supported... Only TF1.15 is supported, but it's buggy too..... Google have upgraded all their TF1.x models to TF2.x in their model zoo....... https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/tensorflow-1.14/..... This URL is for Object detection API and I am not sure as it help you or not....",Tensorflow
"Hey, does it help if I tell you this is not a project for work, this is a project I am working on in my garage.  I'm just beginning to learn how to use new computer tools to work on little projects I have.  

Any help would be greatly appreciated!",Tensorflow
"Tf1.15 is not compatible with cuda 11/cudnn 8.... You have to use cuda 10.0 or cuda 9.2..... But managing multiple cuda versions in a virtual environment like conda is not easy and straightforward.... Instead use Docker.... Datamines github/dockerhub pages have all these combinations of TF versions and Cuda....If you are new to docker, its worth spending some time on how containers work and how an environment can be isolated/containerized/virtualized... I just got into dockers barely two weeks before and I have uninstalled conda from all my system... Will be happy to help/hand hold you on this.... My question to you... Why do you want to use TF1.15... No doubt it is the only supported TF1x version, but it's so buggy... Please change to TF2x....",Tensorflow
"The official TF1.x doesn’t support CUDA 11 or newer, which means it can’t run on latest NVIDIA GPU.  I tried to change the source code and recompile it but failed. Not easy
But NVIDIA maintains a repo, forked from official tf1.15.5, to support new CUDA. You have found the right place. 

Try to install it by taping 
$ pip install --user nvidia-pyindex",Tensorflow
"Yes, you could use tensorflow for this task.

Buuuuuuut, you don’t need to use deep learning for this so it might be worth your time to explore alternative solutions. This is a pretty general computer vision problem, you might want to look at the structure of your images to see if there are patterns you can exploit.",Tensorflow
"I think you are installing Tensorflow through ""pip install tensorflow"". 

 Mac M1 users were installing Tensorflow through metal plugin instructions with Conda channel.

Another way I found recently.

1. Create a virtual environment with Python  3.10 
2. pip install tensorflow-aarch64.
3. Pip install tensorflow-macos.",Tensorflow
"This sounds like a good usecase. The main challenge you have is the small amount of data. I would suggest transfer learning and a lot of input augmentation(for example if you mirror an image horizontally, left will become right but front and back stay the same, given we ignore the fact this will change where the drivers seat is). Be careful though, because you wont get perfect results, there will always be some weird looking cars that confuse the model.",Tensorflow
"I would suggest to try batchnorm after each conv layer. It helps stabilize training. Also try doing 2 conv layers in a row and then doing a stride of 2 or max pooling. This will increase the receptive field at each image resolution. What is the size of your layer when you pass it to the first linear layer. It seems like you fed a 256x256 image and you downsize it a fair amount for feeding it to a 4096 layer. I would maybe suggest to maybe not down sample so much. Also I bet 4096 is a bit overkill for this model. And as the other redditor suggest try decreasing the dense layer [1024 512 256]. However, for the conv layers you should be increasing the number of channels as resolution decreases. For example maybe do [64 128 256 512]",Tensorflow
"Can you share an example of an image? Aside from what the other commenters have said, you can ""fix"" your dataset to mask portions of the image that are not needed for the network. Essentially it reduces the amount of pixels your network needs to learn about.  


https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7785089/",Tensorflow
"60% train, 30 val, 10 test.

60 train, 20 val, 20 test.

60 train, 10 val, 30 test.

50 train, 20 val, 30 test. 


Or whatever; depends upon how much data you have, if there is periodicity in the data that you want to have both validation and test data on. 

From a “does this model work in real life” standpoint, you want to use as much test data as possible, while training with enough data to avoid overfitting and missing important phenomena, and leaving just enough for validation (parameter tuning, model selection). 

In general, I wouldn’t go below 50% training, or 10% of data for validation or test.

Edit: Also, the order is train first, then validate and select best model (if tuning parameters, you then retrain, and select a new best model from the validation results), then test — if that wasn’t clear. If your final test isn’t good, you *do not* select a different validation model and re-test. If you do, you’re basically using two validation sets. Instead, you go back to your training set and model, and come up with something new. The test set is just a test. It either shows your model works, or that it doesn’t. You completely void anything useful you’ve done if you start tweaking things to get better test performance by iterating on the test set.",Tensorflow
"Are you saving your models as you go along? Even with the random seed set, batch randomisation can cause variations in what direction in the solution space the network goes, which can cause models trained on the same dataset to end up with different weights/bias. If you have a very large difference in performance from the SAME model with the same dataset, then it is likely your dataset isn't properly balanced and so your model (per batch/epoch) is getting pushed into widely different directions despite having the overall same original data.  


Hyperparameter optimization, time, and  an understanding of exactly what type of validation best meets the solution to your question at hand, will be the best starting point to deciding which model best suits your needs.",Tensorflow
"Just checking, but you know that loss function operates on batches right?  X[0] and X[1] are going to be the first and second inputs in a batch which I do not think is what you want.

While your approach would work once you solve the logic issues in the loss function, I think you're making things harder than they need to be.  Typically, the approach I would take is to just calculate alpha in advance to use as labels, if what I want is to predict alpha.  Then you can just use predefined losses.  It seems like this ought to be doable for you: alpha = (y_true  - X[1]) / X[0], calculate all of these in advance to be your labels.  This will also solve your scaling question, as you can calculate unscaled alpha for use as labels then easily scale and descale it.",Tensorflow
"I've read in the [tensorflow docs](https://www.tensorflow.org/lite/guide/inference#supported_data_types_in_java) that if you're feeding a byte buffer you're supposed to call to resizeInputs. When I perform that though it throws an error saying the dimensions are wrong for the input to the next layer. I tried just resizing from 1,2000,1 to just 2000.",Tensorflow
"I think the problem is that X.shape[1] is an integer and the argument expects a shape. Try (X.shape[1]) or (None, X.shape[1]) since I think in the input shape you have to specify also the sequence length.",Tensorflow
"Maybe try with a simple dataset and convnet like CIFAR10 to see if you can run with GPU? If that works then maybe the problem is in the way you set up your dataset? 

Otherwise you could also check if you installed tensorflow-gpu. Sometimes it does funny things when you do pip install tensorflow instead of tensorflow-gpu. Also, is there some setting of OS.environ that prevents it from seeing the GPU? Just things off the top of my head, hope it was of some help.",Tensorflow
"Look into the NGC container catalog available from NVIDIA. It installs the most compatible version of TensorFlow with your drivers.

Uninstall TensorFlow and install it from the NGC container. Make sure you have Docker installed on your machine.

https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow",Tensorflow
"I know there was an ampere (RTX 3000 series) bug with cuda 10, but that was resolved in cuda 11, so that shouldn't be the issue. Can you check the GPU usage, and if it's stalling on memory copy, or during processing? Is resizable BAR enabled? Are there any processes taking up CPU/GPU time?",Tensorflow
Haven’t started using TensorFlow yet but have a little bit of knowledge of Python and I see no one’s replied to you yet. Is it that you don’t know Python? What does the output look like if you actually know it’s identifying these cars? Is it a return code?,Tensorflow
"This was my code to get the scores and the classes that are above a specified confidence score and insert them into an array of objects.

    min_acc = 0.1 // minimum confidence score
    def retreive_detection_info(self):
        output = []
        class_arr = self.detections['detection_classes']
        score_arr = self.detections['detection_scores']
        for index, score in enumerate(score_arr):
            if score > self.min_acc:
                dict = {
                     'category':self.category_index.get(class_arr[index]+1),
                     'score': str(score)
                }
                output.append(dict)
        return output

 output ->  
\[{'category': {'id': 3, 'name': 'Honda'}, 'score': '0.32142583'}, {'category': {'id': 4, 'name': 'Kia'}, 'score': '0.1607558'}, {'category': {'id': 1, 'name': 'Toyota'}, 'score': '0.15470149'}\]",Tensorflow
"Had installed tf1. 15 yesterday on my system yesterday, but I had installed it using Docker..... But did not check the list and versions of related tf libraries.... Will check them and revert today..... I was running tf2. 8 with Cuda 11 and OpenCV (all of them bundled in a docker image..... The github page and docker hub page of ""Datamine"") is an excellent resource to run these kind of TF + Cuda + OpenCV on Docker.....",Tensorflow
"I was using Conda for almost a year and I can see the difference when I switched to docker....Conda and Pip use pre-built binaries for installing tf and other related libraries... Have been trying to build tf from source using Bazel, but till today have not got a breakthrough.... Datamine's docker images combo of TF, Cuda and OpenCV are all built from source... For noobs like me, it's God sent...If you have time, switch to docker.....",Tensorflow
"Seems to be a lot of mismatch between the installed tf version (1.15) and other related tf libraries......

Below is the tf and tf related libraries from my docker build....

    tensorboard          1.15.0
tensorflow           1.15.5
tensorflow-estimator 1.15.1",Tensorflow
"If anyone is having this problem, then here’s the solution: 
Use: 

‘ sentence = “The sky is blue”
tokenizer = tf.keras.preprocessing.text.Tokenizer
tokenizer.fit_on_texts(sentence)

def preprocess_sentence(sentence):
    sequences = tokenizer.texts_to_sequences(sentence)
    padding = tf.keras.preprocessing.sequence.pad_sequences(sequences)

  return padding

Preprocessing_sentence = preprocess_sentence(sentence) ‘

Then you pass that to your model (make sure to include the embedding layer in to your model)",Tensorflow
"https://www.tensorflow.org/guide/distributed_training

https://www.tensorflow.org/probability/examples/TensorFlow_Distributions_Tutorial

https://docs.microsoft.com/en-us/azure/machine-learning/how-to-train-tensorflow",Tensorflow
"I think [This might solve your issue](https://gist.github.com/ohad7/d8458a66661ec4c35a4846ab945af78e),

edit refer this notebook too

https://github.com/omaralbeik/mnist-coreml/blob/master/Jupyter/mnist-covnet.ipynb",Tensorflow
"Don’t worry about getting the certificate. Do the course irrespective of you are getting a certificate or not. 

Then sign up for the TensorFlow Developer Exam and pay for that - about $100 I think.  

https://www.tensorflow.org/certificate

The exam format closely follows the coursera course. 

I would say that’s a better certificate to have.",Tensorflow
"“Still” implying that it is outdated.

Reasons I use TensorFlow:

I like the Keras API way more than the high level PyTorch API
Have an easier time saving models using Keras than PyTorch
I like the tf.data API
According to my benchmarks graph mode is more performant than PyTorch’s",Tensorflow
"Are you sure its running on the GPU?  like can u check taskmanager or some other tool to monitor the GPU Core and Memory usage? 

Are you sure it's running on the GPU?  Can you check the task manager or another tool to monitor the GPU Core and Memory usage? ge? e?",Tensorflow
